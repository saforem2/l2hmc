{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gauge Observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------\n",
    "### TODO:\n",
    "* [x] Generate multiple chain lengths and deal with loading in from multiple `samples_history` files.\n",
    "* [x] Implement the same logic for `observables` as for `samples_history`.\n",
    "* [x] Modify remainder of code below to deal with case where `samples` and `observables` are dictionaries with keys specifying the length of the MCMC chain.\n",
    "* [x] Re-run the cells below for the remainder of `HMC` directory to get ESS values for comparing against ESS from L2HMC.\n",
    "* [x] Try training sampler for >> 1000 steps and running the trained sampler for a variety of different chain lengths to see what the integrated autocorrelation time approaches as  $N_{steps} \\longrightarrow \\infty$.\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T20:33:27.235204Z",
     "start_time": "2019-02-21T20:33:00.244978Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from scipy.special import i0, i1\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "COLORS = 5 * ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9']\n",
    "MARKERS = 5 * ['o', 's', 'x', 'v', 'h', '^', 'p', '<', 'd', '>', 'P', 'D']\n",
    "LINESTYLES = ['-', '--', ':', '-.', '-', '--', ':', '-.', '-', '--']\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T20:34:25.964441Z",
     "start_time": "2019-02-21T20:34:24.998656Z"
    }
   },
   "outputs": [],
   "source": [
    "from lattice.lattice import GaugeLattice, u1_plaq_exact\n",
    "#from l2hmc_eager import gauge_dynamics_eager as gde\n",
    "from gauge_model import GaugeModel, save_params_to_pkl_file\n",
    "\n",
    "import utils.gauge_model_helpers as helpers\n",
    "from utils.autocorr import *\n",
    "from utils.gauge_observables import *\n",
    "from utils.data_utils import (\n",
    "    calc_avg_vals_errors, block_resampling, jackknife_err\n",
    ")\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-21T22:22:23.241393Z",
     "start_time": "2019-02-21T22:22:23.151409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3878, shape=(), dtype=float64, numpy=3.0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3883, shape=(), dtype=float64, numpy=3.0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1., 0., -1., 2., -3.])\n",
    "y = np.array([0., -1., -1., 3., -3.])\n",
    "changes = tf.where(x != y)\n",
    "tf.reduce_sum(tf.square(x[changes] - y[changes]))\n",
    "tf.reduce_sum(tf.square(x - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T00:24:47.431631Z",
     "start_time": "2019-02-22T00:24:47.311399Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_else_make_dir(d):\n",
    "    if not os.path.isdir(d):\n",
    "        print(f\"Making directory: {d}\")\n",
    "        os.makedirs(d)\n",
    "        \n",
    "def _plot_individual_observables(figs_dir, observables, top_charges_autocorr):\n",
    "    multiple_lines_figs_axes = make_multiple_lines_plots(\n",
    "        figs_dir,\n",
    "        params['beta_final'],\n",
    "        observables,\n",
    "        top_charges_autocorr,\n",
    "        legend=False\n",
    "    )\n",
    "    return multiple_lines_figs_axes\n",
    "\n",
    "def _plot_individual_acf_iat(acf_arr, iat_arr, ess_arr, figs_dir):\n",
    "    out_file = os.path.join(\n",
    "        figs_dir, \n",
    "        'integrated_autocorrelation_time_plot.pdf'\n",
    "    )\n",
    "    kwargs = {\n",
    "        'x_label': 'Lag',\n",
    "        'y_label': 'Autocorrelation (top. charge)',\n",
    "        'legend': True,\n",
    "        'out_file': out_file\n",
    "    }\n",
    "    fig, ax = plot_autocorr_with_iat(acf_arr, iat_arr, ess_arr, **kwargs)\n",
    "    \n",
    "    return fig, ax\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and plot observables..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate observables for samples generated **_during_** training:\n",
    "- Every $\\approx 500$ steps or so during training procedure, we run the sampler at $\\beta \\equiv \\beta_{\\mathrm{final}}$. \n",
    "- By calculating observables (``total action``, ``average plaquette``, and ``topological charge``) for these samples and looking at the ``thermalization time``, we can get an idea of how well the sampler is performing.\n",
    "- We expect that as the training procedure continues, the ``thermalization time`` should decrease as the sampler improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 53.3s\n",
    "plt.close('all')\n",
    "log_dir = os.path.join('..', '..', 'gauge_logs_graph', 'run_233')\n",
    "train_observables_dicts = calc_observables(log_dir,\n",
    "                                           observables_dicts=None,\n",
    "                                           training=True,\n",
    "                                           frac=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T01:59:23.696620Z",
     "start_time": "2019-02-22T01:59:23.640228Z"
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([1., 1., 1., -1., -1., -1., 2., -2., 0., 0., 0., -2.])\n",
    "y = np.array([0., 2., -1., -2., 0., 1., 0., 2., -2., 2., 1., -2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:00:59.660515Z",
     "start_time": "2019-02-22T02:00:59.604107Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:02:15.994554Z",
     "start_time": "2019-02-22T02:02:15.944488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = np.sqrt(np.sum((x - y))**2)\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:02:19.193138Z",
     "start_time": "2019-02-22T02:02:19.140733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = np.sum(np.abs(x-y))\n",
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:01:30.082586Z",
     "start_time": "2019-02-22T02:01:30.029876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(x != y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:04:40.903373Z",
     "start_time": "2019-02-22T02:04:40.847487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(x != y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:06:04.657905Z",
     "start_time": "2019-02-22T02:06:04.598769Z"
    }
   },
   "outputs": [],
   "source": [
    "def tot_diff(x, y):\n",
    "    z = np.where(x != y)[0]\n",
    "    return np.sum([x[i] - y[i] if x[i] > y[i] else y[i] - x[i] for i in z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:06:38.391750Z",
     "start_time": "2019-02-22T02:06:38.339359Z"
    }
   },
   "outputs": [],
   "source": [
    "def tot_diff1(x, y):\n",
    "    return np.sum(np.abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:33:24.027742Z",
     "start_time": "2019-02-22T05:33:23.978713Z"
    }
   },
   "outputs": [],
   "source": [
    "xx = np.random.randint(-2, 2, size=1000)\n",
    "yy = np.random.randint(-2, 2, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:34:35.841402Z",
     "start_time": "2019-02-22T05:34:35.792369Z"
    }
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(-2, 2, size=10)\n",
    "j = np.random.randint(-2, 2, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:33:24.509534Z",
     "start_time": "2019-02-22T05:33:24.358604Z"
    }
   },
   "outputs": [],
   "source": [
    "def tot_diff2(x, y):\n",
    "    return len(np.where(x != y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:33:25.091576Z",
     "start_time": "2019-02-22T05:33:24.930438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_diff1(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:33:25.631464Z",
     "start_time": "2019-02-22T05:33:25.485279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "760"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_diff2(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:34:39.114980Z",
     "start_time": "2019-02-22T05:34:39.068974Z"
    }
   },
   "outputs": [],
   "source": [
    "charges_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:34:43.711611Z",
     "start_time": "2019-02-22T05:34:43.663871Z"
    }
   },
   "outputs": [],
   "source": [
    "charges_arr.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:34:46.548137Z",
     "start_time": "2019-02-22T05:34:46.494681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -2, 1, -2, -1, 0, 1, -1, 1, -2]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charges_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:34:52.100023Z",
     "start_time": "2019-02-22T05:34:52.046267Z"
    }
   },
   "outputs": [],
   "source": [
    "charges_arr.extend(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:35:15.753579Z",
     "start_time": "2019-02-22T05:35:15.702744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_diff1(charges_arr[-1], charges_arr[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:35:25.383398Z",
     "start_time": "2019-02-22T05:35:25.326637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_diff2(charges_arr[-1], charges_arr[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:35:55.108161Z",
     "start_time": "2019-02-22T05:35:55.045923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca = []\n",
    "ca.append(i)\n",
    "ca.append(j)\n",
    "tot_diff1(ca[-1], ca[-2])\n",
    "tot_diff2(ca[-1], ca[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T05:34:06.811939Z",
     "start_time": "2019-02-22T05:34:06.766029Z"
    }
   },
   "outputs": [],
   "source": [
    "charges_arr.extend(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:07:28.134905Z",
     "start_time": "2019-02-22T02:07:08.152721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.54 ms ± 415 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit d = tot_diff(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:07:30.788819Z",
     "start_time": "2019-02-22T02:07:28.801359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.1 µs ± 3.51 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit d1 = tot_diff1(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:08:02.012427Z",
     "start_time": "2019-02-22T02:08:01.959343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_diff(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-22T02:08:05.174537Z",
     "start_time": "2019-02-22T02:08:05.124878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_diff1(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Update train_observables_dicts:  \n",
    " * If `observables_dicts` argument of `calc_training_observables` is not `None`, only calculate observables that haven't been previously calculated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_observables_dicts = calc_observables(\n",
    "    log_dir, \n",
    "    observables_dicts=train_observables_dicts,\n",
    "    training=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Plot observables for samples generated **_during_** training:\n",
    "- In addition, for each batch of samples generated during, plot the topological charge history of each individual chain in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figs_axes = plot_observables(log_dir, train_observables_dicts, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges(log_dir, train_observables_dicts[2], training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges_counts(log_dir,  train_observables_dicts[2],  training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Plot top charges counts totaled over all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_charges_dict = train_observables_dicts[2]\n",
    "params, _, _, _, figs_dir_dict = find_samples(log_dir, training=True)\n",
    "title_str_key = 'training'\n",
    "count_dict = {}\n",
    "idx = 0\n",
    "for key, val in train_charges_dict.items():\n",
    "    step, beta = key\n",
    "    counts = Counter(list(val.flatten()))\n",
    "    count_dict[key] = counts\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(list(counts.keys()), list(counts.values()), \n",
    "                color=COLORS[idx], marker=MARKERS[idx], ls='')\n",
    "                #fillstyle='none')#, label=f'{key} training steps')\n",
    "    idx += 1\n",
    "    _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "    _ = ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 + f\"{beta}, \"\n",
    "                 + f\"{step} {title_str_key} steps; \"\n",
    "                 + f\"total across {params['num_samples']} samples\")\n",
    "    _ = ax.set_title(title_str, fontsize=14)\n",
    "    out_dir = os.path.join(\n",
    "        figs_dir_dict[key], 'topological_charges_counts'\n",
    "    )\n",
    "    check_else_make_dir(out_dir)\n",
    "    out_file = os.path.join(\n",
    "        out_dir,\n",
    "        f'topological_charge_counts_total_{step}_steps_beta_{beta}.pdf'\n",
    "    )\n",
    "    #if not os.path.isfile(out_file):\n",
    "    print(f\"Saving figure to {out_file}.\")\n",
    "    _ = fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate observables for samples generated **_after_** training.\n",
    " - Again, samples are generated at $\\beta = \\beta_{\\mathrm{final}}$.\n",
    " - In contrast to the samples generated **_during_** training (which are all ran for $\\sim 100$ steps), we now look at generating longer chains (i.e. longer runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "log_dir = os.path.join('..', '..', 'gauge_logs_graph', 'run_227')\n",
    "observables_dicts = calc_observables(log_dir, \n",
    "                                     observables_dicts=None, \n",
    "                                     training=False,\n",
    "                                     frac=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "observables_dicts = calc_observables(log_dir, \n",
    "                                     observables_dicts=observables_dicts, \n",
    "                                     training=False,\n",
    "                                     frac=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Plot observables for samples generated **_after_** training:\n",
    "- In addition, for each batch of samples generated during, plot the topological charge history of each individual chain in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figs_axes = plot_observables(log_dir, train_observables_dicts, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges(log_dir, train_observables_dicts[2], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges_counts(log_dir,  train_observables_dicts[2],  training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Plot top charges counts totaled over all samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "COLORS *= 10\n",
    "MARKERS *= 10\n",
    "params, _, _, _, figs_dir_dict = find_samples(log_dir)\n",
    "charges_dict = observables_dicts[2]\n",
    "title_str_key = 'evaluation'\n",
    "count_dict = {}\n",
    "idx = 0\n",
    "for key, val in charges_dict.items():\n",
    "    step, beta = key \n",
    "    counts = Counter(list(val.flatten()))\n",
    "    count_dict[key] = counts\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(list(counts.keys()), list(counts.values()), \n",
    "                color=COLORS[idx], marker=MARKERS[idx], ls='',\n",
    "                fillstyle='full')#, label=f'{key} training steps')\n",
    "    idx += 1\n",
    "    _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "    _ = ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 + f\"{beta}, \"\n",
    "                 + f\"{step} steps; \"\n",
    "                 + f\"total across {params['num_samples']} samples\")\n",
    "    _ = ax.set_title(title_str, fontsize=16)\n",
    "    #out_dir = os.path.join(\n",
    "    #    figs_dir_dict[key], 'topological_charges_counts'\n",
    "    #)\n",
    "    #check_else_make_dir(out_dir)\n",
    "    out_file = os.path.join(\n",
    "       figs_dir_dict[key],\n",
    "        f'topological_charge_counts_total_{step}_steps_beta_{beta}.pdf'\n",
    "    )\n",
    "    #if not os.path.isfile(out_file):\n",
    "    print(f\"Saving figure to {out_file}.\")\n",
    "    _ = fig.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
