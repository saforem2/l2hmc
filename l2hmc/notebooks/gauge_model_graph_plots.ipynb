{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gauge Observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------\n",
    "### TODO:\n",
    "* [x] Generate multiple chain lengths and deal with loading in from multiple `samples_history` files.\n",
    "* [x] Implement the same logic for `observables` as for `samples_history`.\n",
    "* [x] Modify remainder of code below to deal with case where `samples` and `observables` are dictionaries with keys specifying the length of the MCMC chain.\n",
    "* [x] Re-run the cells below for the remainder of `HMC` directory to get ESS values for comparing against ESS from L2HMC.\n",
    "* [x] Try training sampler for >> 1000 steps and running the trained sampler for a variety of different chain lengths to see what the integrated autocorrelation time approaches as  $N_{steps} \\longrightarrow \\infty$.\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from scipy.special import i0, i1\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "COLORS = 5 * ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9']\n",
    "MARKERS = 5 * ['o', 's', 'x', 'v', 'h', '^', 'p', '<', 'd', '>', 'P', 'D']\n",
    "LINESTYLES = ['-', '--', ':', '-.', '-', '--', ':', '-.', '-', '--']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lattice.lattice import GaugeLattice, u1_plaq_exact\n",
    "#from l2hmc_eager import gauge_dynamics_eager as gde\n",
    "from gauge_model import GaugeModel, save_params_to_pkl_file\n",
    "\n",
    "import utils.gauge_model_helpers as helpers\n",
    "from utils.autocorr import *\n",
    "from utils.gauge_observables import *\n",
    "from utils.data_utils import (\n",
    "    calc_avg_vals_errors, block_resampling, jackknife_err\n",
    ")\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def check_else_make_dir(d):\n",
    "    if not os.path.isdir(d):\n",
    "        print(f\"Making directory: {d}\")\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "def _plot_individual_observables(figs_dir, observables, top_charges_autocorr):\n",
    "    multiple_lines_figs_axes = make_multiple_lines_plots(\n",
    "        figs_dir,\n",
    "        params['beta_final'],\n",
    "        observables,\n",
    "        top_charges_autocorr,\n",
    "        legend=False\n",
    "    )\n",
    "    return multiple_lines_figs_axes\n",
    "\n",
    "def _plot_individual_acf_iat(acf_arr, iat_arr, ess_arr, figs_dir):\n",
    "    out_file = os.path.join(\n",
    "        figs_dir, \n",
    "        'integrated_autocorrelation_time_plot.pdf'\n",
    "    )\n",
    "    kwargs = {\n",
    "        'x_label': 'Lag',\n",
    "        'y_label': 'Autocorrelation (top. charge)',\n",
    "        'legend': True,\n",
    "        'out_file': out_file\n",
    "    }\n",
    "    fig, ax = plot_autocorr_with_iat(acf_arr, iat_arr, ess_arr, **kwargs)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and plot observables..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate observables for samples generated during **_training_**:\n",
    "- Every $\\approx 500$ steps or so during training procedure, we run the sampler at $\\beta \\equiv \\beta_{\\mathrm{final}}$. \n",
    "- By calculating observables (``total action``, ``average plaquette``, and ``topological charge``) for these samples and looking at the ``thermalization time``, we can get an idea of how well the sampler is performing.\n",
    "- We expect that as the training procedure continues, the ``thermalization time`` should decrease as the sampler improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 53.3s\n",
    "plt.close('all')\n",
    "log_dir = os.path.join('..', '..', 'gauge_logs_graph', 'run_227')\n",
    "train_observables_dicts = calc_observables(log_dir,\n",
    "                                           observables_dicts=None,\n",
    "                                           training=True,\n",
    "                                           frac=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **Update train_observables_dicts:**  \n",
    " * If `observables_dicts` argument of `calc_training_observables` is not `None`, only calculate observables that haven't been previously calculated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_observables_dicts = calc_observables(\n",
    "    log_dir, \n",
    "    observables_dicts=train_observables_dicts,\n",
    "    training=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plot observables for samples generated during training:**\n",
    "- In addition, for each batch of samples generated during, plot the topological charge history of each individual chain in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_axes = plot_observables(log_dir, train_observables_dicts, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_charges(log_dir, train_observables_dicts[2], training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plot_top_charges_counts(log_dir, \n",
    "                        train_observables_dicts[2], \n",
    "                        training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_charges_dict = train_observables_dicts[2]\n",
    "params, _, _, _, figs_dir_dict = find_samples(log_dir, training=True)\n",
    "title_str_key = 'training'\n",
    "count_dict = {}\n",
    "idx = 0\n",
    "for key, val in train_charges_dict.items():\n",
    "    step, beta = key\n",
    "    counts = Counter(list(val.flatten()))\n",
    "    count_dict[key] = counts\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(list(counts.keys()), list(counts.values()), \n",
    "                color=COLORS[idx], marker=MARKERS[idx], ls='')\n",
    "                #fillstyle='none')#, label=f'{key} training steps')\n",
    "    idx += 1\n",
    "    _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "    _ = ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 + f\"{beta}, \"\n",
    "                 + f\"{step} {title_str_key} steps; \"\n",
    "                 + f\"total across {params['num_samples']} samples\")\n",
    "    _ = ax.set_title(title_str, fontsize=14)\n",
    "    out_dir = os.path.join(\n",
    "        figs_dir_dict[key], 'topological_charges_counts'\n",
    "    )\n",
    "    check_else_make_dir(out_dir)\n",
    "    out_file = os.path.join(\n",
    "        out_dir,\n",
    "        f'topological_charge_counts_total_{step}_steps_beta_{beta}.pdf'\n",
    "    )\n",
    "    #if not os.path.isfile(out_file):\n",
    "    print(f\"Saving figure to {out_file}.\")\n",
    "    _ = fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate observables for samples generated **_after_** training.\n",
    " - Again, samples are generated at $\\beta = \\beta_{\\mathrm{final}}$.\n",
    " - In contrast to the samples generated **_during_** training (which are all ran for $\\sim 100$ steps), we now look at generating longer chains (i.e. longer runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "log_dir = os.path.join('..', '..', 'gauge_logs_graph', 'run_227')\n",
    "observables_dicts = calc_observables(log_dir, \n",
    "                                     observables_dicts=None, \n",
    "                                     training=False,\n",
    "                                     frac=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables_dicts = calc_observables(log_dir, \n",
    "                                     observables_dicts=observables_dicts, \n",
    "                                     training=False,\n",
    "                                     frac=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_dict = observables_dicts[0]\n",
    "plaqs_dict = observables_dicts[1]\n",
    "charges_dict = observables_dicts[2]\n",
    "suscept_stats_dict = observables_dicts[3]\n",
    "plaqs_stats_dict = observables_dicts[4]\n",
    "charges_probs_dict = observables_dicts[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaqs_arr = plaqs_dict[(20000, 4.0)]\n",
    "charges_arr = charges_dict[(20000, 4.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaqs_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.arange(plaqs_arr.shape[0])\n",
    "for idx in range(plaqs_arr.shape[1]):\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(steps, plaqs_arr[:, idx], label=f'sample {idx}', marker='', color=COLORS[idx])\n",
    "    _ = ax.axhline(y=u1_plaq_exact(4.), color='r', ls='--', lw=2.5, label='exact')\n",
    "    _ = ax.legend(loc='best')\n",
    "    _ = ax.set_xlabel('Step', fontsize=14)\n",
    "    _ = ax.set_ylabel('Avg. Plaquette', fontsize=14)\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 + f\"{4.0}, {20000} eval steps\")\n",
    "    _ = ax.set_title(title_str, fontsize=16)\n",
    "    out_file = os.path.join(log_dir, 'figures', f'avg_plaquette_sample{idx}.pdf')\n",
    "    plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "    _ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.arange(plaqs_arr.shape[0])\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps, plaqs_arr[:, 0], label='sample 0', marker='.', color='C0')\n",
    "_ = ax.axhline(y=u1_plaq_exact(4.), color='r', ls='--', lw=2.5, label='exact')\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('Avg. Plaquette')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_observables(log_dir, observables_dicts, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_charges(log_dir, observables_dicts[2], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plot_top_charges_counts(log_dir, observables_dicts[2], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "COLORS *= 10\n",
    "MARKERS *= 10\n",
    "params, _, _, _, figs_dir_dict = find_samples(log_dir)\n",
    "charges_dict = observables_dicts[2]\n",
    "title_str_key = 'evaluation'\n",
    "count_dict = {}\n",
    "idx = 0\n",
    "for key, val in charges_dict.items():\n",
    "    step, beta = key \n",
    "    counts = Counter(list(val.flatten()))\n",
    "    count_dict[key] = counts\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(list(counts.keys()), list(counts.values()), \n",
    "                color=COLORS[idx], marker=MARKERS[idx], ls='',\n",
    "                fillstyle='full')#, label=f'{key} training steps')\n",
    "    idx += 1\n",
    "    _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "    _ = ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 + f\"{beta}, \"\n",
    "                 + f\"{step} steps; \"\n",
    "                 + f\"total across {params['num_samples']} samples\")\n",
    "    _ = ax.set_title(title_str, fontsize=16)\n",
    "    #out_dir = os.path.join(\n",
    "    #    figs_dir_dict[key], 'topological_charges_counts'\n",
    "    #)\n",
    "    #check_else_make_dir(out_dir)\n",
    "    out_file = os.path.join(\n",
    "       figs_dir_dict[key],\n",
    "        f'topological_charge_counts_total_{step}_steps_beta_{beta}.pdf'\n",
    "    )\n",
    "    #if not os.path.isfile(out_file):\n",
    "    print(f\"Saving figure to {out_file}.\")\n",
    "    _ = fig.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beta(step, beta_init, beta_final, train_steps):\n",
    "    \"\"\"Returns new beta to follow annealing schedule.\"\"\"\n",
    "    temp = ((1. / beta_init - 1. / beta_final)\n",
    "            * (1. - step / float(train_steps))\n",
    "            + 1. / beta_final)\n",
    "    new_beta = 1. / temp\n",
    "\n",
    "    return new_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_beta(500, 3., 4., 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beta1(beta, annealing_factor, beta_final):\n",
    "    new_beta = beta / annealing_factor\n",
    "    if new_beta < beta_final:\n",
    "        return new_beta\n",
    "    return beta_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_beta2(beta_init, beta_final, train_steps, step):\n",
    "    \"\"\"Returns new beta to follow annealing schedule.\"\"\"\n",
    "    temp = ((1. / beta_init - 1. / beta_final)\n",
    "            * (1. - step / float(train_steps))\n",
    "            + 1. / beta_final)\n",
    "    new_beta = 1. / temp\n",
    "    return new_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_init = 2.\n",
    "beta_final = 4.\n",
    "train_steps = 6931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas1 = []\n",
    "betas2 = []\n",
    "beta1 = beta_init\n",
    "for i in range(train_steps):\n",
    "    beta1 = update_beta1(beta1, 0.9999, beta_final)\n",
    "    beta2 = update_beta2(beta_init, beta_final, train_steps, i)\n",
    "    betas1.append(beta1)\n",
    "    betas2.append(beta2)\n",
    "betas1 = np.array(betas1)\n",
    "betas2 = np.array(betas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(betas1 >= 4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(train_steps)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, betas1, label='betas1')\n",
    "ax.plot(x, betas2, label='betas2')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 2* np.pi)\n",
    "y = 1. - np.cos(x)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Topological susceptibility\n",
    "\n",
    "$ \\chi(\\beta, V) \\equiv \\frac{\\left< Q^2 \\right>}{V}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from astropy.stats import jackknife_resampling\n",
    "from astropy.stats import jackknife_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "actions_dicts, plaqs_dicts, charges_dicts = observables_dicts\n",
    "charges = charges_dicts[5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_statistic = lambda x: np.mean(x)\n",
    "\n",
    "estimate_arr = []\n",
    "bias_arr = []\n",
    "stderr_arr = []\n",
    "conf_interval_arr = []\n",
    "for idx, sample in enumerate(charges.T):\n",
    "    sample_squared = sample ** 2\n",
    "    charge_rs = jackknife_resampling(sample_squared)\n",
    "    estimate, bias, stderr, conf_interval = jackknife_stats(sample_squared,\n",
    "                                                            test_statistic,\n",
    "                                                            0.95)\n",
    "    print(80 * '-' + '\\n')\n",
    "    print(f\"Topological susceptibility statistics for sample {idx}, \"\n",
    "          f\"consisting of {charge_rs.shape[0]} L2HMC steps.\")\n",
    "    print(f'estimate: {estimate}')\n",
    "    print(f'bias: {bias}')\n",
    "    print(f'stderr: {stderr}')\n",
    "    print(f'conf_interval: {conf_interval}\\n')\n",
    "    print(80 * '-' + '\\n')\n",
    "    estimate_arr.append(estimate)\n",
    "    bias_arr.append(bias)\n",
    "    stderr_arr.append(stderr)\n",
    "    conf_interval_arr.extend(conf_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_statistic = lambda x: np.mean(x)\n",
    "\n",
    "estimate_arr = []\n",
    "bias_arr = []\n",
    "stderr_arr = []\n",
    "conf_interval_arr = []\n",
    "for idx, sample in enumerate(charges.T):\n",
    "    sample_squared = sample ** 2\n",
    "    charge_rs = jackknife_resampling(sample_squared)\n",
    "    estimate, bias, stderr, conf_interval = jackknife_stats(sample_squared,\n",
    "                                                            test_statistic,\n",
    "                                                            0.95)\n",
    "    print(80 * '-' + '\\n')\n",
    "    print(f\"Topological susceptibility statistics for sample {idx}, \"\n",
    "          f\"consisting of {charge_rs.shape[0]} L2HMC steps.\")\n",
    "    print(f'estimate: {estimate}')\n",
    "    print(f'bias: {bias}')\n",
    "    print(f'stderr: {stderr}')\n",
    "    print(f'conf_interval: {conf_interval}\\n')\n",
    "    print(80 * '-' + '\\n')\n",
    "    estimate_arr.append(estimate)\n",
    "    bias_arr.append(bias)\n",
    "    stderr_arr.append(stderr)\n",
    "    conf_interval_arr.extend(conf_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "charges_rs = np.array([jackknife_resampling(sample**2) for sample in charges.T])\n",
    "charges_rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_statistic = lambda x: np.mean(x))\n",
    "\n",
    "susceptibility_stats = {\n",
    "    'estimate': [],\n",
    "    'bias': [],\n",
    "    'stderr': [],\n",
    "    'conf_interval': []\n",
    "}\n",
    "for sample in charges_rs:\n",
    "    estimate, bias, stderr, conf_interval = jackknife_stats(sample,\n",
    "                                                            test_statistic,\n",
    "                                                            0.95)\n",
    "    susceptibility_stats['estimate'].append(estimate)\n",
    "    susceptibility_stats['bias'].append(bias)\n",
    "    susceptibility_stats['stderr'].append(bias)\n",
    "    susceptibility_stats['conf_interval'].append(conf_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_statistic = lambda x: (np.mean(x), np.var(x))\n",
    "estimate, bias, stderr, conf_interval = jackknife_stats(data, \n",
    "                                                        test_statistic, \n",
    "                                                        0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "charge_squared_mean, charge_squared_err = resampling.jackknife(\n",
    "    charges, func=lambda x: x**2, func_axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "squared_mean_a, squared_mean_a_error = resampling.jackknife(a, func=lambda x: x**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "suscept = []\n",
    "errors = []\n",
    "for sample in charges.T:\n",
    "    charges_rs = block_resampling(np.array(sample), 2500)\n",
    "    avg_charge2_rs = []\n",
    "    for block in charges_rs:\n",
    "        avg_charge2_rs.append(np.mean(block ** 2))\n",
    "    error = jackknife_err(y_i=avg_charge2_rs,\n",
    "                          y_full=sample,\n",
    "                          num_blocks=2500)\n",
    "    suscept.append(np.mean(avg_charge2_rs))\n",
    "    errors.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "charges = charges_dicts[10000]\n",
    "print(np.mean(charges**2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from lattice.lattice import GaugeLattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice = GaugeLattice(4, 4, 2, 'U1', 5, rand=False, data_format='channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice_gpu = GaugeLattice(4, 4, 2, 'U1', 5, rand=False, data_format='channels_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.links.shape, lattice_gpu.links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.samples.shape, lattice_gpu.samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key in lattice.plaquettes_dict.keys():\n",
    "    print(f'channels_last  {key}: {lattice.plaquettes_dict[key]}')\n",
    "    print(f'channels_first {key}: {lattice_gpu.plaquettes_dict[key]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rand_samples = np.random.randn(lattice.num_samples * lattice.num_links)\n",
    "rand_links = np.random.randn(lattice.num_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s_rand = rand_samples.reshape(lattice.samples.shape)\n",
    "l_rand = rand_links.reshape(lattice.links.shape)\n",
    "s_rand.shape, l_rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s_rand_gpu = s_rand.transpose(0, 3, 1, 2)\n",
    "l_rand_gpu = l_rand.transpose(2, 0, 1)\n",
    "s_rand_gpu.shape, l_rand_gpu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice._total_action(l_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice_gpu._total_action(l_rand_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key in lattice.plaquettes_dict.keys():\n",
    "    idxs0 = lattice.plaquettes_dict[key]\n",
    "    idxs1 = lattice_gpu.plaquettes_dict[key]\n",
    "    plaq_sum0 = [l_rand[idxs0[0]] + l_rand[idxs0[1]] \n",
    "                 - l_rand[idxs0[2]] -  l_rand[idxs0[3]]]\n",
    "    plaq_sum1 = [l_rand_gpu[idxs1[0]] + l_rand_gpu[idxs1[1]] \n",
    "                 - l_rand_gpu[idxs1[2]] - l_rand_gpu[idxs1[3]]]\n",
    "    print(f'plaq_sum (channels last):  {plaq_sum0}')\n",
    "    print(f'plaq_sum (channels first): {plaq_sum1}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(lattice.calc_plaq_observables(s_rand, 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(lattice_gpu.calc_plaq_observables(s_rand_gpu, 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice._total_action(l_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice_gpu._total_action(l_rand_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "links_shape = tuple([8] + [8 for _ in range(1)] + [2])\n",
    "links = np.arange(lattice.num_links).reshape(links_shape)\n",
    "#links = np.zeros(links_shape, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plaquettes_arr = np.array(list(lattice.plaquettes_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(plaquettes_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plaquettes_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plaquettes_arr[0, 2:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos_plaquettes = plaquettes_arr[:, :2, :]\n",
    "neg_plaquettes = plaquettes_arr[:, 2:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "action, plaqs, charge = lattice._calc_plaq_observables(links, beta=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def project_angle(x):\n",
    "    return x - 2 * np.pi * tf.math.floor((x + np.pi) / (2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos_plaquettes[0]\n",
    "np.sum(pos_plaquettes[0], axis=1)\n",
    "neg_plaquettes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "links(pos_plaquettes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_charge = np.sum(project_angle(np.sum(links[pos_plaquettes]) - np.sum(links[neg_plaquettes])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "links[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "links[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "links[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "links = np.array(\n",
    "    [[i, j, k] for i in range(8) for j in range(8) for k in range(2)]\n",
    ")\n",
    "links\n",
    "links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arr = np.array(\n",
    "    [[a, b, c, d] for a in range(5) for b in range(8) for c in range(8) for d in range(2)]\n",
    ").reshape(lattice.samples.shape)\n",
    "arr\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "patches = tf.extract_image_patches(images=samples_tensor,\n",
    "                                   ksizes=[1, 2, 2, 1],\n",
    "                                   strides=[1, 1, 1, 1],\n",
    "                                   rates=[1, 1, 1, 1],\n",
    "                                   padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "patches[0, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "  print tf.extract_image_patches(images=images, ksizes=[1, 3, 3, 1], strides=[1, 5, 5, 1], rates=[1, 1, 1, 1], padding='VALID').eval(), '\\n\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "offsets = np.array(\n",
    "    [(i, j) for i in range(8) for j in range(8)],  dtype=np.float32\n",
    ")\n",
    "offsets\n",
    "offsets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_tensor = tf.convert_to_tensor(lattice.samples, dtype=tf.float32)\n",
    "glimpse = tf.image.extract_glimpse(input=samples_tensor, size=(2, 2), offsets=offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Using helpers from: `utils/gauge_observables.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = (\n",
    "    '../../gauge_logs_graph/run_48/'\n",
    ")\n",
    "\n",
    "calc_observables_generate_plots(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_dir = ('../../gauge_logs_graph/gauge_logs_by_size/sixteen_by_sixteen/')\n",
    "log_dirs = [\n",
    "    root_dir + d for d in os.listdir(root_dir) \n",
    "    if os.path.isdir(os.path.join(root_dir, d))\n",
    "]\n",
    "log_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bad_dirs = []\n",
    "for log_dir in log_dirs:\n",
    "    try:\n",
    "        calc_observables_generate_plots(log_dir)\n",
    "    except:\n",
    "        bad_dirs.append(log_dir)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice = GaugeLattice(time_size=8, \n",
    "                       space_size=8,\n",
    "                       dim=2, \n",
    "                       beta=8., \n",
    "                       link_type='U1',\n",
    "                       num_samples=5,\n",
    "                       rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.links.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Calculate observables and create plots step by step, dir by dir..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = '../../gauge_logs_graph/run_1/'\n",
    "observables_dicts = calc_observables(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observables_dicts = calc_observables(log_dir, observables_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figs_axes = plot_observables(log_dir, observables_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges(log_dir, observables_dicts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "forward_mask = tf.cast(\n",
    "    tf.random_uniform((batch_size,)) > 0.5,\n",
    "    tf.float32\n",
    ")\n",
    "backward_mask = 1. - forward_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice = GaugeLattice(8, 8, 2, 'U1', batch_size, rand=False)\n",
    "position = lattice.samples\n",
    "position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "position_mask_forward = forward_mask[:, None, None, None] * position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "position_mask_forward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "forward_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "backward_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = (\n",
    "    '../../gauge_logs_graph/run_78/'\n",
    ")\n",
    "\n",
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "#autocorr_dir = os.path.join(figs_dir, 'autocorrelation_plots')\n",
    "#check_else_make_dir(autocorr_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Calculate observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params, samples, observables = calc_observables_from_log_dir(log_dir)\n",
    "if isinstance(observables, dict):\n",
    "    actions = {}\n",
    "    avg_plaquettes = {}\n",
    "    top_charges = {}\n",
    "    for key, val in observables.items():\n",
    "        _actions, _avg_plaquettes, _top_charges = val\n",
    "        actions[key] = _actions\n",
    "        avg_plaquettes[key] = _avg_plaquettes\n",
    "        top_charges[key] = _top_charges\n",
    "else:\n",
    "    actions, avg_plaquettes, top_charges = observables\n",
    "\n",
    "print('\\n' + 80 * '-')\n",
    "for key, val in params.items():\n",
    "    print(f'{key}: {val}')\n",
    "print(80 * '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Calculate autocorr fns, integrated autocorr times (IAT $ = \\tau$), and expected sample size (ESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if isinstance(top_charges, dict):\n",
    "    top_charges_autocorr = {}\n",
    "    top_charges_autocorr_avg = {}\n",
    "    acf_dict = {}\n",
    "    iat_dict = {}\n",
    "    ess_dict = {}\n",
    "    for key, val in top_charges.items():\n",
    "        # Previous (naive) method for calculating the top. charges autocorr fn\n",
    "        _autocorr, _avg = calc_top_charges_autocorr(val)\n",
    "        top_charges_autocorr[key] = _autocorr\n",
    "        top_charges_autocorr_avg[key] = _avg\n",
    "        \n",
    "        # New (better) method for calculating the top. charges autocorr fn and \n",
    "        # integrated autocorrelation time\n",
    "        acf_arr, iat_arr = calc_integrated_autocorr_time(val)\n",
    "        \n",
    "        ess_arr = []\n",
    "        for acf in acf_arr:\n",
    "            ess_arr.append(calc_ESS(acf))\n",
    "            \n",
    "        acf_dict[key] = acf_arr\n",
    "        iat_dict[key] = iat_arr\n",
    "        ess_dict[key] = ess_arr\n",
    "        \n",
    "else:\n",
    "    output = calc_top_charges_autocorr(top_charges)\n",
    "    top_charges_autocorr, top_charges_autocorr_avg = output\n",
    "\n",
    "    # New (better) method for calculating the top. charges autocorr fn and \n",
    "    # integrated autocorrelation time:\n",
    "    acf_arr, iat_arr = calc_integrated_autocorr_time(top_charges)\n",
    "\n",
    "    ESS_arr = []\n",
    "    for acf in acf_arr:\n",
    "        ESS_arr.append(calc_ESS(acf))\n",
    "\n",
    "# Use naive method for calculating autocorr fn. of invidiual links in samples \n",
    "if isinstance(samples, dict):\n",
    "    samples_autocorr_dict = {}\n",
    "    samples_autocorr_avg_dict = {}\n",
    "    for key, val in samples.items():\n",
    "        samples_autocorr, samples_autocorr_avg = calc_samples_autocorr(val)\n",
    "        \n",
    "        samples_autocorr_dict[key] = samples_autocorr\n",
    "        samples_autocorr_avg_dict[key] = samples_autocorr_avg\n",
    "else:\n",
    "    samples_autocorr, samples_autocorr_avg = calc_samples_autocorr(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Create plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figs_dir_dict = {}\n",
    "for key in observables.keys():\n",
    "    new_figs_dir = os.path.join(figs_dir, f'figures_{key}')\n",
    "    if not os.path.isdir(new_figs_dir):\n",
    "        print(f'Creating directory: {new_figs_dir}.')\n",
    "        os.makedirs(new_figs_dir)\n",
    "        \n",
    "    figs_dir_dict[key] = new_figs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key in observables.keys():\n",
    "    _figs_dir = figs_dir_dict[key]\n",
    "    _actions = actions[key]\n",
    "    _avg_plaquettes = avg_plaquettes[key]\n",
    "    _top_charges = top_charges[key]\n",
    "    _top_charges_autocorr = top_charges_autocorr[key]\n",
    "    _observables = (_actions, _avg_plaquettes, _top_charges)\n",
    "    \n",
    "    kwargs = {\n",
    "        'figs_dir': _figs_dir\n",
    "    }\n",
    "    \n",
    "    figs_axes = make_multiple_lines_plots(\n",
    "        params['beta_final'], \n",
    "        _observables,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    _acf_arr = acf_dict[key]\n",
    "    _iat_arr = iat_dict[key]\n",
    "    _ess_arr = ess_dict[key]\n",
    "    fig, ax = _plot_individual_acf_iat(_acf_arr, _iat_arr, _ess_arr, _figs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Topological charge history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, val in top_charges.items():\n",
    "    root_dir = figs_dir_dict[key]\n",
    "    fig_dir = os.path.join(root_dir, 'top_charges_figs')\n",
    "    check_else_make_dir(fig_dir)\n",
    "    for idx in range(val.shape[1]):\n",
    "        fig, ax = plt.subplots()\n",
    "        _ = ax.plot(val[:, idx], label=f'sample {idx}', \n",
    "                    color=COLORS[idx], marker=MARKERS[idx], fillstyle='none', \n",
    "                    ls=':', lw=0.75)\n",
    "        _ = ax.legend(loc='best')\n",
    "        out_file = os.path.join(fig_dir, \n",
    "                                f'top_charge_history_sample_{idx}.pdf')\n",
    "        print(f'Saving figure to: {out_file}.')\n",
    "        _ = plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Histograms for topological charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "for key, val in top_charges.items():\n",
    "    root_dir = figs_dir_dict[key]\n",
    "    fig_dir = os.path.join(root_dir, 'top_charges_histograms')\n",
    "    check_else_make_dir(fig_dir)\n",
    "    for idx in range(val.shape[1]):\n",
    "        fig, ax = plt.subplots()\n",
    "        # the trick is to set up the bins centered on the integers, i.e.\n",
    "        # -0.5, 0.5, 1,5, 2.5, ... up to max(data) + 1.5. \n",
    "        # Then you substract -0.5 to # eliminate the extra bin at the end.\n",
    "        bins = np.arange(val[:, idx].min(), val[:, idx].max() + 1.5) - 0.5\n",
    "        _ = ax.hist(\n",
    "            val[:, idx], \n",
    "            bins, \n",
    "            color=COLORS[idx], \n",
    "            label=f'sample {idx}'\n",
    "        )\n",
    "        _ = ax.set_xticks(bins + 0.5)\n",
    "        #ax.hist(val[:, idx])\n",
    "        _ = ax.legend(loc='best')\n",
    "        out_file = os.path.join(\n",
    "            fig_dir, \n",
    "            f'top_charge_history_sample_{idx}_histogram.pdf'\n",
    "        )\n",
    "        print(f'Saving figure to: {out_file}')\n",
    "        _ = plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def exp_fn(x, a, b, c, d):\n",
    "    return a * np.exp(-b * (x - c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fit_exp_linear(t, y, C=0):\n",
    "    y = y - C\n",
    "    y = np.log(y)\n",
    "    K, A_log = np.polyfit(t, y, 1)\n",
    "    A = np.exp(A_log)\n",
    "    return A, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def model_func(t, A, K, C):\n",
    "    return A * np.exp(K * t) + C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ydata = actions[200][:, 0]\n",
    "xdata = np.arange(len(ydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "A, K = fit_exp_linear(xdata, ydata, C=0)\n",
    "#fit_y = model_func(t, A, K, C0)\n",
    "plot(ax2, t, y, noisy_y, fit_y, (A0, K0, C0), (A, K, 0))\n",
    "ax2.set_title('Linear Fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(exp_fn, xdata, ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(xdata, exp_fn(xdata, *popt), ls='-',\n",
    "        label='fit: a=%5.3f, b=%5.3f, c=%5.3f, d=%5.3f' % tuple(popt))\n",
    "ax.plot(xdata, ydata, marker='o', ls='', label='Sample 0')\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('Total action')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Look at observables from samples generated during training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = '../../gauge_logs_graph/run_10/'\n",
    "train_observables_dicts = calc_training_observables(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_observables_dicts = calc_training_observables(log_dir, \n",
    "                                                    train_observables_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figs_axes = plot_training_observables(log_dir, train_observables_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#actions_dict, plaqs_dict, charges_dict = train_observables_dicts\n",
    "plot_top_charges_training(log_dir, train_observables_dicts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.gauge_observables import (\n",
    "    _load_samples_from_file, _load_params, _calc_observables,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'time_size': 8,\n",
    "    'space_size': 8,\n",
    "    'link_type': 'U1',\n",
    "    'dim': 2,\n",
    "    'beta': 1.,\n",
    "    'beta_init': 1.,\n",
    "    'beta_final': 8.,\n",
    "    'num_samples': 5,\n",
    "    'num_steps': 5,\n",
    "    'eps': 0.1,\n",
    "    'loss_scale': 0.1,\n",
    "    'loss_eps': 1e-4,\n",
    "    'learning_rate_init': 1e-3,\n",
    "    'learning_rate_decay_steps': 100,\n",
    "    'learning_rate_decay_rate': 0.98,\n",
    "    'train_steps': 10000,\n",
    "    'save_steps': 1000,\n",
    "    'logging_steps': 50,\n",
    "    'annealing_steps': 50,\n",
    "    'annealing_factor': 0.97,\n",
    "    'clip_value': 10.,\n",
    "    'rand': False,\n",
    "    'metric': 'euc2',\n",
    "    'training_samples_steps': 500,\n",
    "    'training_samples_length': 100\n",
    "}\n",
    "\n",
    "save_params_to_pkl_file(params, info_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = '../../gauge_logs_graph/run_63/'\n",
    "samples_dir = os.path.join(log_dir, 'samples_history/')\n",
    "train_samples_dir = os.path.join(samples_dir, 'training/')\n",
    "info_dir = os.path.join(log_dir, 'run_info/')\n",
    "\n",
    "params = {\n",
    "    'time_size': 8,\n",
    "    'space_size': 8,\n",
    "    'link_type': 'U1',\n",
    "    'dim': 2,\n",
    "    'beta': 1.,\n",
    "    'beta_init': 1.,\n",
    "    'beta_final': 8.,\n",
    "    'num_samples': 5,\n",
    "    'num_steps': 5,\n",
    "    'eps': 0.1,\n",
    "    'loss_scale': 0.1,\n",
    "    'loss_eps': 1e-4,\n",
    "    'learning_rate_init': 1e-4,\n",
    "    'learning_rate_decay_steps': 1000,\n",
    "    'learning_rate_decay_rate': 0.98,\n",
    "    'train_steps': 10000,\n",
    "    'save_steps': 1000,\n",
    "    'logging_steps': 50,\n",
    "    'annealing_steps': 100,\n",
    "    'annealing_factor': 0.97,\n",
    "    'clip_value': 10.,\n",
    "    'rand': False,\n",
    "    'metric': 'euc2',\n",
    "    'training_samples_steps': 500,\n",
    "    'training_samples_length': 100\n",
    "}\n",
    "\n",
    "save_params_to_pkl_file(params, info_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = '../../gauge_logs_graph/run_78/'\n",
    "samples_dir = os.path.join(log_dir, 'samples_history/')\n",
    "train_samples_dir = os.path.join(samples_dir, 'training/')\n",
    "info_dir = os.path.join(log_dir, 'run_info/')\n",
    "\n",
    "#save_params_to_pkl_file(params, info_dir)\n",
    "\n",
    "params = _load_params(log_dir)\n",
    "\n",
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "samples_dict, actions_dict, plaqs_dict, charges_dict = {}, {}, {}, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_samples_files = [train_samples_dir + i \n",
    "                       for i in os.listdir(train_samples_dir) \n",
    "                       if i.endswith('.pkl')]\n",
    "train_samples_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "step_keys = sorted(\n",
    "    [int(i.split('/')[-1].split('_')[2]) for i in train_samples_files]\n",
    ")\n",
    "step_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "training_figs_dir = os.path.join(figs_dir, 'training/')\n",
    "check_else_make_dir(training_figs_dir)\n",
    "training_steps_figs_dir = {}\n",
    "\n",
    "for key in step_keys:\n",
    "    _dir = os.path.join(training_figs_dir, f'{key}_train_steps/')\n",
    "    check_else_make_dir(_dir)\n",
    "    training_steps_figs_dir[key] = _dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx, sample_file in enumerate(train_samples_files):\n",
    "    step = step_keys[idx]\n",
    "    if step not in charges_dict.keys():\n",
    "        print(f\"Calculating observables for {step}...\")\n",
    "        with open(sample_file, 'rb') as f:\n",
    "            samples = pickle.load(f)\n",
    "\n",
    "        actions, plaqs, charges = _calc_observables(samples, params)\n",
    "\n",
    "        actions_dict[step] = actions\n",
    "        plaqs_dict[step] = plaqs\n",
    "        charges_dict[step] = charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key in charges_dict.keys():\n",
    "    actions = actions_dict[key]\n",
    "    plaqs = plaqs_dict[key]\n",
    "    charges = charges_dict[key]\n",
    "    observables = (actions, plaqs, charges)\n",
    "    \n",
    "    title_str = (r\"$\\beta =$\"\n",
    "                 + f\"{params['beta_final']}, {key} training steps\")\n",
    "    \n",
    "    kwargs = {\n",
    "        'figs_dir': training_steps_figs_dir[key],\n",
    "        'title': title_str\n",
    "    }\n",
    "    \n",
    "    figs_axes = make_multiple_lines_plots(\n",
    "        params['beta_final'],  \n",
    "        observables, \n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "for key, val in charges_dict.items():\n",
    "    for idx in range(val.shape[1]):\n",
    "        fig, ax = plt.subplots()\n",
    "        _ = ax.plot(val[:, idx], \n",
    "                    marker=MARKERS[idx], color=COLORS[idx], \n",
    "                    ls='', fillstyle='none', label=f'sample {idx}')\n",
    "        _ = ax.legend(loc='best')\n",
    "        _ = ax.set_xlabel('Step', fontsize=14)\n",
    "        _ = ax.set_ylabel('Topological charge', fontsize=14)\n",
    "        title_str = (r\"$\\beta =$\"\n",
    "                     + f\"{params['beta_final']}, {key} training steps\")\n",
    "        _ = ax.set_title(title_str, fontsize=16)\n",
    "        out_file = os.path.join(training_steps_figs_dir[key],\n",
    "                                f'topological_charge_history_sample_{idx}.pdf')\n",
    "        if not os.path.isfile(out_file):\n",
    "            print(f\"Saving figure to: {out_file}.\")\n",
    "            _ = fig.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "        \n",
    "        #_ = ax.set_title(fr\"\"\"$\\beta =$ {params['beta_final']},\"\"\"\n",
    "        #                 fr\"\"\" {key} training steps\"\"\")\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Modifying lattice structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from lattice.lattice import GaugeLattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice = GaugeLattice(8, 8, 2, 'U1', 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample = lattice.samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "links_arr = np.arange(lattice.num_links).reshape(sample.shape)\n",
    "sites_arr = np.arange(lattice.num_sites).reshape(lattice.sites.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sites_arr = np.array(lattice.num_sites * ['o']).reshape(lattice.sites.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(sites_arr)\n",
    "print(sites_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(links_arr.T)\n",
    "print(links_arr.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(links_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## OLD PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(311)\n",
    "_ = plt.plot(top_charges[100][:, 0], label=f'sample 1', color='C0', ls=':')\n",
    "             #markersize=2.5, marker=MARKERS[0], ls=':')\n",
    "_ = plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "\n",
    "# share x only\n",
    "_ = ax2 = plt.subplot(312, sharex=ax1)\n",
    "_ = plt.plot(top_charges[100][:, 1], label=f'sample 2', color='C1', ls=':')\n",
    "             #markersize=2.5, marker=MARKERS[1], ls=':')\n",
    "_ = plt.setp(ax2.get_xticklabels(), visible=False)\n",
    "\n",
    "_ = ax3 = plt.subplot(313, sharex=ax1)\n",
    "_ = plt.plot(top_charges[100][:, 2], label=f'sample 3', color='C2', ls=':')\n",
    "             #markersize=2.5, marker=MARKERS[2], ls=':')\n",
    "#_ = plt.setp(ax3.get_xticklabels(), visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MARKERS = ['o', 's', 'x', 'v', 'h', '^', 'p', '<', 'd', '>', 'o']\n",
    "LINESTYLES = ['-', '--', ':', '-.', '-', '--', ':', '-.', '-', '--']\n",
    "\n",
    "ax1 = plt.subplot(511)\n",
    "\n",
    "_ = plt.plot(top_charges[100][:, 0], label=f'sample 1', color='C0', ls=':')\n",
    "             #markersize=2.5, marker=MARKERS[0], ls=':')\n",
    "_ = plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "\n",
    "# share x only\n",
    "_ = ax2 = plt.subplot(512, sharex=ax1)\n",
    "_ = plt.plot(top_charges[100][:, 1], label=f'sample 2', color='C1', ls=':')\n",
    "             #markersize=2.5, marker=MARKERS[1], ls=':')\n",
    "_ = plt.setp(ax2.get_xticklabels(), visible=False)\n",
    "\n",
    "_ = ax3 = plt.subplot(513, sharex=ax1)\n",
    "_ = plt.plot(top_charges[100][:, 2], label=f'sample 3', color='C2', ls=':')\n",
    "             #markersize=2.5, marker=MARKERS[2], ls=':')\n",
    "_ = plt.setp(ax3.get_xticklabels(), visible=False)\n",
    "\n",
    "_ = ax4 = plt.subplot(514, sharex=ax1)\n",
    "_ = plt.plot(top_charges[100][:, 3], label=f'sample 4', color='C3', ls=':')\n",
    "             #markersize=2.5, marker=MARKERS[3], ls=':')\n",
    "_ = plt.setp(ax4.get_xticklabels(), visible=False)\n",
    "\n",
    "_ = ax5 = plt.subplot(515, sharex=ax1)\n",
    "_ = plt.plot(top_charges[100][:, 4], label=f'sample 5', color='C4', ls=':')\n",
    "             #markersize=2.5, marker=MARKERS[4], ls=':')\n",
    "_ = plt.setp(ax5.get_xticklabels(), visible=False)\n",
    "\n",
    "out_file = os.path.join(figs_dir_dict[100], 'top_charges_sharedx.pdf')\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     22,
     36
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create plots for observables.\n",
    "multiple_lines_figs_axes = make_multiple_lines_plots(\n",
    "    figs_dir,\n",
    "    params['beta'],\n",
    "    observables,\n",
    "    top_charges_autocorr,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Create plots for observables with broken x-axes.\n",
    "broken_xaxis_figs_axes = make_broken_xaxis_plots(\n",
    "    figs_dir,\n",
    "    params['beta'],\n",
    "    observables,\n",
    "    top_charges_autocorr,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Plot lag k autocorrelation function of topological charge\n",
    "# Plot topological charges autocorrelation function using the \n",
    "# built-in `pandas.plotting.autocorrelation_plot` method.\n",
    "for idx in range(top_charges.shape[1]):\n",
    "    out_file = os.path.join(\n",
    "        pandas_autocorr_dir, \n",
    "        f'top_charges_autocorr_pandas_{idx}.pdf'\n",
    "    )\n",
    "    fig, ax = make_pandas_autocorrelation_plot(\n",
    "        top_charges[:, idx],\n",
    "        x_label='Lag',\n",
    "        y_label='Autocorrelation (top. charge)',\n",
    "        out_file=out_file\n",
    "    )\n",
    "    \n",
    "# Plot topological charges autocorrelation function using the \n",
    "# built-in matplotlib `acorr` method.\n",
    "for idx in range(top_charges.shape[1]):\n",
    "    out_file = os.path.join(\n",
    "        matplotlib_autocorr_dir, \n",
    "        f'top_charges_autocorr_matplotlib_{idx}.pdf'\n",
    "    )\n",
    "    kwargs = {'x_label': 'Lag',\n",
    "              'y_label': 'Autocorrelation (top. charge)',\n",
    "              'label': f'sample {idx}',\n",
    "              'out_file': out_file,\n",
    "              'color': COLORS[idx]}\n",
    "    output = make_matplotlib_autocorrelation_plot(\n",
    "        top_charges[:, idx],\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "# Compute and plot the samples autocorrelation spectrum.\n",
    "# This is done by computing the autocorrelation function of each \n",
    "# individual link and then averaging over all links in the sample.\n",
    "out_file = os.path.join(figs_dir, 'links_autocorrelation_vs_step.pdf')\n",
    "fig, ax = make_samples_acl_spectrum_plot(samples, out_file=out_file)\n",
    "\n",
    "    \n",
    "# Compute the integrated autocorrelation time (IAT) \n",
    "# from top. charges data using `tau` from `utils/gauge_observables`\n",
    "out_file = os.path.join(figs_dir, 'integrated_autocorrelation_time_plot.pdf')\n",
    "kwargs = {\n",
    "    'x_label': 'Lag',\n",
    "    'y_label': 'Autocorrelation (top. charge)',\n",
    "    'legend': True,\n",
    "    'out_file': out_file\n",
    "}\n",
    "fig, ax = plot_autocorr_with_iat(acf_arr, iat_arr, ESS_arr, **kwargs)\n",
    "#fig, ax = calc_integrated_autocorr_time_with_plots(top_charges, **kwargs)\n",
    "#_ = ax.legend(bbox_to_anchor=(1, 0), loc=\"lower left\",\n",
    "#              bbox_transform=ax.transAxes, columnspacing=0.5, ncol=1)\n",
    "#print(f\"Saving figure to: {out_file}\")\n",
    "#plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create plots for observables.\n",
    "\n",
    "multiple_lines_figs_axes = make_multiple_lines_plots(\n",
    "    figs_dir,\n",
    "    params['beta'],\n",
    "    observables,\n",
    "    top_charges_autocorr,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Create plots for observables with broken x-axes.\n",
    "broken_xaxis_figs_axes = make_broken_xaxis_plots(\n",
    "    figs_dir,\n",
    "    params['beta'],\n",
    "    observables,\n",
    "    top_charges_autocorr,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Plot lag k autocorrelation function of topological charge\n",
    "# Plot topological charges autocorrelation function using the \n",
    "# built-in `pandas.plotting.autocorrelation_plot` method.\n",
    "for idx in range(top_charges.shape[1]):\n",
    "    out_file = os.path.join(\n",
    "        pandas_autocorr_dir, \n",
    "        f'top_charges_autocorr_pandas_{idx}.pdf'\n",
    "    )\n",
    "    fig, ax = make_pandas_autocorrelation_plot(\n",
    "        top_charges[:, idx],\n",
    "        x_label='Lag',\n",
    "        y_label='Autocorrelation (top. charge)',\n",
    "        out_file=out_file\n",
    "    )\n",
    "    \n",
    "# Plot topological charges autocorrelation function using the \n",
    "# built-in matplotlib `acorr` method.\n",
    "for idx in range(top_charges.shape[1]):\n",
    "    out_file = os.path.join(\n",
    "        matplotlib_autocorr_dir, \n",
    "        f'top_charges_autocorr_matplotlib_{idx}.pdf'\n",
    "    )\n",
    "    kwargs = {'x_label': 'Lag',\n",
    "              'y_label': 'Autocorrelation (top. charge)',\n",
    "              'label': f'sample {idx}',\n",
    "              'out_file': out_file,\n",
    "              'color': COLORS[idx]}\n",
    "    output = make_matplotlib_autocorrelation_plot(\n",
    "        top_charges[:, idx],\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "# Compute and plot the samples autocorrelation spectrum.\n",
    "# This is done by computing the autocorrelation function of each \n",
    "# individual link and then averaging over all links in the sample.\n",
    "out_file = os.path.join(figs_dir, 'links_autocorrelation_vs_step.pdf')\n",
    "fig, ax = make_samples_acl_spectrum_plot(samples, out_file=out_file)\n",
    "\n",
    "# Compute the integrated autocorrelation time (IAT) \n",
    "# from top. charges data using `tau` from `utils/gauge_observables`\n",
    "out_file = os.path.join(figs_dir, 'integrated_autocorrelation_time_plot.pdf')\n",
    "kwargs = {\n",
    "    'x_label': 'Lag',\n",
    "    'y_label': 'Autocorrelation (top. charge)',\n",
    "    'legend': True,\n",
    "    'out_file': out_file\n",
    "}\n",
    "fig, ax = plot_autocorr_with_iat(acf_arr, iat_arr, ESS_arr, **kwargs)\n",
    "#fig, ax = calc_integrated_autocorr_time_with_plots(top_charges, **kwargs)\n",
    "#_ = ax.legend(bbox_to_anchor=(1, 0), loc=\"lower left\",\n",
    "#              bbox_transform=ax.transAxes, columnspacing=0.5, ncol=1)\n",
    "#print(f\"Saving figure to: {out_file}\")\n",
    "#plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, 'integrated_autocorrelation_time_plot.pdf')\n",
    "kwargs = {\n",
    "    'x_label': 'Lag',\n",
    "    'y_label': 'Autocorrelation (top. charge)',\n",
    "    'legend': True,\n",
    "    'out_file': out_file\n",
    "}\n",
    "fig, ax = plot_autocorr_with_iat(acf_arr, iat_arr, ESS_arr, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(ESS_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alphas = [0.3, 0.275, 0.25, 0.225, 0.2, 0.175, \n",
    "          0.15, 0.125, 0.1, 0.075, 0.05, 0.025][::-1]\n",
    "out_file = os.path.join(matplotlib_autocorr_dir, \n",
    "                        'top_charges_autocorr_matplotlib.pdf')\n",
    "fig, ax = plt.subplots()\n",
    "for idx in range(top_charges.shape[1]):\n",
    "    output = ax.acorr(top_charges[:, idx], usevlines=True, color=COLORS[idx],\n",
    "                      normed=True, maxlags=None,\n",
    "                      alpha=alphas[idx]+0.4, #zorder=zorders[idx],\n",
    "                      label=f'sample {idx}')\n",
    "\n",
    "_ = ax.axhline(0, color='r', lw=2)\n",
    "_ = ax.grid(True)\n",
    "_ = ax.legend(loc='best')\n",
    "    \n",
    "_ = ax.set_xlabel(\"Lag\", fontsize=14)\n",
    "_ = ax.set_ylabel(\"Autocorrelation (top. charge)\", fontsize=14)\n",
    "print(f'Saving figure to: {out_file}.')\n",
    "_ = plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice = GaugeLattice(8, 8, 2, 8., 'U1', 5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.num_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Old approach (unsure of validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len_by_4 = len(top_charges) // 4\n",
    "len_by_2 = len(top_charges) // 2\n",
    "len_by_10 = len(top_charges) // 10\n",
    "kappa4 = len(top_charges) - len_by_4\n",
    "kappa2 = len(top_charges) - len_by_2\n",
    "kappa10 = len(top_charges) - len_by_10\n",
    "iac2, autocorr2 = calc_iat(top_charges.mean(axis=1), kappa=kappa2)\n",
    "iac4, autocorr4 = calc_iat(top_charges.mean(axis=1), kappa=kappa4)\n",
    "iac10, autocorr10 = calc_iat(top_charges.mean(axis=1), kappa=kappa10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iac2, iac4, iac10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(autocorr_dir, \n",
    "                        f'integrated_autocorrelation_time_plot_{kappa2}.pdf')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(np.arange(len(autocorr2)), autocorr2, ls='-')\n",
    "_ = ax.set_xlabel('Lag', fontsize=14)\n",
    "_ = ax.set_ylabel('Autocorrelation (top. charge)', fontsize=14)\n",
    "_ = ax.set_title(f'Integrated autocorrelation time (IAC): {iac2:6.4g}')\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, \n",
    "                        f'integrated_autocorrelation_time_plot_{kappa4}.pdf')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(np.arange(len(autocorr4)), autocorr4, ls='-')\n",
    "_ = ax.set_xlabel('Lag', fontsize=14)\n",
    "_ = ax.set_ylabel('Autocorrelation (top. charge)', fontsize=14)\n",
    "_ = ax.set_title(f'Integrated autocorrelation time (IAC): {iac4:6.4g}')\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, \n",
    "                        f'integrated_autocorrelation_time_plot_{kappa10}.pdf')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(np.arange(len(autocorr10)), autocorr10, ls='-')\n",
    "_ = ax.set_xlabel('Lag', fontsize=14)\n",
    "_ = ax.set_ylabel('Autocorrelation (top. charge)', fontsize=14)\n",
    "_ = ax.set_title(f'Integrated autocorrelation time (IAC): {iac10:6.4g}')\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Old method (make each plot by hand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Specify run directory containing parameters and samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = '../../gauge_logs_graph/run_2/'\n",
    "info_dir = os.path.join(log_dir, 'run_info')\n",
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "params_file = os.path.join(info_dir, 'parameters.pkl')\n",
    "with open(params_file, 'rb') as f:\n",
    "    params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create lattice with same parameters to use for calculating observables\n",
    "lattice = GaugeLattice(params['time_size'],\n",
    "                       params['space_size'],\n",
    "                       params['dim'],\n",
    "                       params['beta'],\n",
    "                       params['link_type'],\n",
    "                       params['num_samples'],\n",
    "                       params['rand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load samples from `info_dir/samples_history.pkl` file\n",
    "# Note that samples_history will be an array of shape:\n",
    "#    [num_samples, num_eval_steps]\n",
    "# where num_samples is the number of samples in each batch\n",
    "# and num_eval steps is the number of steps the (trained) L2HMC simulation \n",
    "# was ran for.\n",
    "samples_history_file = os.path.join(info_dir, 'samples_history.pkl')\n",
    "with open(samples_history_file, 'rb') as f:\n",
    "    samples_history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.array(samples_history).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Iterate over samples history and calculate observables for each sample.\n",
    "# `lattice.calc_plaq_observables(samples)` calculates observables for each of\n",
    "# the samples in the mini-batch.\n",
    "actions_history = []\n",
    "avg_plaquettes_history = []\n",
    "top_charges_history = []\n",
    "for idx, samples in enumerate(samples_history):\n",
    "    t0 = time.time()\n",
    "    observables = np.array(lattice.calc_plaq_observables(samples))\n",
    "    actions, plaqs, charges = observables\n",
    "    \n",
    "    actions_history.append(actions)\n",
    "    avg_plaquettes_history.append(plaqs)\n",
    "    top_charges_history.append(charges)\n",
    "    \n",
    "    print(f'step: {idx}  '\n",
    "          f'time / step: {time.time() - t0:^6.4g}  '\n",
    "          f'avg action: {np.mean(actions):^6.4g}  '\n",
    "          f'avg plaquette: {np.mean(plaqs):^6.4g} '\n",
    "          f'top charge: {np.mean(charges):^6.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_history = np.array(samples_history)\n",
    "actions_history = np.array(actions_history)\n",
    "avg_plaquettes_history = np.array(avg_plaquettes_history)\n",
    "top_charges_history = np.array(top_charges_history)\n",
    "steps = np.arange(len(actions_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(samples_history[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compute the autocorrelation function using the topological charges\n",
    "top_charges_autocorr_arr = []\n",
    "num_samples = top_charges_history.shape[1]\n",
    "for i in range(num_samples):\n",
    "    top_charges_autocorr_arr.append(autocorr(top_charges_history[:, i]))\n",
    "top_charges_autocorr_arr = np.array(top_charges_autocorr_arr)\n",
    "top_charges_autocorr_avg = np.mean(top_charges_autocorr_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_charges_autocorr_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_charges_autocorr_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_history = np.array(samples_history)\n",
    "_shape = samples_history.shape\n",
    "samples_history = samples_history.reshape(_shape[0], _shape[1], -1)\n",
    "num_samples = samples_history.shape[1]\n",
    "num_links  = samples_history.shape[-1]\n",
    "samples_autocorr_arr = []\n",
    "for n in range(num_samples):\n",
    "    links_autocorr_arr = []\n",
    "    for l in range(num_links):\n",
    "        links_autocorr_arr.append(autocorr(samples_history[:, n, l]))\n",
    "    samples_autocorr_arr.append(links_autocorr_arr)\n",
    "samples_autocorr_arr = np.array(samples_autocorr_arr)\n",
    "samples_autocorr_arr_avg = samples_autocorr_arr.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_autocorr_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_autocorr_arr_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, 'topological_charge_autocorr_fn.pdf')\n",
    "fig, ax = plot_multiple_lines(steps, top_charges_autocorr_arr,\n",
    "                              x_label='step', \n",
    "                              y_label='Autocorrelation (top. charge)',\n",
    "                              legend=True,\n",
    "                              out_file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, \n",
    "                        'topological_charge_autocorr_fn_broken_xaxis.pdf')\n",
    "fig, ax, ax2 = plot_broken_xaxis(steps, top_charges_autocorr_arr.T,\n",
    "                                 xlabel='step',\n",
    "                                 ylabel='Autocorrelation (top. charge)',\n",
    "                                 #xlim1=(-2, 50), xlim2=(395, 500),\n",
    "                                 output_file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, 'topological_charge_vs_step.pdf')\n",
    "fig, ax = plot_multiple_lines(steps, top_charges_history.T,\n",
    "                              x_label='step', y_label='Topological charge',\n",
    "                              out_file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, \n",
    "                        'topological_charge_vs_step_broken_xaxis.pdf')\n",
    "fig, ax, ax2 = plot_broken_xaxis(steps, top_charges_history,\n",
    "                                 xlabel='step', ylabel='Topological charge',\n",
    "                                 xlim1=(-2, 100), xlim2=(895, 1000),\n",
    "                                 output_file=None)\n",
    "ax2.legend(loc='lower right')\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from lattice.gauge_lattice import u1_plaq_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, 'average_plaquette_vs_step.pdf')\n",
    "fig, ax = plot_multiple_lines(steps, avg_plaquettes_history.T,\n",
    "                              x_label='step', y_label='Average plaquette')\n",
    "_ = ax.axhline(y=u1_plaq_exact(params['beta']), \n",
    "           color='r', ls='--', lw=2.5, label='exact')\n",
    "fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, 'average_plaquette_vs_step_broken_xaxis.pdf')\n",
    "fig, ax, ax2 = plot_broken_xaxis(steps, avg_plaquettes_history,\n",
    "                                 xlabel='step', ylabel='Average plaquette',\n",
    "                                 xlim1=(-2, 65), xlim2=(895, 1000),\n",
    "                                 output_file=None)\n",
    "\n",
    "_ = ax.axhline(y=u1_plaq_exact(params['beta']), \n",
    "           color='r', ls='--', lw=2.5, label='exact')\n",
    "\n",
    "_ = ax2.axhline(y=u1_plaq_exact(params['beta']), \n",
    "                color='r', ls='--', lw=2.5, label='exact')\n",
    "leg = ax2.legend(loc='lower right', fontsize=10)\n",
    "\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, 'average_action_vs_step.pdf')\n",
    "fig, ax = plot_multiple_lines(steps, actions_history.T,\n",
    "                              x_label='step', y_label='Average plaquette')\n",
    "fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, 'average_action_vs_step_broken_xaxis.pdf')\n",
    "fig, ax, ax2 = plot_broken_xaxis(steps, actions_history,\n",
    "                                 xlabel='step', ylabel='Total action',\n",
    "                                 xlim1=(-2, 55), xlim2=(895, 1000),\n",
    "                                 output_file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_acl_spectrum = acl_spectrum(samples_history, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_acl_spectrum = acl_spectrum(samples_history, scale=1)\n",
    "acl_steps = np.arange(len(samples_acl_spectrum))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(acl_steps, samples_acl_spectrum/samples_acl_spectrum[0])\n",
    "ax.set_xlabel('step', fontsize=14)\n",
    "ax.set_ylabel('Autocorrelation (avg. over links)', fontsize=14)\n",
    "plt.savefig(os.path.join(figs_dir, 'links_autocorrelation_vs_step.pdf'),\n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.gauge_observables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_dir = '../../gauge_logs_graph/run_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "params, samples, observables = calc_observables_from_log_dir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "actions, avg_plaquettes, top_charges = observables\n",
    "\n",
    "beta = params['beta']\n",
    "figs_dir = os.path.join(log_dir, 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_charges_autocorr, _ = calc_top_charges_autocorr(top_charges)\n",
    "samples_autocorr, _ = calc_samples_autocorr(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from utils.gauge_observables import _make_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multiple_lines_figs_axes, broken_xaxis_figs_axes = _make_plots(\n",
    "    figs_dir, \n",
    "    beta, \n",
    "    samples, \n",
    "    observables,\n",
    "    top_charges_autocorr, \n",
    "    samples_autocorr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "make_plots_from_log_dir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Compare Sample Autocorrelation across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_dir = '../../gauge_logs_graph/'\n",
    "dirs = [\n",
    "    os.path.join(_dir, i) for i in os.listdir(_dir) if i .startswith('run')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_dict = {}\n",
    "params_dict = {}\n",
    "lattice_dict = {}\n",
    "for d in dirs:\n",
    "    key = d.split('/')[-1]\n",
    "    info_dir = os.path.join(d, 'run_info')\n",
    "    samples_file = os.path.join(info_dir, 'samples_history.pkl')\n",
    "    parameters_file = os.path.join(info_dir, 'parameters.pkl')\n",
    "    try:\n",
    "        with open(samples_file, 'rb') as f:\n",
    "            samples_dict[key] = pickle.load(f)\n",
    "        with open(parameters_file, 'rb') as f:\n",
    "            params_dict[key] = pickle.load(f)\n",
    "        lattice_dict[key] = GaugeLattice(time_size=params['time_size'],\n",
    "                                         space_size=params['space_size'],\n",
    "                                         dim=params['dim'],\n",
    "                                         beta=params['beta'],\n",
    "                                         link_type=params['link_type'],\n",
    "                                         num_samples=params['num_samples'],\n",
    "                                         rand=params['rand'])\n",
    "    except FileNotFoundError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_autocorr_dict = {}\n",
    "samples_autocorr_avg_dict = {}\n",
    "samples_acl_spectrum_dict = {}\n",
    "for key, samples_history in samples_dict.items():\n",
    "    samples_history = np.array(samples_history)\n",
    "    _shape = samples_history.shape\n",
    "    samples_history = samples_history.reshape(_shape[0], _shape[1], -1)\n",
    "    num_samples = samples_history.shape[1]\n",
    "    num_links  = samples_history.shape[-1]\n",
    "    samples_autocorr_arr = []\n",
    "    for n in range(num_samples):\n",
    "        links_autocorr_arr = []\n",
    "        for l in range(num_links):\n",
    "            links_autocorr_arr.append(autocorr(samples_history[:, n, l]))\n",
    "        samples_autocorr_arr.append(links_autocorr_arr)\n",
    "    samples_autocorr_arr = np.array(samples_autocorr_arr)\n",
    "    samples_autocorr_arr_avg = samples_autocorr_arr.mean(axis=1)\n",
    "    samples_autocorr_dict[key] = samples_autocorr_arr\n",
    "    samples_autocorr_avg_dict[key] = samples_autocorr_arr_avg\n",
    "    samples_acl_spectrum_dict[key] = acl_spectrum(samples_history, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_autocorr_avg_dict['run_37'].mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for key, samples_autocorr_avg in samples_autocorr_avg_dict.items():\n",
    "    autocorr_avg_over_samples = samples_autocorr_avg.mean(axis=0)\n",
    "    steps = np.arange(len(autocorr_avg_over_samples))\n",
    "    _ = ax.plot(steps, autocorr_avg_over_samples, label=f'{key}')\n",
    "_ = ax.set_xlabel('step', fontsize=14)\n",
    "_ = ax.set_ylabel('Autocorrelation (avg. over links)', fontsize=14)\n",
    "_ = ax.legend(loc='best')\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for key, samples_acl_spectrum in samples_acl_spectrum_dict.items():\n",
    "    acl_steps = np.arange(len(samples_acl_spectrum))\n",
    "    _ = ax.plot(acl_steps, samples_acl_spectrum/samples_acl_spectrum[0], \n",
    "                label=f'{key}')\n",
    "_ = ax.set_xlabel('step', fontsize=14)\n",
    "_ = ax.set_ylabel('Autocorrelation (avg. over links)', fontsize=14)\n",
    "_ = ax.legend(loc='best')\n",
    "#plt.savefig(os.path.join(figs_dir, 'links_autocorrelation_vs_step.pdf'),\n",
    "#            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, 'samples_acl_spectrum.pdf')\n",
    "fig, ax = plot_multiple_lines(x_data=steps, \n",
    "                              y_data=samples_autocorr_arr[0, 0:20],\n",
    "                              x_label='step',\n",
    "                              y_label='Autocorrelation (links)',\n",
    "                              legend=False,\n",
    "                              out_file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out_file = os.path.join(figs_dir, 'samples_acl_spectrum_avg.pdf')\n",
    "fig, ax = plot_multiple_lines(x_data=steps,\n",
    "                              y_data=samples_autocorr_arr_avg,\n",
    "                              x_label='step',\n",
    "                              y_label='Autocorrelation (avg. over links)',\n",
    "                              semilogy=False,\n",
    "                              legend=True,\n",
    "                              out_file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.InteractiveSession.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.Session().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice = GaugeLattice(8, 8, 2, 8., 'U1', 2, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples = tf.convert_to_tensor(lattice.samples, dtype=tf.float32)\n",
    "potential_fn = lattice.get_energy_function(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dynamics = gde.GaugeDynamicsEager(\n",
    "    lattice=lattice,\n",
    "    num_steps=5,\n",
    "    eps=0.1,\n",
    "    minus_loglikelihood_fn=potential_fn,\n",
    "    conv_net=True,\n",
    "    hmc=False,\n",
    "    eps_trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset = tf.data.Dataset.range(100).map(\n",
    "    lambda x: x + tf.random_uniform([], -10, 10, tf.int64))\n",
    "validation_dataset = tf.data.Dataset.range(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# A reinitializable iterator is defined by its structure. We could use the\n",
    "# `output_types` and `output_shapes` properties of either `training_dataset`\n",
    "# or `validation_dataset` here, because they are compatible.\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,\n",
    "                                           training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run 20 epochs in which the training dataset is traversed, followed by the\n",
    "# validation dataset.\n",
    "for _ in range(20):\n",
    "  # Initialize an iterator over the training dataset.\n",
    "  sess.run(training_init_op)\n",
    "  for _ in range(10):\n",
    "    sess.run(next_element)\n",
    "\n",
    "  # Initialize an iterator over the validation dataset.\n",
    "  sess.run(validation_init_op)\n",
    "  for _ in range(5):\n",
    "    sess.run(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(5)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# Typically `result` will be the output of a model, or an optimizer's\n",
    "# training operation.\n",
    "result = tf.add(next_element, next_element)\n",
    "\n",
    "sess.run(iterator.initializer)\n",
    "print(sess.run(result))  # ==> \"0\"\n",
    "print(sess.run(result))  # ==> \"2\"\n",
    "print(sess.run(result))  # ==> \"4\"\n",
    "print(sess.run(result))  # ==> \"6\"\n",
    "print(sess.run(result))  # ==> \"8\"\n",
    "try:\n",
    "  sess.run(result)\n",
    "except tf.errors.OutOfRangeError:\n",
    "  print(\"End of dataset\")  # ==> \"End of dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_placeholder = tf.placeholder(samples.dtype, samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(samples_placeholder).batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(dynamics.apply_transition(samples_placeholder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset.apply(dynamics.apply_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sess.run(iterator.initializer, feed_dict={samples_placeholder: samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset = tf.data.Dataset.range(max_value)    # Take a placeholder to create a dataset\n",
    "iterator = dataset.make_initializable_iterator()      # Create an initializable iterator\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize an iterator over a dataset with 10 elements using placeholder.\n",
    "    sess.run(iterator.initializer, feed_dict={max_value: 10}) \n",
    "\n",
    "    for i in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value} \", end=\" \")    # 0 1 2 3 ... 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensors(samples_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset.apply(dynamics.apply_transition)\n",
    "dataset = dataset.map(dynamics.apply_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sess.run(iterator.initializer, \n",
    "         feed_dict={samples_placeholder: lattice.samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = dynamics.apply_transition(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sess.run(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result = dynamics.apply_transition(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# Typically `result` will be the output of a model, or an optimizer's\n",
    "# training operation.\n",
    "result = tf.add(next_element, next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features_placeholder = tf.placeholder(features.dtype, features.shape)\n",
    "labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "# [Other transformations on `dataset`...]\n",
    "dataset = ...\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "sess.run(iterator.initializer, feed_dict={features_placeholder: features,\n",
    "                                          labels_placeholder: labels})"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
