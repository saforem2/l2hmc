{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gauge Observables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------\n",
    "### TODO:\n",
    "* [x] Generate multiple chain lengths and deal with loading in from multiple `samples_history` files.\n",
    "* [x] Implement the same logic for `observables` as for `samples_history`.\n",
    "* [x] Modify remainder of code below to deal with case where `samples` and `observables` are dictionaries with keys specifying the length of the MCMC chain.\n",
    "* [x] Re-run the cells below for the remainder of `HMC` directory to get ESS values for comparing against ESS from L2HMC.\n",
    "* [x] Try training sampler for >> 1000 steps and running the trained sampler for a variety of different chain lengths to see what the integrated autocorrelation time approaches as  $N_{steps} \\longrightarrow \\infty$.\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from scipy.special import i0, i1\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "COLORS = 5 * ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9']\n",
    "MARKERS = 5 * ['o', 's', 'x', 'v', 'h', '^', 'p', '<', 'd', '>', 'P', 'D']\n",
    "LINESTYLES = ['-', '--', ':', '-.', '-', '--', ':', '-.', '-', '--']\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.file_io as io\n",
    "from lattice.lattice import GaugeLattice, u1_plaq_exact\n",
    "#from l2hmc_eager import gauge_dynamics_eager as gde\n",
    "from gauge_model import GaugeModel\n",
    "from utils.file_io import save_params_to_pkl_file\n",
    "from utils.observables import Observables\n",
    "\n",
    "import utils.gauge_model_helpers as helpers\n",
    "from utils.autocorr import *\n",
    "from utils.gauge_observables import *\n",
    "from utils.data_utils import (\n",
    "    calc_avg_vals_errors, block_resampling, jackknife_err\n",
    ")\n",
    "\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_else_make_dir(d):\n",
    "    if not os.path.isdir(d):\n",
    "        print(f\"Making directory: {d}\")\n",
    "        os.makedirs(d)\n",
    "        \n",
    "def plot_individual_observables(figs_dir, observables, top_charges_autocorr):\n",
    "    multiple_lines_figs_axes = make_multiple_lines_plots(\n",
    "        figs_dir,\n",
    "        params['beta_final'],\n",
    "        observables,\n",
    "        top_charges_autocorr,\n",
    "        legend=False\n",
    "    )\n",
    "    return multiple_lines_figs_axes\n",
    "\n",
    "def plot_individual_acf_iat(acf_arr, iat_arr, ess_arr, figs_dir):\n",
    "    out_file = os.path.join(\n",
    "        figs_dir, \n",
    "        'integrated_autocorrelation_time_plot.pdf'\n",
    "    )\n",
    "    kwargs = {\n",
    "        'x_label': 'Lag',\n",
    "        'y_label': 'Autocorrelation (top. charge)',\n",
    "        'legend': True,\n",
    "        'out_file': out_file\n",
    "    }\n",
    "    fig, ax = plot_autocorr_with_iat(acf_arr, iat_arr, ess_arr, **kwargs)\n",
    "    \n",
    "    return fig, ax\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observables analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stats_and_observables(d):\n",
    "    \"\"\"Load actions, plaqs. and top. charges from `.pkl` files in dir `d`.\"\"\"\n",
    "    actions_file = [\n",
    "        os.path.join(d, i) for i in os.listdir(d) \n",
    "        if i.startswith('actions_steps') and i.endswith('.pkl')\n",
    "    ]\n",
    "    plaqs_file = [\n",
    "        os.path.join(d, i) for i in os.listdir(d) \n",
    "        if i.startswith('plaqs_steps') and i.endswith('.pkl')\n",
    "    ]\n",
    "    charges_file = [\n",
    "        os.path.join(d, i) for i in os.listdir(d) \n",
    "        if i.startswith('charges_steps') and i.endswith('.pkl')\n",
    "    ]\n",
    "    tun_events_file = [\n",
    "        os.path.join(d, i) for i in os.listdir(d)\n",
    "        if i.startswith('charge_diff') and i.endswith('.pkl')\n",
    "    ]\n",
    "    with open(actions_file[0], 'rb') as f:\n",
    "        actions_dict = pickle.load(f)\n",
    "    with open(plaqs_file[0], 'rb') as f:\n",
    "        plaqs_dict = pickle.load(f)\n",
    "    with open(charges_file[0], 'rb') as f:\n",
    "        charges_dict = pickle.load(f)\n",
    "    with open(tun_events_file[0], 'rb') as f:\n",
    "        tun_events = pickle.load(f)\n",
    "        \n",
    "    return actions_dict, plaqs_dict, charges_dict, tun_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_observables(steps_arr, observables, train=False):\n",
    "    actions_arr, plaqs_arr, charges_arr = observables\n",
    "    ######################\n",
    "    # Total actions plots\n",
    "    ######################\n",
    "    if train:\n",
    "        key = 'train'\n",
    "    else:\n",
    "        key = 'eval'\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 f\"{beta}, {len(steps_arr)} {key} steps\")\n",
    "    kwargs = {\n",
    "        'out_file': None,\n",
    "        'markers': False,\n",
    "        'lines': True,\n",
    "        'alpha': 0.6,\n",
    "        'title': title_str,\n",
    "        'legend': False,\n",
    "        'ret': False,\n",
    "    }\n",
    "    plot_multiple_lines(steps_arr, actions_arr.T,  x_label='Step', \n",
    "                        y_label='Total action', **kwargs)\n",
    "\n",
    "    ###########################\n",
    "    # Average plaquettes plots\n",
    "    ###########################\n",
    "    kwargs['ret'] = True\n",
    "    _, ax = plot_multiple_lines(steps_arr, plaqs_arr.T, x_label='Step',\n",
    "                                y_label='Avg. plaquette', **kwargs)\n",
    "\n",
    "    _ = ax.axhline(y=u1_plaq_exact(beta),\n",
    "                   color='#CC0033', ls='-', lw=2.5, label='exact')\n",
    "\n",
    "    _ = ax.plot(steps_arr, plaqs_arr.T.mean(axis=0),\n",
    "                color='k', label='average', alpha=0.75)\n",
    "\n",
    "\n",
    "    ############################\n",
    "    # Topological charge plots\n",
    "    ############################\n",
    "    kwargs['markers'] = True\n",
    "    kwargs['lines'] = False\n",
    "    kwargs['alpha'] = 1.\n",
    "    kwargs['ret'] = False\n",
    "    plot_multiple_lines(steps_arr, charges_arr.T, x_label='Step',\n",
    "                        y_label='Topological charge', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_charge_probs(charges_arr, beta, params, out_dir=None, training=False):\n",
    "    if training:\n",
    "        key = 'train'\n",
    "    else:\n",
    "        key = 'eval'\n",
    "        \n",
    "    num_samples = params['num_samples']\n",
    "    charges = np.array(charges_arr, dtype=int)\n",
    "    _run_steps = charges.shape[0]\n",
    "\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 f\"{beta}, {_run_steps} {key} steps\")\n",
    "    # if we have more than 5 samples per batch, only plot first 5\n",
    "    for idx in range(5):\n",
    "        counts = Counter(charges[:, idx])\n",
    "        total_counts = np.sum(list(counts.values()))\n",
    "        _, ax = plt.subplots()\n",
    "        ax.plot(list(counts.keys()),\n",
    "                np.array(list(counts.values()) / total_counts),\n",
    "                marker=MARKERS[idx],\n",
    "                color=COLORS[idx],\n",
    "                ls='',\n",
    "                label=f'sample {idx}')\n",
    "        _ = ax.legend(loc='best')\n",
    "        _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "        _ = ax.set_ylabel('Probability', fontsize=14)\n",
    "        _ = ax.set_title(title_str, fontsize=16)\n",
    "        if out_dir is not None:\n",
    "            out_file = os.path.join(out_dir,\n",
    "                                    f'top_charge_prob_vs_val_{idx}.png')\n",
    "            io.log(f'Saving figure to: {out_file}.')\n",
    "            _ = plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "        #plt.close('all')\n",
    "\n",
    "    all_counts = Counter(list(charges.flatten()))\n",
    "    total_counts = np.sum(list(counts.values()))\n",
    "    _, ax = plt.subplots()\n",
    "    ax.plot(list(all_counts.keys()),\n",
    "            np.array(list(all_counts.values()) / (total_counts * num_samples)),\n",
    "            marker='o',\n",
    "            color='C0',\n",
    "            ls='',\n",
    "            alpha=0.6,\n",
    "            label=f\"total across {num_samples} samples\");\n",
    "    _ = ax.legend(loc='best')\n",
    "    _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "    _ = ax.set_ylabel('Probability', fontsize=14)\n",
    "    _ = ax.set_title(title_str, fontsize=16)\n",
    "    if out_dir is not None:\n",
    "        out_file = os.path.join(out_dir,\n",
    "                                f'TOP_CHARGE_FREQUENCY_VS_VAL_TOTAL.png')\n",
    "        io.log(f'Saving figure to: {out_file}.')\n",
    "        _ = plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "    #plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define log_dir and traverse directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'../../conv3D_logs/lattice_88/lr5e-4/fourier_approx/run_9/'\n",
    "#'../../conv3D_logs/lattice_1616/fourier_approx/run_1/'\n",
    "log_dir = os.path.join('..', '..', 'conv3D_logs', 'HMC',\n",
    "                       'run_L8_7')\n",
    "info_dir = os.path.join(log_dir, 'run_info')\n",
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "eval_dir = os.path.join(log_dir, 'eval_info')\n",
    "obs_dir = os.path.join(eval_dir, 'observables')\n",
    "training_obs_dir = os.path.join(obs_dir, 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_file = os.path.join(info_dir, 'parameters.pkl')\n",
    "with open(params_file, 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "for key, val in params.items():\n",
    "    print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dirs = [\n",
    "    os.path.join(obs_dir, i) for i in os.listdir(obs_dir) if 'steps' in i\n",
    "]\n",
    "try:\n",
    "    training_obs_dirs = [\n",
    "        os.path.join(training_obs_dir, i) for i in os.listdir(training_obs_dir)\n",
    "    ]\n",
    "except FileNotFoundError:\n",
    "    training_obs_dirs = None\n",
    "    pass\n",
    "obs_dirs\n",
    "training_obs_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = [int(i.split('/')[-1].split('_')[1]) for i in obs_dirs]\n",
    "betas = [float(i.split('/')[-1].split('_')[-1]) for i in obs_dirs]\n",
    "\n",
    "try:\n",
    "    training_steps = [\n",
    "        int(i.split('/')[-1].split('_')[0]) for i in training_obs_dirs\n",
    "    ]\n",
    "    training_run_steps = [\n",
    "        int(i.split('/')[-1].split('_')[3]) for i in training_obs_dirs\n",
    "    ]\n",
    "    training_betas = [\n",
    "        float(i.split('/')[-1].split('_')[-1]) for i in training_obs_dirs\n",
    "    ]\n",
    "except TypeError:\n",
    "    training_steps = []\n",
    "    training_run_steps = []\n",
    "    training_betas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_dir = os.path.join(log_dir, 'figures')\n",
    "_names = [f'{s}_steps_beta_{b}' for s, b in zip(run_steps, betas)]\n",
    "figs_dirs = [os.path.join(figs_dir, n) for n in _names]\n",
    "_ = [io.check_else_make_dir(d) for d in figs_dirs]\n",
    "figs_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, d in enumerate(obs_dirs):\n",
    "    output = load_stats_and_observables(d)\n",
    "    actions_dict, plaqs_dict, charges_dict, tun_events = output\n",
    "    \n",
    "    actions_arr = np.array(list(actions_dict.values()))\n",
    "    plaqs_arr = np.array(list(plaqs_dict.values()))\n",
    "    charges_arr = np.array(list(charges_dict.values()))\n",
    "\n",
    "    keys_arr = np.array(list(actions_dict.keys()))\n",
    "    steps_arr = keys_arr[:, 0]\n",
    "    #beta = keys_arr[0, 1]\n",
    "    #run_steps = charges.shape[0]\n",
    "    observables = (actions_arr, plaqs_arr, charges_arr)\n",
    "    plot_observables(steps_arr, observables, train=False)\n",
    "    \n",
    "    beta = betas[idx]\n",
    "    out_dir = os.path.join(figs_dirs[idx], 'top_charge_probs')\n",
    "    #num_samples = params['num_samples']\n",
    "    plot_charge_probs(charges_arr, beta, params, out_dir, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output =  load_stats_and_observables(obs_dirs[1])\n",
    "actions_dict, plaqs_dict, charges_dict, tun_events = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_arr = np.array(list(actions_dict.values()))\n",
    "plaqs_arr = np.array(list(plaqs_dict.values()))\n",
    "charges_arr = np.array(list(charges_dict.values()))\n",
    "\n",
    "keys_arr = np.array(list(actions_dict.keys()))\n",
    "steps_arr = keys_arr[:, 0]\n",
    "beta = keys_arr[0, 1]\n",
    "_run_steps = charges.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_arr = np.array(charges_arr, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot_helper import plot_multiple_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables = (actions_arr, plaqs_arr, charges_arr)\n",
    "plot_observables(steps_arr, observables, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = betas[1]\n",
    "out_dir = os.path.join(figs_dirs[1], 'top_charge_probs')\n",
    "num_samples = params['num_samples']\n",
    "\n",
    "plot_charge_probs(charges_arr, beta, params, out_dir, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-4, 4, 1e-4)\n",
    "y_exact = project_angle(x)\n",
    "y_slow = linear_fft(x)\n",
    "y_approx_arr = []\n",
    "num_terms = [10, 20, 50, 100, 250, 500, 1000]\n",
    "times = []\n",
    "for n in num_terms:\n",
    "    t0 = time.time()\n",
    "    y_approx_arr.append(linear_fs(x, n))\n",
    "    dt = time.time() - t0\n",
    "    print(f'Time to complete ({n} terms): {dt:.4g}')\n",
    "    times.append(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = []\n",
    "for idx, y in enumerate(y_approx_arr):\n",
    "    err = sum((y - y_exact)/len(y_exact.numpy()))\n",
    "    print(f\"Error ({num_terms[idx]} terms): {err:.4g}\")\n",
    "    errs.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_charges = int(\n",
    "    0.1 + (tf.reduce_sum(ps_proj, axis=(1, 2),\n",
    "                         name='top_charges') / 2 * np.pi)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy1 = np.array((y_exact / 2 * np.pi), dtype=int)\n",
    "yy = np.array(y_approx_arr[1] / 2 * np.pi, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(yy)), yy1, label='exact')\n",
    "ax.plot(np.arange(len(yy)), yy, label='fft')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for idx, y in enumerate(y_approx_arr):\n",
    "    ax.plot(x, y, label = f'{num_terms[idx]} terms', alpha=0.7, ls='-');\n",
    "ax.plot(x, y_exact, label='Exact', color='k');\n",
    "ax.legend(loc='best', fontsize=10);\n",
    "ax.set_xlabel('x');\n",
    "ax.set_ylabel('y');\n",
    "#ax.set_xlim((-np.pi-0.05, -np.pi + 0.05))\n",
    "out_file = os.path.join(os.getcwd(), 'fourier_series_approx_zoom.png');\n",
    "print(f'Saving figure to: {out_file}.');\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_val[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_exact[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for idx, y in enumerate(y_approx_arr):\n",
    "    ax.plot(x, y, label = f'{num_terms[idx]} terms', alpha=0.7, ls='-');\n",
    "ax.plot(x, y_exact, label='Exact', color='k');\n",
    "ax.legend(loc='best', fontsize=10);\n",
    "ax.set_xlabel('x');\n",
    "ax.set_ylabel('y');\n",
    "ax.set_xlim((-np.pi-0.05, -np.pi + 0.05))\n",
    "out_file = os.path.join(os.getcwd(), 'fourier_series_approx_zoom.png');\n",
    "print(f'Saving figure to: {out_file}.');\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight');\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_plaq_sums(x, batch_size, links_shape):\n",
    "    \"\"\"Calculate plaquette sums.\n",
    "\n",
    "    Explicitly, calculate the sum of the links around each plaquette in the\n",
    "    lattice for each sample in samples.\n",
    "\n",
    "    Args:\n",
    "        samples: Tensor of shape (N, D) where N is the batch size and D is\n",
    "        the number of links on the lattice (flattened)\n",
    "    \"\"\"\n",
    "    x = np.reshape(x, shape=(batch_size, *links.shape))\n",
    "\n",
    "    plaq_sums = (x[:, :, :, 0]\n",
    "                 - x[:, :, :, 1]\n",
    "                 - np.roll(x[:, :, :, 0], shift=-1, axis=2)\n",
    "                 + np.roll(x[:, :, :, 1], shift=-1, axis=1))\n",
    "    return plaq_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_top_charges(x, batch_size, links_Shape, fn=np.floor):\n",
    "    \"\"\"Calculate topological charges for each sample in samples.\"\"\"\n",
    "    top_charges = fn(\n",
    "        0.1 + (np.sum(project_angle(calc_plaq_sums(x)), axis=(1, 2))\n",
    "               / (2 * np.pi))\n",
    "    )\n",
    "    return top_charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-10, 10, 0.05)\n",
    "y1 = np.tanh(x)\n",
    "OIkkoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and plot observables..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate observables for samples generated **_during_** training:\n",
    "- Every $\\approx 500$ steps or so during training procedure, we run the sampler at $\\beta \\equiv \\beta_{\\mathrm{final}}$. \n",
    "- By calculating observables (``total action``, ``average plaquette``, and ``topological charge``) for these samples and looking at the ``thermalization time``, we can get an idea of how well the sampler is performing.\n",
    "- We expect that as the training procedure continues, the ``thermalization time`` should decrease as the sampler improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 53.3s\n",
    "plt.close('all')\n",
    "log_dir = os.path.join('..', '..', 'gauge_logs_graph', 'run_233')\n",
    "train_observables_dicts = calc_observables(log_dir,\n",
    "                                           observables_dicts=None,\n",
    "                                           training=True,\n",
    "                                           frac=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1., 1., 1., -1., -1., -1., 2., -2., 0., 0., 0., -2.])\n",
    "y = np.array([0., 2., -1., -2., 0., 1., 0., 2., -2., 2., 1., -2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = np.sqrt(np.sum((x - y))**2)\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = np.sum(np.abs(x-y))\n",
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(x != y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(x != y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tot_diff(x, y):\n",
    "    z = np.where(x != y)[0]\n",
    "    return np.sum([x[i] - y[i] if x[i] > y[i] else y[i] - x[i] for i in z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tot_diff1(x, y):\n",
    "    return np.sum(np.abs(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.random.randint(-2, 2, size=1000)\n",
    "yy = np.random.randint(-2, 2, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(-2, 2, size=10)\n",
    "j = np.random.randint(-2, 2, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tot_diff2(x, y):\n",
    "    return len(np.where(x != y)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(i - j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_diff1(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples2 = tf.random_normal(samples.shape, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tf.cast(samples, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tf.reshape(samples, shape=(5, -1))\n",
    "samples2 = tf.reshape(samples2, shape=(5, -1))\n",
    "samples.shape, samples2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = tf.cast(i - j, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ = (tf.reduce_sum(1. - tf.cos(samples - samples2), axis=1)\n",
    "          + tf.reduce_sum(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1_plaq_exact(4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(i - j).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = []\n",
    "ca.append(i)\n",
    "ca.append(j)\n",
    "tot_diff1(ca[-1], ca[-2])\n",
    "tot_diff2(ca[-1], ca[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_arr.extend(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1_plaq_exact(2.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit d = tot_diff(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit d1 = tot_diff1(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_diff(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_diff1(xx, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Update train_observables_dicts:  \n",
    " * If `observables_dicts` argument of `calc_training_observables` is not `None`, only calculate observables that haven't been previously calculated.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_observables_dicts = calc_observables(\n",
    "    log_dir, \n",
    "    observables_dicts=train_observables_dicts,\n",
    "    training=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot observables for samples generated **_during_** training:\n",
    "- In addition, for each batch of samples generated during, plot the topological charge history of each individual chain in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_axes = plot_observables(log_dir, train_observables_dicts, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_charges(log_dir, train_observables_dicts[2], training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_charges_counts(log_dir,  train_observables_dicts[2],  training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot top charges counts totaled over all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "train_charges_dict = train_observables_dicts[2]\n",
    "params, _, _, _, figs_dir_dict = find_samples(log_dir, training=True)\n",
    "title_str_key = 'training'\n",
    "count_dict = {}\n",
    "idx = 0\n",
    "for key, val in train_charges_dict.items():\n",
    "    step, beta = key\n",
    "    counts = Counter(list(val.flatten()))\n",
    "    count_dict[key] = counts\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(list(counts.keys()), list(counts.values()), \n",
    "                color=COLORS[idx], marker=MARKERS[idx], ls='')\n",
    "                #fillstyle='none')#, label=f'{key} training steps')\n",
    "    idx += 1\n",
    "    _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "    _ = ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 + f\"{beta}, \"\n",
    "                 + f\"{step} {title_str_key} steps; \"\n",
    "                 + f\"total across {params['num_samples']} samples\")\n",
    "    _ = ax.set_title(title_str, fontsize=14)\n",
    "    out_dir = os.path.join(\n",
    "        figs_dir_dict[key], 'topological_charges_counts'\n",
    "    )\n",
    "    check_else_make_dir(out_dir)\n",
    "    out_file = os.path.join(\n",
    "        out_dir,\n",
    "        f'topological_charge_counts_total_{step}_steps_beta_{beta}.pdf'\n",
    "    )\n",
    "    #if not os.path.isfile(out_file):\n",
    "    print(f\"Saving figure to {out_file}.\")\n",
    "    _ = fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate observables for samples generated **_after_** training.\n",
    " - Again, samples are generated at $\\beta = \\beta_{\\mathrm{final}}$.\n",
    " - In contrast to the samples generated **_during_** training (which are all ran for $\\sim 100$ steps), we now look at generating longer chains (i.e. longer runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "log_dir = os.path.join('..', '..', 'gauge_logs_graph', 'run_227')\n",
    "observables_dicts = calc_observables(log_dir, \n",
    "                                     observables_dicts=None, \n",
    "                                     training=False,\n",
    "                                     frac=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "observables_dicts = calc_observables(log_dir, \n",
    "                                     observables_dicts=observables_dicts, \n",
    "                                     training=False,\n",
    "                                     frac=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Plot observables for samples generated **_after_** training:\n",
    "- In addition, for each batch of samples generated during, plot the topological charge history of each individual chain in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "figs_axes = plot_observables(log_dir, train_observables_dicts, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges(log_dir, train_observables_dicts[2], training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_top_charges_counts(log_dir,  train_observables_dicts[2],  training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Plot top charges counts totaled over all samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "COLORS *= 10\n",
    "MARKERS *= 10\n",
    "params, _, _, _, figs_dir_dict = find_samples(log_dir)\n",
    "charges_dict = observables_dicts[2]\n",
    "title_str_key = 'evaluation'\n",
    "count_dict = {}\n",
    "idx = 0\n",
    "for key, val in charges_dict.items():\n",
    "    step, beta = key \n",
    "    counts = Counter(list(val.flatten()))\n",
    "    count_dict[key] = counts\n",
    "    fig, ax = plt.subplots()\n",
    "    _ = ax.plot(list(counts.keys()), list(counts.values()), \n",
    "                color=COLORS[idx], marker=MARKERS[idx], ls='',\n",
    "                fillstyle='full')#, label=f'{key} training steps')\n",
    "    idx += 1\n",
    "    _ = ax.set_xlabel('Topological charge', fontsize=14)\n",
    "    _ = ax.set_ylabel('Number of occurrences', fontsize=14)\n",
    "    title_str = (r\"$\\beta = $\"\n",
    "                 + f\"{beta}, \"\n",
    "                 + f\"{step} steps; \"\n",
    "                 + f\"total across {params['num_samples']} samples\")\n",
    "    _ = ax.set_title(title_str, fontsize=16)\n",
    "    #out_dir = os.path.join(\n",
    "    #    figs_dir_dict[key], 'topological_charges_counts'\n",
    "    #)\n",
    "    #check_else_make_dir(out_dir)\n",
    "    out_file = os.path.join(\n",
    "       figs_dir_dict[key],\n",
    "        f'topological_charge_counts_total_{step}_steps_beta_{beta}.pdf'\n",
    "    )\n",
    "    #if not os.path.isfile(out_file):\n",
    "    print(f\"Saving figure to {out_file}.\")\n",
    "    _ = fig.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
