{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture of Gaussians experiment using L2HMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.func_utils import accept, jacobian, autocovariance, get_log_likelihood, \\\n",
    "    get_data, binarize, normal_kl, acl_spectrum, ESS\n",
    "from utils.distributions import Gaussian, GMM, GaussianFunnel, gen_ring\n",
    "from utils.layers import Linear, Sequential, Zip, Parallel, ScaleTanh\n",
    "from utils.dynamics import Dynamics\n",
    "from utils.sampler import propose\n",
    "from utils.notebook_utils import get_hmc_samples\n",
    "from utils.logging import variable_summaries, get_run_num, make_run_dir\n",
    "from utils.tunneling import distance, calc_min_distance, calc_tunneling_rate, \\\n",
    "    find_tunneling_events\n",
    "from utils.jackknife import block_resampling, jackknife_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory_w_distribution(samples, traj, x_dim=None):\n",
    "    if samples.shape[1] == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(samples[:, 0], samples[:, 1], samples[:, 2],\n",
    "                   alpha=0.5, marker='o', s=15, color='C0')\n",
    "        ax.plot(traj[:, 0], traj[:, 1], traj[:, 2], \n",
    "                color='C1', marker='o', markeredgecolor='C1', alpha=0.75, \n",
    "                ls='-', lw=1., markersize=2)\n",
    "    if samples.shape[1] == 2:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(samples[:, 0], samples[:, 1],  color='C0', alpha=0.6)\n",
    "        ax.plot(traj[:, 0], traj[:, 1],\n",
    "                 color='C1', marker='o', alpha=0.8, ls='-')\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_log_dir = './log_mog_tf/'\n",
    "log_dir = make_run_dir(root_log_dir)\n",
    "\n",
    "info_dir = log_dir + 'run_info/'\n",
    "figs_dir = log_dir + 'figures/'\n",
    "\n",
    "if not os.path.isdir(info_dir):\n",
    "    os.makedirs(info_dir)\n",
    "if not os.path.isdir(figs_dir):\n",
    "    os.makedirs(figs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 4\n",
    "init_learning_rate = 1e-3\n",
    "num_decay_steps = 1000\n",
    "decay_rate = 0.96\n",
    "temp = 10  # Initial temperature to be used in annealing schedule\n",
    "initial_temp = 10 # Copy used for reference\n",
    "annealing_steps = 100\n",
    "annealing_rate = 0.98\n",
    "eps = 0.1 # initial step size (trainable)\n",
    "n_steps = 20000 # number of training steps\n",
    "n_samples = 200 # number of trajectories to generate during training\n",
    "# number of trajectories to use for checking intermediate tunneling rates\n",
    "n_training_samples = 200\n",
    "# length of trajectory used for checking intermediate tunneling rates\n",
    "train_traj_length = 2000\n",
    "L2HMC_tunneling_rate = []\n",
    "all_tunneling_rates = {}  # record tunneling rates for each trajectory\n",
    "all_tunneling_events = {} # record each tunneling event of each trajectory\n",
    "losses = []\n",
    "training_samples = []  # record all intermediate trajectories during training\n",
    "# average tunneling rate over all n_training_samples during training\n",
    "tunneling_info = []  \n",
    "temp_arr = []             ## record temperatures of annealing schedule\n",
    "samples = np.random.randn(n_samples, x_dim)\n",
    "#min_distance = calc_min_distance(means, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture\n",
    "\n",
    "We define the network architecture for our L2HMC network. We first embed the first two variables ($\\{x, \\partial_x U\\}$ or $\\{v, x_m\\}$) as well as the time, formatted as $\\tau(t) = \\left(\\cos(\\frac{2\\pi t}{M}), \\sin(\\frac{2\\pi t}{M})\\right)$. They are forwarded through an MLP and then produce $S, T$ and $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def network(x_dim, scope, factor):\n",
    "    with tf.variable_scope(scope):\n",
    "        net = Sequential([\n",
    "            Zip([\n",
    "                Linear(x_dim, 10, scope='embed_1', factor=1.0 / 3),\n",
    "                Linear(x_dim, 10, scope='embed_2', factor=factor * 1.0 / 3),\n",
    "                Linear(2, 10, scope='embed_3', factor=1.0 / 3),\n",
    "                lambda _: 0.,\n",
    "            ]),\n",
    "            sum,\n",
    "            tf.nn.relu,\n",
    "            Linear(10, 10, scope='linear_1'),\n",
    "            tf.nn.relu,\n",
    "            Parallel([\n",
    "                Sequential([\n",
    "                    Linear(10, x_dim, scope='linear_s', factor=0.001), \n",
    "                    ScaleTanh(x_dim, scope='scale_s')\n",
    "                ]),\n",
    "                Linear(10, x_dim, scope='linear_t', factor=0.001),\n",
    "                Sequential([\n",
    "                    Linear(10, x_dim, scope='linear_f', factor=0.001),\n",
    "                    ScaleTanh(x_dim, scope='scale_f'),\n",
    "                ])\n",
    "            ])  \n",
    "        ])\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution\n",
    "\n",
    "We set up our dynamics which take as input our energy function, the number of time step of our operator, the (learnable) step-size and our architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_distributions = int(2)\n",
    "small_pi = (num_distributions * (10**(-16))).as_y\n",
    "big_pi = (1 - small_pi) / num_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [big_pi, big_pi, small_pi, small_pi]\n",
    "print(sum(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_arr = num_distributions * [big_pi]\n",
    "dist_arr.extend((x_dim - num_distributions) * [small_pi])\n",
    "dist_arr = np.array(dist_arr, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dist_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(dist_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_dim = 3\n",
    "sigma = 0.05\n",
    "#means = [np.array([-1.0, 0.0]).astype(np.float32),\n",
    "#         np.array([1.0, 0.0]).astype(np.float32)]\n",
    "means = np.array([[np.sqrt(2), 0.0, 0.0, 0.0],\n",
    "                  [0.0, np.sqrt(2), 0.0, 0.0],\n",
    "                  [np.sqrt(2), 0.0, 0.0, 0.0],\n",
    "                  [0.0, np.sqrt(2), 0.0, 0.0]]).astype(np.float32)\n",
    "#covs = [np.array([[0.1, 0.0], [0.0, 0.1]]).astype(np.float32),\n",
    "#        np.array([[0.1, 0.0], [0.0, 0.1]]).astype(np.float32)]\n",
    "#cov_mtx = np.array([[sigma, 0.0], [0.0, sigma]])\n",
    "cov_mtx = np.array([[sigma, 0.0, 0.0, 0.0],\n",
    "                    [0.0, sigma, 0.0, 0.0],\n",
    "                    [0.0, 0.0, sigma, 0.0],\n",
    "                    [0.0, 0.0, 0.0, sigma]]).astype(np.float32)\n",
    "covs = np.array([cov_mtx, cov_mtx, cov_mtx, cov_mtx]).astype(np.float32)\n",
    "#covs = [cov_mtx, cov_mtx]\n",
    "num_distributions = 1\n",
    "small_pi = num_distributions * (10**(-16))\n",
    "big_pi = (1 - small_pi) / num_distributions\n",
    "big_pi = 1 / num_distributions - small_pi * num_distributions\n",
    "dist_arr = num_distributions * [big_pi]\n",
    "dist_arr.extend((x_dim - num_distributions) * [small_pi])\n",
    "dist_arr = np.array(dist_arr, dtype=np.float32)\n",
    "distribution = GMM(means, covs, dist_arr)\n",
    "#distribution = GMM(means, covs, [0.5, 0.5])\n",
    "# Get some samples from the true distribution for debugging\n",
    "init_samples = distribution.get_samples(1000)\n",
    "#np.save('init_samples', init_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(init_samples[:, 0], init_samples[:, 1], init_samples[:, 2],\n",
    "           alpha=0.6, marker='o', s=15, color='C0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics = Dynamics(x_dim, distribution.get_energy_function(), \n",
    "                    T=10, eps=eps, net_factory=network, use_temperature=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, x_dim))\n",
    "z = tf.random_normal(tf.shape(x))\n",
    "\n",
    "Lx, _, px, output = propose(x, dynamics, do_mh_step=True)\n",
    "Lz, _, pz, _ = propose(z, dynamics, do_mh_step=False)\n",
    "\n",
    "loss = 0.\n",
    "\n",
    "v1 = (tf.reduce_sum(tf.square(x - Lx), axis=1) * px) + 1e-4\n",
    "v2 = (tf.reduce_sum(tf.square(z - Lz), axis=1) * pz) + 1e-4\n",
    "scale = 0.1\n",
    "loss += scale * (tf.reduce_mean(1.0 / v1) + tf.reduce_mean(1.0 / v2))\n",
    "loss += (- tf.reduce_mean(v1, name='v1') \n",
    "         - tf.reduce_mean(v2, name='v2')) / scale\n",
    "tf.summary.scalar('loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(tf.train.import_meta_graph)\n",
    "\n",
    "#graph_meta_file = './log_mog_tf/run87/-20001.meta'\n",
    "#imported_meta = tf.train.import_meta_graph('./log_mog_tf/run87/-20001.meta')\n",
    "\n",
    "\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#summary = tf.summary.merge_all()\n",
    "#init = tf.global_variables_initializer()\n",
    "#sess = tf.Session(config=config)\n",
    "#imported_meta.restore(sess, log_dir + '-200001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0., name='global_step', trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(init_learning_rate, global_step, \n",
    "                                           num_decay_steps, decay_rate,\n",
    "                                           staircase=True)\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_tunneling_rate = tf.placeholder(tf.float32, shape=(train_traj_length, \n",
    "#                                                    n_training_samples, x_dim))\n",
    "#_tunneling_rate = tf.placeholder(tf.float32, shape=(n_training_samples,))\n",
    "#_mean, _var = tf.nn.moments(_tunneling_rate, axes=[0])\n",
    "#_avg_tunneling_rate = _mean\n",
    "#_avg_tunneling_rate_std = tf.sqrt(_var)\n",
    "\n",
    "#_avg_tunneling_rate = 0.\n",
    "#_avg_tunneling_rate_std = 0.\n",
    "\n",
    "#tf.summary.scalar('avg_tunneling_rate_std', _avg_tunneling_rate_std_)\n",
    "# L2HMC_samples[:_traj_length, idx], \n",
    "# Take the mean of you measure\n",
    "#_avg_tunneling_rate = 0.\n",
    "#tf.summary.scalar('avg_tunneling_rate', _avg_tunneling_rate_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_tensorflow(log_dir)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "summary = tf.summary.merge_all()\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session(config=config)\n",
    "#ckpt = tf.train.get_checkpoint_state(log_dir)\n",
    "#if ckpt and ckpt.model_checkpoint_path:\n",
    "#    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "   \n",
    "summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_samples = np.load(info_dir + 'training_samples.npy')\n",
    "#temp_array = np.load(info_dir + 'temp_array.npy')\n",
    "#params__ = np.load(info_dir + 'parameters.npy')\n",
    "#means = np.load(info_dir + 'means.npy')\n",
    "#covs = np.load(info_dir + 'covariances.npy')\n",
    "#tunneling_info = np.load(info_dir + 'tunneling_info.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     2
    ]
   },
   "outputs": [],
   "source": [
    "log_parameters_file = info_dir + 'parameters.txt'\n",
    "with open(log_parameters_file, 'w') as f:\n",
    "    f.write((f\"\\ninitial_temp: {initial_temp}\\n\"\n",
    "             f\"\\nannealing_steps: {annealing_steps}\\n\"\n",
    "             f\"\\nannealing_factor: {annealing_rate}\\n\"\n",
    "             f\"\\neps: {eps} (initial step size; trainable)\\n\"\n",
    "             f\"\\nn_steps: {n_steps} (number of training steps)\\n\"\n",
    "             f\"\\nn_samples: {n_samples}\\n\"\n",
    "             f\"\\nn_training_samples: {n_training_samples}\\n\"\n",
    "             f\"\\ntrain_traj_length: {train_traj_length}\\n\"\n",
    "             f\"\\ninit_learning_rate: {init_learning_rate}\\n\"\n",
    "             f\"\\nnum_decay_steps: {num_decay_steps}\\n\"\n",
    "             f\"\\ndecay_rate: {decay_rate}\\n\"\n",
    "             f\"\\nmeans:\\n\\n {str(means)}\\n\"\n",
    "             f\"\\ncovs:\\n\\n {str(covs)}\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annealing_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annealing_steps1 = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = time.time()\n",
    "\n",
    "for t in range(n_steps // 8):\n",
    "    step_num = global_step.eval(session=sess) \n",
    "    feed_dict = {x: samples, \n",
    "                 dynamics.temperature: temp}\n",
    "    \n",
    "    _, loss_, samples, px_, lr_ = sess.run([\n",
    "        train_op,\n",
    "        loss,\n",
    "        output[0],\n",
    "        px,\n",
    "        learning_rate,\n",
    "    ], feed_dict=feed_dict)\n",
    "    losses.append(loss_)\n",
    "\n",
    "    if step_num % 50 == 0:\n",
    "        if step_num  > 0:\n",
    "            summary_str = sess.run(summary, feed_dict=feed_dict)\n",
    "            summary_writer.add_summary(summary_str, step_num)\n",
    "            summary_writer.flush()\n",
    "            print(f'Step: {step_num} / {n_steps}, Loss: {loss_:.4e}, '\n",
    "                  + f'Acceptance sample: {np.mean(px_):.2f}, LR: {lr_:.5f}, '\n",
    "                  + f'temp: {temp:.5f}')\n",
    "        \n",
    "    if step_num % annealing_steps == 0:\n",
    "        if temp <= 1.5:\n",
    "            break\n",
    "        temp *= annealing_rate\n",
    "            \n",
    "    if step_num % 500 == 0:\n",
    "        #temp *= 0.98\n",
    "        _samples = distribution.get_samples(n=n_training_samples)\n",
    "        _training_samples = []\n",
    "        for step in range(train_traj_length):\n",
    "            _training_samples.append(np.copy(_samples)) \n",
    "            _feed_dict = {\n",
    "                x: _samples, dynamics.temperature: 1.,\n",
    "            } \n",
    "            _samples = sess.run(output[0], _feed_dict)\n",
    "        \n",
    "        _training_samples_arr = np.array(_training_samples)\n",
    "        #_tunneling_events = []\n",
    "        #_tunneling_rate_old = []\n",
    "        _tunneling_rate = []\n",
    "        #_tunneling_events_old = []\n",
    "        _tunneling_events = []\n",
    "        for i in range(_training_samples_arr.shape[1]):\n",
    "            #events_old, rate_old = calc_tunneling_rate(_training_samples_arr[:, i, :], \n",
    "            #                                           min_distance)\n",
    "            events, rate = find_tunneling_events(_training_samples_arr[:, i, :],\n",
    "                                                 means)\n",
    "            _tunneling_rate.append(rate)\n",
    "            _tunneling_events.append(events)\n",
    "            #_tunneling_rate[i] = rate\n",
    "            # Take the mean of you measure\n",
    "        # Create a new Summary object with your measure\n",
    "        _avg_tunneling_rate = np.mean(_tunneling_rate)\n",
    "        _avg_tunneling_rate_std = np.std(_tunneling_rate)\n",
    "        #summary1 = tf.Summary()\n",
    "        #summary1.value.add(tag=\"Avg tunneling rate\", \n",
    "        #                   simple_value=_avg_tunneling_rate)\n",
    "        #summary_writer.add_summary(summary1, global_step)\n",
    "\n",
    "        \n",
    "        #_tunneling_rate_ = tf.stack(_tunneling_rate)\n",
    "        #_mean_, _var_ = tf.nn.moments(_tunneling_rate_, axes=[0])\n",
    "        #_avg_tunneling_rate_ = _mean_\n",
    "        #_avg_tunneling_rate_std_ = tf.sqrt(_var_)\n",
    "        #with tf.name_scope('tunneling_rate'):\n",
    "        #    variable_summaries(_tunneling_rate_)\n",
    "            \n",
    "        parameter_vals = [step_num,\n",
    "                          n_training_samples, \n",
    "                          train_traj_length,\n",
    "                          _avg_tunneling_rate,\n",
    "                          _avg_tunneling_rate_std]\n",
    "        \n",
    "        all_tunneling_events[step_num] = _tunneling_events\n",
    "        all_tunneling_rates[step_num] = _tunneling_rate\n",
    "        tunneling_info.append(parameter_vals)\n",
    "        #tunneling_events.append((step_num, _tunneling_events))\n",
    "        training_samples.append(_training_samples)\n",
    "        temp_arr.append(temp)\n",
    "        print((f\"\\n\\t Step: {step_num}, \"\n",
    "              f\"Average tunneling rate: {_avg_tunneling_rate}, \"\n",
    "              f\"Average tunneling rate std: {_avg_tunneling_rate_std}\\n\"))\n",
    "              #\\t Tunneling rate (old): {parameter_vals[-2]},\n",
    "\n",
    "    if step_num % 2500 == 0:\n",
    "        #step_num = global_step.eval(session=sess) \n",
    "        checkpoint_file = os.path.join(log_dir, 'model.ckpt')\n",
    "        print(f'Saving checkpoint to: {checkpoint_file}')\n",
    "        saver.save(sess, checkpoint_file, global_step=global_step)\n",
    "                \n",
    "#training_samples = np.array(training_samples)        \n",
    "time2 = time.time()\n",
    "dt1 = time2 - time1\n",
    "print(f'Time for {n_steps//8} training steps was: {dt1} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saver.save(sess, log_dir, global_step=global_step)\n",
    "\n",
    "#ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints/checkpoint'))\n",
    "#ckpt = tf.train.get_checkpoint_state(log_dir)\n",
    "#if ckpt and ckpt.model_checkpoint_path:\n",
    "# saver.restore(sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "np.save(info_dir + 'training_samples', np.array(training_samples))\n",
    "np.save(info_dir + 'temp_array', np.array(temp_arr))\n",
    "#np.save(info_dir + 'annealing_schedule', np.array([m]))\n",
    "np.save(info_dir + 'means', means)\n",
    "np.save(info_dir + 'covariances', covs)\n",
    "np.save(info_dir + 'tunneling_info', tunneling_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After training, we generate $200$ chains for $2000$ steps for evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_samples = []\n",
    "samples1 = distribution.get_samples(n=200)\n",
    "trajectory_length = 2000\n",
    "\n",
    "for t in range(trajectory_length):\n",
    "    final_samples.append(np.copy(samples1))\n",
    "\n",
    "    feed_dict = {\n",
    "        x: samples1, dynamics.temperature: 1.0,\n",
    "    }\n",
    "\n",
    "    samples1 = sess.run(output[0], feed_dict)\n",
    "\n",
    "np.save(info_dir + f'L2HMC_samples_{step_num}', np.array(final_samples))\n",
    "L2HMC_samples = np.array(final_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_distance = calc_min_dist(means, 0.02)\n",
    "#tunneling_events0 = []\n",
    "#_tunneling_rate_old_ = []\n",
    "_tunneling_rate_ = []\n",
    "#_parameter_vals_ = []\n",
    "for i in range(L2HMC_samples.shape[1]):\n",
    "    #_, rate_old = calc_tunneling_rate(L2HMC_samples[:, i, :], min_distance)\n",
    "    _, _rate_ = find_tunneling_events(L2HMC_samples[:, i, :], means)\n",
    "    #tunneling_events0.append(events)\n",
    "    #_tunneling_rate_old_.append(rate_old)\n",
    "    _tunneling_rate_.append(_rate_)\n",
    "\n",
    "L2HMC_tunneling_rate.append([step_num, \n",
    "                             L2HMC_samples.shape[1], \n",
    "                             trajectory_length,  \n",
    "                             #np.mean(_tunneling_rate_old_),\n",
    "                             np.mean(_tunneling_rate_),\n",
    "                             np.std(_tunneling_rate_)])\n",
    "for row in np.array(L2HMC_tunneling_rate):\n",
    "    #print(f\"Old tunneling rate: {row[-2]:.5g},\\t New tunneling rate: {row[-1]:.5g}\")\n",
    "    print(f\"Average tunneling rate: {row[-2]:.5g}, std: {row[-1]:.5g}\")\n",
    "#tunneling_rate.append(parameter_vals)\n",
    "\n",
    "#_tunneling_rate_arr_ = np.array(_tunneling_rate)\n",
    "\n",
    "#np.save(info_dir + 'tunneling_rate_arr', tunneling_rate_arr)\n",
    "\n",
    "#tunneling_rate_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate L2HMC MCMC chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "__samples = distribution.get_samples(1000)\n",
    "_traj_length = 100\n",
    "for idx in range(5):\n",
    "    print(f\"idx: {idx}\")\n",
    "    fig, ax = plot_trajectory_w_distribution(__samples, \n",
    "                                             L2HMC_samples[:_traj_length, idx], \n",
    "                                             x_dim=3)\n",
    "    ax.view_init(elev=30, azim=-140)\n",
    "    #ax.view_init(elev=20, azim=-75)\n",
    "    plt.show()\n",
    "    \n",
    "fig, ax = plot_trajectory_w_distribution(__samples,\n",
    "                                         L2HMC_samples[:_traj_length, 1],\n",
    "                                         x_dim=3)\n",
    "#str1 = f'tr (old): {np.array(L2HMC_tunneling_rate)[-1][-2]:.5g}, '\n",
    "str1 = f'first {_traj_length} steps of trajectory\\n'\n",
    "str2 = f'tunneling rate: {np.array(L2HMC_tunneling_rate)[-1][-2]:.5g}'\n",
    "ax.set_title(str1 + str2)\n",
    "#ax.set_title(f'tunneling rate (old): {np.array(L2HMC_tunneling_rate)[-1][-1]:.5f}')\n",
    "ax.view_init(elev=30, azim=-140)\n",
    "fig.tight_layout()\n",
    "out_file = figs_dir + f'MoG_trajectory_{_traj_length}t_{int(step_num)}train.png'\n",
    "#out_file = './2D_MoG_trajectory_2000t_10000train_4.png'\n",
    "print(f\"Saving fig to: {out_file}\")\n",
    "fig.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "#print(L2HMC_samples[:, idx].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_arr = np.array(tunneling_info)\n",
    "print(tr_arr.shape)\n",
    "\n",
    "step_nums_ = tr_arr[:, 0]\n",
    "tr_ = tr_arr[:, -2]\n",
    "#tr_new = tr_arr[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tunneling_rates_cp = {}\n",
    "for key, val in all_tunneling_rates.items():\n",
    "    new_key = int(key)\n",
    "    all_tunneling_rates_cp[new_key] = val\n",
    "\n",
    "all_tunneling_rates_arr = np.array(list(all_tunneling_rates_cp.values()))\n",
    "#print(all_tunneling_rates_arr.shape)\n",
    "\n",
    "avg_tr_vals = []\n",
    "_avg_tr_vals = []\n",
    "avg_tr_errs = []\n",
    "for row in all_tunneling_rates_arr:\n",
    "    avg_val = np.mean(row)\n",
    "    avg_tr_vals.append(avg_val)\n",
    "    data_rs = block_resampling(np.array(val), 100)\n",
    "    avg_tr_rs = []\n",
    "    for block in data_rs:\n",
    "        avg_tr_rs.append(np.mean(block))\n",
    "    _avg_tr_vals.append(np.mean(avg_tr_rs))\n",
    "    error = jackknife_err(y_i = avg_tr_rs,\n",
    "                          y_full = avg_val,\n",
    "                          num_blocks = 20) / len(row)\n",
    "    avg_tr_errs.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim=3\n",
    "np.eye(x_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#ax.plot(step_nums_, tr_old, #yerr=tunneling_rates_old_err,\n",
    "#            label='Old method', color='C0', marker='s', ls='-',\n",
    "#            fillstyle='none')\n",
    "        #fillstyle='none')\n",
    "#ax.errorbar(step_nums_, tr_, yerr=tr_arr[:, -1], lw=1.5, capsize=2, capthick=2,\n",
    "#            color='C0', marker='.', ls='-', fillstyle='none')\n",
    "ax.errorbar(step_nums_, avg_tr_vals, yerr=avg_tr_errs, \n",
    "            capsize=1.5, capthick=1.5,\n",
    "            color='C0', marker='.', ls='-', fillstyle='none')\n",
    "            #fillstyle='none')\n",
    "#ax.plot(step_nums76, tr_old76, label='Old method, run 2', \n",
    "#            color='C1', marker='o', fillstyle='none', ls='-')\n",
    "#ax.plot(step_nums76, tr_new76, label='New method, run 2', \n",
    "#            color='C1', marker='o', ls='--')\n",
    "        #al)\n",
    "        #fillstyle='none')\n",
    "ax.set_ylabel('Tunneling rate')#, fontsize=16)\n",
    "ax.set_xlabel('Training step')#, fontsize=16)\n",
    "#ax.legend(loc='best')#, markerscale=1.5), fontsize=12)\n",
    "str1 = r\"\"\"$\\mathcal{N}_1(\\sqrt{2}\\hat x; 0.05), $\"\"\"\n",
    "str2 = r\"\"\"$\\mathcal{N}_2(\\sqrt{2}\\hat y; 0.05),$ \"\"\"\n",
    "str3 = f\"$T_0 =${initial_temp};  \"\n",
    "str22 = \"\\n\"\n",
    "str4 = r\"\"\"$T \\rightarrow $ \"\"\" \n",
    "str5 = f\"{annealing_rate}\" \n",
    "str6 = r\"\"\"$\\times T$ \"\"\"\n",
    "str7 = f\"every {annealing_steps} steps\"\n",
    "#str5 = f\"$ \\times T$ every {annealing_steps} steps\"\n",
    "#str2 = (r\"$T \\rightarrow $\" + f\"{annealing_rate}\" + \" \\times T$ \"\n",
    "#        f\"every {annealing_steps} steps\")\n",
    "ax.set_title(str1 + str2 + str3 + str22 + str4 + str5 + str6 + str7)# + str2)\n",
    "#ax.set_ylim((-0.05, 1.))\n",
    "fig.tight_layout()\n",
    "out_file = figs_dir + f'3D_tunneling_rate_vs_step_num_{int(step_num)}.png'\n",
    "fig.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "\n",
    "#np.save(info_dir + 'step_nums', step_nums_)\n",
    "#np.save(info_dir + 'tr_old', tr_old)\n",
    "#np.save(info_dir + 'tr_new', tr_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def update_lines(num, dataLines, lines):\n",
    "    for line, data in zip(lines, dataLines):\n",
    "        # NOTE: there is no .set_data() for 3 dim data...\n",
    "        line.set_data(data[0:2, :num])\n",
    "        line.set_3d_properties(data[2, :num])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Creating the Animation object\n",
    "line_ani = animation.FuncAnimation(fig, update_lines, 25, fargs=(data, lines),\n",
    "                                   interval=50, blit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lines = [ax.plot(dat[0, 0:1], dat[1, 0:1], dat[2, 0:1])[0] for dat in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_trajectory_w_distribution(init_samples, \n",
    "                                         L2HMC_samples[:, 8], \n",
    "                                         x_dim=3)\n",
    "ax.view_init(elev=38, azim=38)\n",
    "plt.show()\n",
    "fig.tight_layout()\n",
    "out_file = './3D_MoG_trajectory_2000t_20000train_0.png'\n",
    "fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_trajectory_w_distribution(init_samples, \n",
    "                                         L2HMC_samples[:200, 0], \n",
    "                                         x_dim=3)\n",
    "for idx in range(50):\n",
    "    #print(f\"idx: {idx}\")\n",
    "    ax.plot(L2HMC_samples[:200, idx, 0], \n",
    "            L2HMC_samples[:200, idx, 1], \n",
    "            L2HMC_samples[:200, idx, 2], \n",
    "            color='C1', marker='o', ls='-', alpha=0.6, markersize=1)#, fillstyle='none')\n",
    "    ax.view_init(elev=38, azim=38)\n",
    "    plt.show()\n",
    "#fig.tight_layout()\n",
    "#out_file = './3D_MoG_trajectory_200t_20000train_50samples_0.png'\n",
    "#fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Generic HMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the HMC chains with **auto-correlation spectrums** as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMC_samples_0 = get_hmc_samples(2, 0.1, distribution.get_energy_function(), sess, steps=2000, samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMC_samples_1 = get_hmc_samples(2, 0.2, distribution.get_energy_function(), sess, steps=2000, samples=samples)\n",
    "HMC_samples_2 = get_hmc_samples(2, 0.3, distribution.get_energy_function(), sess, steps=2000, samples=samples)\n",
    "HMC_samples_3 = get_hmc_samples(2, 0.5, distribution.get_energy_function(), sess, steps=2000, samples=samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMC0 = acl_spectrum(HMC_samples_0, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.sqrt(np.trace(covs))\n",
    "L2HMC = acl_spectrum(L2HMC_samples, scale=scale)\n",
    "HMC1 = acl_spectrum(HMC_samples_1, scale=scale)\n",
    "HMC2 = acl_spectrum(HMC_samples_2, scale=scale)\n",
    "HMC3 = acl_spectrum(HMC_samples_3, scale=scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot auto-correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = 10 * np.arange(300)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xaxis, L2HMC[:300]/max(L2HMC[:300]), label='L2HMC')\n",
    "ax.plot(xaxis, HMC0[:300]/max(HMC0[:300]), label='HMC $\\epsilon=0.1$')\n",
    "ax.plot(xaxis, HMC1[:300]/max(HMC1[:300]), label='HMC $\\epsilon=0.2$')\n",
    "ax.plot(xaxis, HMC2[:300]/max(HMC2[:300]), label='HMC $\\epsilon=0.3$')\n",
    "ax.plot(xaxis, HMC3[:300]/max(HMC3[:300]), label='HMC $\\epsilon=0.5$')\n",
    "ax.set_ylabel('Auto-correlation')\n",
    "ax.set_xlabel('Gradient Computations')\n",
    "#ax.set_xlim((0, 200))\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig.savefig('./auto_correlation_vs_grad_comps_MoG_mixed.png', \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the **Effective Sample Size** (ESS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ESS L2HMC: %.2e -- ESS HMC: %.2e -- Ratio: %d' % (ESS(L2HMC), ESS(HMC2), ESS(L2HMC) / ESS(HMC2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize a single chain of both HMC and L2HMC for $500$ time steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(HMC_samples_0[:100, 1, 0], HMC_samples_0[:100, 1, 1], \n",
    "         color='C1', marker='o', alpha=0.8, ls='-')\n",
    "ax.set_title(\"Single chain of HMC $(\\epsilon = 0.1)$ for 1000 time steps\")\n",
    "fig.tight_layout()\n",
    "fig.savefig('./MoG_HMC_chain_e01_100t_1.png', dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(after 5000 training steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_training_samples_ = np.copy(np.array(training_samples))\n",
    "print(_training_samples_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_trajectory_w_distribution(init_samples,\n",
    "                                         _training_samples_[-2, :100, 0],\n",
    "                                         x_dim=3)\n",
    "\n",
    "_temp = temp_arr[-2]\n",
    "ax.view_init(elev=38, azim=38)\n",
    "ax.set_title(f'T = {_temp}')\n",
    "fig.tight_layout()\n",
    "out_file = f'./3D_MoG_trajectory_temp{_temp:.1f}_1.png'\n",
    "fig.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "                                     #_training_samples_[-2, :100, 0, 0],\n",
    "                                         #_training_samples_[-2, :100, 0, 0],\n",
    "                                         #color='C1', marker='o', ls='-', \n",
    "                                         #alpha=0.6, markersize=1, \n",
    "                                         #fillstyle='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for idx in range(len(_training_samples_)):\n",
    "    _temp = temp_arr[idx]\n",
    "    fig, ax = plot_trajectory_w_distribution(init_samples, \n",
    "                                             _training_samples_[idx, :, 0], \n",
    "                                             x_dim=3)\n",
    "    for i in range(_training_samples_.shape[2]):\n",
    "        ax.plot(_training_samples_[idx, :, i, 0], \n",
    "                _training_samples_[idx, :, i, 1], \n",
    "                _training_samples_[idx, :, i, 2], \n",
    "                color='C1', marker='o', ls='-', \n",
    "                alpha=0.6, markersize=1)#, fillstyle='none')\n",
    "    ax.view_init(elev=38, azim=38)\n",
    "    ax.set_title(f'T = {_temp}')\n",
    "    fig.tight_layout()\n",
    "    #out_dir = './figures/training_trajectories/'\n",
    "    #out_file = out_dir + f'3D_MoG_training_trajectory_temp{_temp:.1f}_0.png'\n",
    "    #if not os.path.isfile(out_file):\n",
    "    #    print(f\"Saving figure to file: {out_file}\")\n",
    "    #    fig.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#for i in range(10, 20):\n",
    "#    print(f'i: {i}')\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.scatter(init_samples[:,0], init_samples[:,1], color='C0')\n",
    "#ax.plot(L2HMC_samples[:, -i, 0], L2HMC_samples[:, -i, 1], \n",
    "#        marker='o', color='C1', alpha=0.8)\n",
    "#plt.show()\n",
    "#init_samples = distribution.get_samples(n=n_samples)\n",
    "for i in range(30, 40):\n",
    "    print(f'i: {i}')\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    #ax.scatter(init_samples[:, :1], init_samples[:, 2], s=15, color='C0')\n",
    "    ax.scatter(init_samples[:, 0], init_samples[:, 1], \n",
    "               init_samples[:, 2], s=15, color='C0') \n",
    "    ax.plot(L2HMC_samples[:, i, 0], \n",
    "            L2HMC_samples[:, i, 1], \n",
    "            L2HMC_samples[:, i, 2], color='C1')#, ls='-', lw='10')\n",
    "    plt.show()\n",
    "    \n",
    "#ax.scatter(init_samples[:, :1], init_samples[:,2], s=15)\n",
    "#plt.show()\n",
    "\n",
    "#fig, ax = plt.subplots()\n",
    "#ax.plot(L2HMC_samples[:200, 2, 0], L2HMC_samples[:200, 2, 1], \n",
    "#        color='C1', marker='o', alpha=0.6, ls='-')\n",
    "#ax.scatter(init_samples[:, 0], init_samples[:, 1], color='C0')\n",
    "#fig.tight_layout()\n",
    "#out_file = './3D_MoG_trajectory_2000t_5000train_2.png'\n",
    "#out_file = './2D_MoG_trajectory_2000t_10000train_4.png'\n",
    "#fig.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "ANL/l2hmc_py3/l2hmc/MOGExperiment.ipynb",
    "public": true
   },
   "id": ""
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
