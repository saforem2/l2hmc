{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2HMC for $U(1)$ Gauge Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import i0, i1\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "#from l2hmc_eager import dynamics_eager as _l2hmc\n",
    "#from l2hmc_eager import gauge_dynamics_eager as l2hmc\n",
    "#from l2hmc_eager.neural_nets import *\n",
    "#from utils.distributions import GMM, gen_ring\n",
    "#from utils.jacobian import _map, jacobian\n",
    "from utils.data_utils import (\n",
    "    calc_avg_vals_errors, block_resampling, jackknife_err\n",
    ")\n",
    "#from u1_model_eager import *\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from l2hmc_eager import gauge_dynamics_eager as gde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lattice.gauge_lattice import u1_plaq_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from u1_model_eager import GaugeModelEager, train_one_iter\n",
    "#from gauge_model import GaugeModel, graph_step, train_one_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gauge_model_helpers import plot_run_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.gauge_model_helpers as helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    result /= result[result.argmax()]\n",
    "    return result[result.size//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4,
     10,
     19
    ]
   },
   "outputs": [],
   "source": [
    "def graph_step(dynamics, samples, optimizer, loss_fn, \n",
    "               params,  global_step=None, hmc=False):\n",
    "    \"\"\"Perform a single training step using the compiled tensorflow graph.\n",
    "    \n",
    "    NOTE: \n",
    "        To be defunnable, the function cannot return an Operation, so the above\n",
    "        function is used for defun or eager, and this function is used in graph to be\n",
    "        able to run the gradient updates.\n",
    "    \"\"\"\n",
    "    clip_value = params.get('clip_value', 100)\n",
    "    loss, samples_out, accept_prob, grads = gde.loss_and_grads(\n",
    "        dynamics=dynamics,\n",
    "        x=samples,\n",
    "        params=params,\n",
    "        loss_fn=loss_fn,\n",
    "        hmc=hmc\n",
    "    )\n",
    "    \n",
    "    grads, _ = tf.clip_by_global_norm(grads, clip_value)\n",
    "    train_op = optimizer.apply_gradients(\n",
    "        zip(grads, dynamics.trainable_variables), global_step=global_step\n",
    "    )\n",
    "    \n",
    "    return train_op, loss, samples_out, accept_prob, grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GaugeModelEager for training L2HMC on $U(1)$ gauge lattice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'time_size': 8,\n",
    "    'space_size': 8,\n",
    "    'link_type': 'U1',\n",
    "    'dim': 2,\n",
    "    'beta': 8.,\n",
    "    'num_samples': 4,\n",
    "    'num_steps': 5,\n",
    "    'eps': 0.2,\n",
    "    'loss_scale': 0.1,\n",
    "    'loss_eps': 1e-4,\n",
    "    'learning_rate_init': 1e-3,\n",
    "    'learning_rate_decay_steps': 100,\n",
    "    'learning_rate_decay_rate': 0.96,\n",
    "    'train_steps': 1000,\n",
    "    'record_loss_every': 50,\n",
    "    'data_steps': 1,\n",
    "    'save_steps': 50,\n",
    "    'print_steps': 5,\n",
    "    'logging_steps': 50,\n",
    "    'clip_value': 100,\n",
    "    'rand': False,\n",
    "    'metric': 'l2',\n",
    "}\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Using gauge_model.GaugeModel (compiled graph)\n",
    "\n",
    "Seems to have the same problem as before where the training time / step increases as training progresses. I think this is due to the graph constantly creating new `tf.reshape` operations each time a batch is fed through. Need to test further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_conv = GaugeModel(params=params,\n",
    "                        conv_net=True,\n",
    "                        hmc=False,\n",
    "                        log_dir=None,\n",
    "                        restore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_conv.logging_steps = 50\n",
    "model_conv.data_steps = 1 \n",
    "model_conv.save_steps = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_conv.train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     13
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.enable_resource_variables()\n",
    "tf.reset_default_graph()\n",
    "print(\"Building graph...\")\n",
    "model_conv = GaugeModelEager(params=params,\n",
    "                             conv_net=True,\n",
    "                             hmc=False,\n",
    "                             log_dir=None,\n",
    "                             restore=False,\n",
    "                             defun=False)\n",
    "x = tf.placeholder(tf.float32, shape=model_conv.samples.shape)\n",
    "samples_np = np.array(model_conv.lattice.samples, dtype=np.float32)\n",
    "#x = np.array(model_conv.lattice.samples, dtype=np.float32)\n",
    "loss, _, _ = gde.compute_loss(model_conv.dynamics, x, model_conv.params)\n",
    "train_op, loss, samples_out, accept_prob, _ = graph_step(\n",
    "    dynamics=model_conv.dynamics,\n",
    "    samples=x,\n",
    "    optimizer=model_conv.optimizer,\n",
    "    loss_fn=gde.compute_loss,\n",
    "    params=model_conv.params,\n",
    "    global_step=model_conv.global_step,\n",
    "    hmc=model_conv.hmc\n",
    ")\n",
    "session_conf = tf.ConfigProto()\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#with tf.Session(config=session_conf) as sess:\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(\"Performing warmup...\")\n",
    "for _ in range(1):\n",
    "    _, _ = sess.run([train_op, loss], feed_dict={x: samples_np})\n",
    "print(\"done.\")\n",
    "print(\"Training...\")\n",
    "start_time = time.time()\n",
    "for i in range(10):\n",
    "    _, loss_np, samples_np, accept_prob_np = sess.run(\n",
    "        [train_op,\n",
    "         loss,\n",
    "         samples_out,\n",
    "         accept_prob],\n",
    "        feed_dict={x: samples_np}\n",
    "    )\n",
    "    print(f'step: {i}, loss: {loss_np}')\n",
    "#x_, v_, x_accept_prob, x_out = model_conv.dynamics.apply_transition(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     5
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "      with tf.Graph().as_default():\n",
    "        energy_fn, _, _ = l2hmc.get_scg_energy_fn()\n",
    "        x = tf.random_normal([hparams.n_samples, hparams.x_dim],\n",
    "                             dtype=tf.float32)\n",
    "        dynamics = l2hmc.Dynamics(\n",
    "            x_dim=hparams.x_dim,\n",
    "            minus_loglikelihood_fn=energy_fn,\n",
    "            n_steps=hparams.n_steps,\n",
    "            eps=hparams.eps)\n",
    "        loss, _, _ = l2hmc.compute_loss(dynamics, x)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=hparams.learning_rate)\n",
    "        train_op, loss, _ = graph_step(dynamics, optimizer, x)\n",
    "        # Single thread; fairer comparison against eager\n",
    "        session_conf = tf.ConfigProto(inter_op_parallelism_threads=1)\n",
    "        with tf.Session(config=session_conf) as sess:\n",
    "          sess.run(tf.global_variables_initializer())\n",
    "\n",
    "          # Warmup to reduce initialization effect when timing\n",
    "          for _ in range(hparams.n_warmup_iters):\n",
    "            _, _ = sess.run([train_op, loss])\n",
    "\n",
    "          # Training\n",
    "          start_time = time.time()\n",
    "          for i in range(hparams.n_iters):\n",
    "            _, loss_np = sess.run([train_op, loss])\n",
    "            print(\"Iteration %d: loss %.4f\" % (i, loss_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using tf.contrib.eager execution with 'defun' for compiling ops to graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### (Generic) HMC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_hmc = GaugeModelEager(params=params,\n",
    "                            conv_net=False,\n",
    "                            hmc=True,\n",
    "                            log_dir=None,\n",
    "                            restore=False,\n",
    "                            defun=True)\n",
    "# 1m 22.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "observables_hmc = model_hmc.calc_observables(model_hmc.samples, \n",
    "                                             _print=True, \n",
    "                                             _write=True)\n",
    "total_actions, avg_plaquettes, top_charges = observables_hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_hmc.train(10, keep_samples=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps = np.arange(len(model_hmc.data['average_plaquettes_arr']))\n",
    "_ = plot_run_data(model_hmc.data, model_hmc.params, \n",
    "                  steps, model_hmc.figs_dir, skip_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ConvNet L2HMC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_defun = GaugeModelEager(params=params,\n",
    "                                   conv_net=True,\n",
    "                                   hmc=False,\n",
    "                                   log_dir=None,\n",
    "                                   restore=False,\n",
    "                                   defun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params['conv_net'] = True\n",
    "model_conv = GaugeModelEager(params=params,\n",
    "                             conv_net=True,\n",
    "                             hmc=False,\n",
    "                             log_dir=None,\n",
    "                             restore=False,\n",
    "                             defun=False)\n",
    "#model_conv._restore_model(model_conv.log_dir)\n",
    "#model_conv.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables_conv = model_conv.calc_observables(model_conv.samples, update=True) \n",
    "helpers.print_run_data(model_conv.data, header=True)\n",
    "helpers.write_run_data(model_conv.files['run_info_file'], model_conv.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv_defun.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "model_conv.train(500)\n",
    "# 3h 50m 20s with defun=False, including aux var z, 5 steps eps 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_arr = [0]\n",
    "steps_arr.extend(model_conv.steps_arr)\n",
    "\n",
    "_ = plot_run_data(model_conv.data, model_conv.params, steps_arr, \n",
    "                  model_conv.figs_dir, skip_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_run_data(model_conv.data, model_conv.params, steps_arr, \n",
    "                  model_conv.figs_dir, skip_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FullyConnected (GenericNet) L2HMC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc = GaugeModelEager(params=params,\n",
    "                           conv_net=False,\n",
    "                           hmc=False,\n",
    "                           log_dir=None,\n",
    "                           restore=False,\n",
    "                           defun=True)\n",
    "#model_fc.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables_fc = model_fc.calc_observables(model_fc.samples, update=True) \n",
    "helpers.print_run_data(model_fc.data, header=True)\n",
    "helpers.write_run_data(model_fc.files['run_info_file'], model_fc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fc.train(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model (generate samples to measure Autocorrelation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Using CONV NET model: `model_conv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#samples_conv = np.array(\n",
    "#    model_conv.lattice.samples.reshape((model_conv.batch_size, -1)),\n",
    "#    dtype=np.float32\n",
    "#)\n",
    "apply_transition_conv = tfe.defun(model_conv.dynamics.apply_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_conv = tf.random_normal(shape=model_conv.samples.shape)\n",
    "samples_history_conv = []\n",
    "actions_history_conv = []\n",
    "avg_plaquettes_history_conv = []\n",
    "top_charges_history_conv = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    #samples_history_conv.append(samples_conv.numpy())\n",
    "    t0 = time.time()\n",
    "    #_, _, _, samples_conv = apply_transition_conv(samples_conv)\n",
    "    _, _, _, samples_conv1 = model_conv1.dynamics.apply_transition(samples_conv1)\n",
    "    observables_conv = np.array(\n",
    "        model_conv.lattice.calc_plaq_observables(samples_conv1)\n",
    "    ).T\n",
    "    actions_history_conv.append(observables_conv[0])\n",
    "    avg_plaquettes_history_conv.append(observables_conv[1])\n",
    "    top_charges_history_conv.append(observables_conv[2])\n",
    "    step_time = (time.time() - t0) / (model_conv.num_steps * model_conv.batch_size)\n",
    "    print(f'step: {i}  time/step: {step_time:^6.4g} '\n",
    "          f'top_charge: {np.mean(observables_conv[2]):^6.4g} '\n",
    "          f'avg_plaq: {np.mean(observables_conv[1]):^6.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#samples_history_conv = np.array(samples_history_conv)\n",
    "actions_history_conv = np.array(actions_history_conv)\n",
    "avg_plaquettes_history_conv = np.array(avg_plaquettes_history_conv)\n",
    "top_charges_history_conv = np.array(top_charges_history_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_charges_autocorr0_conv = autocorr(top_charges_history_conv[:, 0])\n",
    "top_charges_autocorr1_conv = autocorr(top_charges_history_conv[:, 1])\n",
    "\n",
    "top_charges_autocorr_conv = (top_charges_autocorr0_conv \n",
    "                            + top_charges_autocorr1_conv) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaquettes_autocorr0_conv = autocorr(avg_plaquettes_history_conv[:, 0])\n",
    "avg_plaquettes_autocorr1_conv = autocorr(avg_plaquettes_history_conv[:, 1])\n",
    "\n",
    "avg_plaquettes_autocorr_conv = (avg_plaquettes_autocorr0_conv\n",
    "                                + avg_plaquettes_autocorr1_conv) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps_conv = np.arange(len(top_charges_autocorr_conv))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#ax.plot(steps_hmc, top_charges_autocorr_hmc, \n",
    "#        marker='', ls='-', label='topological_charge (HMC)')\n",
    "#ax.plot(steps_conv, avg_plaquettes_autocorr_conv,\n",
    "#        marker='', ls='--', label='avg plaquettes (L2HMC, ConvNet)')\n",
    "ax.plot(steps_conv, top_charges_autocorr_conv,\n",
    "        marker='', ls='-', label='topological charges (L2HMC, ConvNet)')\n",
    "#ax.plot(steps1, top_charges_autocorr, marker='', ls='-', label='topological_charge (L2HMC)')\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.set_title(\"\")\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "fig.savefig(os.path.join(model_conv.figs_dir, \n",
    "                         'top_charge_autocorrelation_fn_hmc.pdf'), \n",
    "            dpi=400, bbox_inches='tight')\n",
    "#ax.set_xlim((ax.get_xlim()[0], 1000))\n",
    "#ax.set_xlim((-5, 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Using HMC model: `model_hmc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_hmc = np.array(\n",
    "    model_hmc.lattice.samples.reshape((model_hmc.batch_size, -1)),\n",
    "    dtype=np.float32\n",
    ")\n",
    "apply_transition_hmc = tfe.defun(model_hmc.dynamics.apply_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_hmc = tf.random_normal(shape=model_hmc.samples.shape)\n",
    "samples_history_hmc = []\n",
    "actions_history_hmc = []\n",
    "avg_plaquettes_history_hmc = []\n",
    "top_charges_history_hmc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    samples_history_hmc.append(samples_hmc.numpy())\n",
    "    t0 = time.time()\n",
    "    _, _, _, samples_hmc = apply_transition_hmc(samples_hmc)\n",
    "    observables_hmc = np.array(\n",
    "        model_hmc.lattice.calc_plaq_observables(samples_hmc)\n",
    "    ).T\n",
    "    actions_history_hmc.append(observables_hmc[0])\n",
    "    avg_plaquettes_history_hmc.append(observables_hmc[1])\n",
    "    top_charges_history_hmc.append(observables_hmc[2])\n",
    "    print(f'step: {i}  time/step: {time.time() - t0:^6.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_history_hmc = np.array(samples_history_hmc)\n",
    "actions_history_hmc = np.array(actions_history_hmc)\n",
    "avg_plaquettes_history_hmc = np.array(avg_plaquettes_history_hmc)\n",
    "top_charges_history_hmc = np.array(top_charges_history_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_charges_autocorr0_hmc = autocorr(top_charges_history_hmc[:, 0])\n",
    "top_charges_autocorr1_hmc = autocorr(top_charges_history_hmc[:, 1])\n",
    "\n",
    "top_charges_autocorr_hmc = (top_charges_autocorr0_hmc \n",
    "                            + top_charges_autocorr1_hmc) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Compute Autocorrelation spectrum directly from samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_ac_spectrum_hmc = compute_ac_spectrum(samples_history_hmc, \n",
    "                                              samples_history_mean_hmc)\n",
    "\n",
    "steps_hmc = np.arange(len(samples_ac_spectrum_hmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_ac_spectrum_hmc_file = os.path.join(model_hmc.info_dir,\n",
    "                                            'samples_ac_spectrum_hmc.pkl')\n",
    "top_charges_acl_spectrum_hmc_file = os.path.join(model_hmc.info_dir,\n",
    "                                                 'top_charges_acl_spectrum_hmc.pkl')\n",
    "actions_acl_spectrum_hmc_file = os.path.join(model_hmc.info_dir,\n",
    "                                             'actions_acl_spectrum_hmc.pkl')\n",
    "avg_plaquette_acl_spectrum_hmc_file = os.path.join(model_hmc.info_dir,\n",
    "                                                   'avg_plaquette_acl_spectrum_hmc.pkl')\n",
    "with open(samples_ac_spectrum_hmc_file, 'wb') as f:\n",
    "    pickle.dump(samples_ac_spectrum_hmc, f)\n",
    "\n",
    "with open(top_charges_acl_spectrum_hmc_file, 'wb') as f:\n",
    "    pickle.dump(top_charges_acl_spectrum_hmc, f)\n",
    "    \n",
    "with open(actions_acl_spectrum_hmc_file, 'wb') as f:\n",
    "    pickle.dump(actions_acl_spectrum_hmc, f)\n",
    "    \n",
    "with open(avg_plaquette_acl_spectrum_hmc_file, 'wb') as f:\n",
    "    pickle.dump(avg_plaquette_acl_spectrum_hmc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps = np.arange(len(samples_ac_spectrum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps_hmc, samples_ac_spectrum_hmc, marker='', ls='-', label='HMC')\n",
    "ax.plot(steps, samples_ac_spectrum, marker='', ls='-', label='L2HMC')\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.set_title(\"Autocorrelation directly from samples (Eq. 15)\", fontsize=16)\n",
    "ax.legend(loc='best')\n",
    "fig.savefig(os.path.join(model_hmc.figs_dir, 'samples_autocorrelation_fn_hmc.pdf'), \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Compute Autocorrelation for Topological charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#top_charges_acl_spectrum_hmc = compute_autocorrelation(top_charges_history_hmc, \n",
    "#                                                       top_charges_mean_hmc,\n",
    "#                                                       top_charges_var_hmc)\n",
    "#actions_acl_spectrum_hmc = compute_autocorrelation(actions_history_hmc, \n",
    "#                                                   actions_mean_hmc,\n",
    "#                                                   actions_var_hmc)\n",
    "#avg_plaquette_acl_spectrum_hmc = compute_autocorrelation(avg_plaquettes_history_hmc,\n",
    "#                                                         avg_plaquettes_mean_hmc,\n",
    "#                                                         avg_plaquettes_var_hmc)\n",
    "#steps_hmc = np.arange(len(top_charges_acl_spectrum_hmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#top_charges_acl_spectrum_hmc = compute_autocorrelation(top_charges_history_hmc, \n",
    "#                                                       top_charges_mean_hmc,\n",
    "#                                                       top_charges_var_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_charges_autocorr0 = autocorr(top_charges_history[:, 0])\n",
    "top_charges_autocorr1 = autocorr(top_charges_history[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#top_charges_autocorr = (top_charges_autocorr0 + top_charges_autocorr1) / 2\n",
    "#avg_plaquette_autocorr0 = autocorr(avg_plaquettes_history[:, 0])\n",
    "#avg_plaquette_autocorr1 = autocorr(avg_plaquettes_history[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaquette_autocorr0_hmc = autocorr(avg_plaquettes_history_hmc[:, 0])\n",
    "avg_plaquette_autocorr1_hmc = autocorr(avg_plaquettes_history_hmc[:, 1])\n",
    "\n",
    "#avg_plaquette_autocorr = (avg_plaquette_autocorr0\n",
    "#                          + avg_plaquette_autocorr1) / 2\n",
    "\n",
    "avg_plaquette_autocorr_hmc = (avg_plaquette_autocorr0_hmc\n",
    "                              + avg_plaquette_autocorr1_hmc) / 2\n",
    "\n",
    "#steps = np.arange(len(avg_plaquette_autocorr))\n",
    "steps_hmc = np.arange(len(avg_plaquette_autocorr_hmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps_hmc, avg_plaquette_autocorr_hmc, marker='', ls='-', label='Average plaquette (HMC)')\n",
    "ax.plot(steps_conv, avg_plaquette_autocorr_conv, marker='', ls='-', label='Average plaquette (L2HMC, ConvNet)')\n",
    "#ax.plot(steps, avg_plaquette_autocorr, marker='', ls='-', label='Average plaquette (L2HMC)')\n",
    "#ax.plot(steps, avg_plaquette_autocorr1, marker='', ls='-', label='Average plaquette1 (L2HMC)')\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "#fig.savefig(os.path.join(model_hmc.figs_dir, 'avg_plaquette_autocorrelation_fn_hmc.pdf'), \n",
    "#            dpi=400, bbox_inches='tight')\n",
    "#ax.set_xlim((-20, 450))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps1 = np.arange(len(top_charges_autocorr0))\n",
    "steps_hmc = np.arange(len(top_charges_autocorr0_hmc))\n",
    "steps_conv = np.arange(len(top_charges_autocorr_conv))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps_hmc, top_charges_autocorr_hmc, \n",
    "        marker='', ls='-', label='topological_charge (HMC)')\n",
    "ax.plot(steps_conv, top_charges_autocorr_conv,\n",
    "        marker='', ls='-', label='topological_charges (L2HMC, ConvNet)')\n",
    "#ax.plot(steps1, top_charges_autocorr, marker='', ls='-', label='topological_charge (L2HMC)')\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.set_title(\"\")\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "fig.savefig(os.path.join(model_hmc.figs_dir, \n",
    "                         'top_charge_autocorrelation_fn_hmc.pdf'), \n",
    "            dpi=400, bbox_inches='tight')\n",
    "#ax.set_xlim((-20, 500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#ax.semilogy(steps_hmc, actions_acl_spectrum_hmc, marker='', ls='-', label='total action (HMC)')\n",
    "ax.semilogy(steps_hmc, avg_plaquette_acl_spectrum_hmc, marker='', ls='-', label='average plaquette (HMC)')\n",
    "#ax.plot(steps, actions_acl_spectrum, marker='', ls='-', label='total action (L2HMC)')\n",
    "ax.semilogy(steps, avg_plaquette_acl_spectrum, marker='', ls='-', label='average plaquette (L2HMC)')\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.set_title(\"\")\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "fig.savefig(os.path.join(model_hmc.figs_dir, 'avg_plaquette_autocorrelation_fn_hmc_semilogy.pdf'), \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Using GENERIC NET (Fully-Connected) model: `model_fc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "apply_transition_fc = tfe.defun(model_fc.dynamics.apply_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "  #samples_history = []\n",
    "  #for i in range(eval_iters):\n",
    "    #samples_history.append(samples.numpy())\n",
    "    #_, _, _, samples = apply_transition(samples)\n",
    "  #samples_history = np.array(samples_history)\n",
    "  #print(\"Sampling complete.\")\n",
    "  #sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#samples_fc = tf.random_normal(shape=model_fc.samples.shape)\n",
    "samples_fc = model_fc.samples\n",
    "samples_history_fc = []\n",
    "actions_history_fc = []\n",
    "avg_plaquettes_history_fc = []\n",
    "top_charges_history_fc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_, _, _, _samples_fc = apply_transition_fc(samples_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_observables_fc = model_fc.lattice.calc_plaq_observables(_samples_fc.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_observables_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    samples_history_fc.append(samples_fc.numpy())\n",
    "    t0 = time.time()\n",
    "    _, _, _, samples_fc = apply_transition_fc(samples_fc)\n",
    "    observables_fc = np.array(\n",
    "        model_fc.lattice.calc_plaq_observables(samples_fc.numpy())\n",
    "    ).T\n",
    "    actions_history_fc.append(observables_fc[0])\n",
    "    avg_plaquettes_history_fc.append(observables_fc[1])\n",
    "    top_charges_history_fc.append(observables_fc[2])\n",
    "    step_time = (time.time() - t0) / (model_fc.num_steps * model_fc.batch_size)\n",
    "    print(f'step: {i}  time/step: {step_time:^6.4g} '\n",
    "          f'top_charge: {np.mean(observables_conv[2]):^6.4g} '\n",
    "          f'avg_plaq: {np.mean(observables_conv[1]):^6.4g}')\n",
    "    #print(f'step: {i}  time/step: {step_time:^6.4g}  avg_plaq: {np.mean(observables_fc[1]):^6.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_history_fc = np.array(samples_history_fc)\n",
    "actions_history_fc = np.array(actions_history_fc)\n",
    "avg_plaquettes_history_fc = np.array(avg_plaquettes_history_fc)\n",
    "top_charges_history_fc = np.array(top_charges_history_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_charges_autocorr0_fc = autocorr(top_charges_history_fc[:, 0])\n",
    "top_charges_autocorr1_fc = autocorr(top_charges_history_fc[:, 1])\n",
    "\n",
    "top_charges_autocorr_fc = (top_charges_autocorr0_fc \n",
    "                            + top_charges_autocorr1_fc) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaquettes_autocorr0_fc = autocorr(avg_plaquettes_history_fc[:, 0])\n",
    "avg_plaquettes_autocorr1_fc = autocorr(avg_plaquettes_history_fc[:, 1])\n",
    "\n",
    "avg_plaquettes_autocorr_fc = (avg_plaquettes_autocorr0_fc\n",
    "                              + avg_plaquettes_autocorr1_fc) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Topological Charge Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps_fc = np.arange(len(top_charges_autocorr_fc))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#ax.plot(steps_hmc, top_charges_autocorr_hmc, \n",
    "#        marker='', ls='-', label='topological_charge (HMC)')\n",
    "ax.plot(steps_fc, top_charges_autocorr_fc,\n",
    "        marker='', ls='-', label='topological_charges (L2HMC, FCNet)')\n",
    "#ax.plot(steps1, top_charges_autocorr, marker='', ls='-', label='topological_charge (L2HMC)')\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.set_title(\"\")\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "fig.savefig(os.path.join(model_fc.figs_dir, \n",
    "                         'top_charge_autocorrelation_fn_hmc.pdf'), \n",
    "            dpi=400, bbox_inches='tight')\n",
    "#ax.set_xlim((-20, 500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Average Plaquette Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps_fc = np.arange(len(avg_plaquettes_autocorr_fc))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#ax.plot(steps_hmc, avg_plaquettes_autocorr_hmc, \n",
    "#        marker='', ls='-', label='topological_charge (HMC)')\n",
    "ax.plot(steps_fc, avg_plaquettes_autocorr_fc,\n",
    "        marker='', ls='-', label='Average Plaquettes (L2HMC, FCNet)')\n",
    "#ax.plot(steps1, avg_plaquettes_autocorr, marker='', ls='-', label='topological_charge (L2HMC)')\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.set_title(\"\")\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "fig.savefig(os.path.join(model_fc.figs_dir, \n",
    "                         'avg_plaquettes_autocorrelation_fn_hmc.pdf'), \n",
    "            dpi=400, bbox_inches='tight')\n",
    "#ax.set_xlim((-20, 500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "apply_transition_conv = tfe.defun(model_conv.dynamics.apply_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_fc = np.array(model.lattice.samples.reshape((model.batch_size, -1)), dtype=np.float32)\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "apply_transition = tfe.defun(model.dynamics.apply_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples = tf.random_normal(shape=model.samples.shape)\n",
    "samples_history = []\n",
    "actions_history = []\n",
    "avg_plaquettes_history = []\n",
    "top_charges_history = []\n",
    "for i in range(5000):\n",
    "    samples_history.append(samples.numpy())\n",
    "    t0 = time.time()\n",
    "    _, _, _, samples = apply_transition(samples)\n",
    "    observables = np.array(model.lattice.calc_plaq_observables(samples)).T\n",
    "    actions_history.append(observables[0])\n",
    "    avg_plaquettes_history.append(observables[1])\n",
    "    top_charges_history.append(observables[2])\n",
    "    print(f'step: {i}  time/step: {time.time() - t0:^6.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_history = np.array(samples_history)\n",
    "actions_history = np.array(actions_history)\n",
    "avg_plaquettes_history = np.array(avg_plaquettes_history)\n",
    "top_charges_history = np.array(top_charges_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_charges_autocorr0_conv = autocorr(top_charges_history_conv[:, 0])\n",
    "top_charges_autocorr1_conv = autocorr(top_charges_history_conv[:, 1])\n",
    "avg_plaquette_autocorr0_conv = autocorr(avg_plaquettes_history_conv[:, 0])\n",
    "avg_plaquette_autocorr1_conv = autocorr(avg_plaquettes_history_conv[:, 1])\n",
    "\n",
    "top_charges_autocorr_conv = (top_charges_autocorr0_conv \n",
    "                             + top_charges_autocorr1_conv) / 2\n",
    "avg_plaquette_autocorr_conv = (avg_plaquette_autocorr0_conv\n",
    "                               + avg_plaquette_autocorr1_conv) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Compute Autocorrelation spectrum directly from samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_ac_spectrum = compute_ac_spectrum(samples_history, \n",
    "                                          samples_history_mean,\n",
    "                                          samples_history_var)\n",
    "\n",
    "#ax.plot(steps, samples_ac_spectrum, marker='', ls='-', label='L2HMC')\n",
    "steps = np.arange(len(samples_ac_spectrum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps, samples_ac_spectrum, marker='', ls='-', label='L2HMC')\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.set_title(\"Autocorrelation directly from samples (Eq. 15)\", fontsize=16)\n",
    "ax.legend(loc='best')\n",
    "fig.savefig(os.path.join(model.figs_dir, 'samples_autocorrelation_fn.pdf'), \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Compute Autocorrelation for Topological charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_charges_acl_spectrum = compute_autocorrelation(top_charges_history, \n",
    "                                                   top_charges_mean,\n",
    "                                                   top_charges_var)\n",
    "actions_acl_spectrum = compute_autocorrelation(actions_history, \n",
    "                                               actions_mean,\n",
    "                                               actions_var)\n",
    "avg_plaquette_acl_spectrum = compute_autocorrelation(avg_plaquettes_history,\n",
    "                                                     avg_plaquettes_mean,\n",
    "                                                     avg_plaquettes_var)\n",
    "steps = np.arange(len(top_charges_acl_spectrum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps, top_charges_acl_spectrum, marker='', ls='-', label='topological_charge (L2HMC)')\n",
    "ax.plot(steps, actions_acl_spectrum, marker='', ls='-', label='total action (L2HMC)')\n",
    "ax.plot(steps, avg_plaquette_acl_spectrum, marker='', ls='-', label='average plaquette (L2HMC)')\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.set_title(\"\")\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "fig.savefig(os.path.join(model.figs_dir, 'observables_autocorrelation_fn.pdf'), \n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_ac_spectrum_file = os.path.join(model.info_dir,\n",
    "                                        'samples_ac_spectrum.pkl')\n",
    "top_charges_acl_spectrum_file = os.path.join(model.info_dir,\n",
    "                                             'top_charges_acl_spectrum.pkl')\n",
    "actions_acl_spectrum_file = os.path.join(model.info_dir,\n",
    "                                         'actions_acl_spectrum.pkl')\n",
    "avg_plaquette_acl_spectrum_file = os.path.join(model.info_dir,\n",
    "                                               'avg_plaquette_acl_spectrum.pkl')\n",
    "with open(samples_ac_spectrum_file, 'wb') as f:\n",
    "    pickle.dump(samples_ac_spectrum, f)\n",
    "\n",
    "with open(top_charges_acl_spectrum_file, 'wb') as f:\n",
    "    pickle.dump(top_charges_acl_spectrum, f)\n",
    "    \n",
    "with open(actions_acl_spectrum_file, 'wb') as f:\n",
    "    pickle.dump(actions_acl_spectrum, f)\n",
    "    \n",
    "with open(avg_plaquette_acl_spectrum_file, 'wb') as f:\n",
    "    pickle.dump(avg_plaquette_acl_spectrum, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load / Restore from previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_l2hmc = GaugeModelEager(params=params, log_dir='../../gauge_logs_eager/run_40/', restore=True, use_defun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaq_arr_hmc = model.data['average_plaquettes_arr']\n",
    "top_charge_arr_hmc = model.data['topological_charges_arr']\n",
    "total_actions_arr_hmc = model.data['total_actions_arr']\n",
    "steps = np.arange(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaq_arr_hmc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaq_arr_l2hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps = np.arange(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Compare plots across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_run_data(model.data, model.params, steps, model.figs_dir, skip_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "average_plaquettes_file_l2hmc = os.path.join(model_l2hmc.info_dir,\n",
    "                                             'average_plaquettes.npy')\n",
    "top_charge_file_l2hmc = os.path.join(model_l2hmc.info_dir,\n",
    "                                     'topological_charges.npy')\n",
    "total_actions_file_l2hmc = os.path.join(model_l2hmc.info_dir,\n",
    "                                        'total_actions.npy')\n",
    "avg_plaq_arr_l2hmc = np.load(average_plaquettes_file_l2hmc)\n",
    "top_charge_arr_l2hmc = np.load(top_charge_file_l2hmc)\n",
    "total_actions_arr_l2hmc = np.load(total_actions_file_l2hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_l2hmc.topological_charges_arr = []\n",
    "model_l2hmc.average_plaquettes_arr = []\n",
    "model_l2hmc.total_actions_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_l2hmc._update_data(total_actions_arr_l2hmc,\n",
    "                         avg_plaq_arr_l2hmc,\n",
    "                         top_charge_arr_l2hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps, avg_plaq_arr_hmc[:, 0], marker='', markersize=4., ls='--', label=f'Generic HMC (sample 0) (avg: {np.mean(avg_plaq_arr_hmc[:, 0]):^5.4g})')\n",
    "ax.plot(steps, avg_plaq_arr_hmc[:, 1], marker='', markersize=4., ls='--', label=f'Generic HMC (sample 1) (avg: {np.mean(avg_plaq_arr_hmc[:, 1]):^5.4g})')\n",
    "ax.plot(steps, avg_plaq_arr_l2hmc[:, 0], marker='', markersize=4., ls='-', label=f'L2HMC (sample 0) (avg: {np.mean(avg_plaq_arr_l2hmc[:, 0]):^5.4g})')\n",
    "ax.plot(steps, avg_plaq_arr_l2hmc[:, 1], marker='', markersize=4., ls='-', label=f'L2HMC (sample 1) (avg: {np.mean(avg_plaq_arr_l2hmc[:, 1]):^5.4g})')\n",
    "#ax.plot(steps, avg_plaq_arr_l2hmc[:, 0], marker='.', ls='-', label=f'L2HMC (avg: {np.mean(avg_plaq_arr[:, 1]):^5.4g})')\n",
    "#ax.axhline(np.mean(avg_plaq_arr[:,0]), xmin=0, xmax=500, color='C0', ls='-', lw=2., label='Sample 1 (avg)')\n",
    "#ax.axhline(np.mean(avg_plaq_arr[:,1]), xmin=0, xmax=500, color='C1', ls='-', lw=2., label='Sample 2 (avg)')\n",
    "ax.axhline(u1_plaq_exact(params['beta']), xmin=0, xmax=500, color='k', lw=2., label=f\"Exact ({u1_plaq_exact(params['beta']):^5.4g})\")\n",
    "ax.set_ylabel('Avg. Plaquette')\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_xlim((0, 20))\n",
    "ax.legend(loc='best')\n",
    "#file_name = os.path.join(model.figs_dir, 'average_plaquettes.pdf')\n",
    "#fig.savefig(file_name, dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#ax.plot(steps[::5], top_charge_arr[:, 0][::5], marker='.', ls='-', label='sample 1')\n",
    "#ax.plot(steps[::5], top_charge_arr[:, 1][::5], marker='.', ls='-', label='sample 2')\n",
    "_ = ax.plot(steps, top_charge_arr_hmc[:, 0], marker='', markersize=4., ls='--', label=f'Generic HMC (sample 0) (avg: {np.mean(top_charge_arr_hmc[:, 0]):^5.4g})')\n",
    "_ = ax.plot(steps, top_charge_arr_hmc[:, 1], marker='', markersize=4., ls='--', label=f'Generic HMC (sample 1) (avg: {np.mean(top_charge_arr_hmc[:, 1]):^5.4g})')\n",
    "_ = ax.plot(steps, top_charge_arr_l2hmc[:, 0], marker='', markersize=4., ls='-', label=f'L2HMC (sample 0) (avg: {np.mean(top_charge_arr_l2hmc[:, 0]):^5.4g})')\n",
    "_ = ax.plot(steps, top_charge_arr_l2hmc[:, 1], marker='', markersize=4., ls='-', label=f'L2HMC (sample 1) (avg: {np.mean(top_charge_arr_l2hmc[:, 1]):^5.4g})')\n",
    "#ax.axhline(u1_plaq_exact(params['beta']), xmin=0, xmax=500, color='r', label='Exact')\n",
    "_ = ax.set_ylabel('Topological Charge')\n",
    "_ = ax.set_xlabel('Step')\n",
    "_ = ax.legend(loc='best')\n",
    "_ = ax.set_xlim((0, 25))\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#ax.plot(steps[::5], total_action_arr[:, 0][::5], marker='.', ls='-', label='sample 1')\n",
    "#ax.plot(steps[::5], total_action_arr[:, 1][::5], marker='.', ls='-', label='sample 2')\n",
    "_ = ax.plot(steps, total_action_arr_hmc[:, 0], marker='', markersize=4., ls='--', label=f'Generic HMC (sample 0) (avg: {np.mean(total_action_arr_hmc[:, 0]):^5.4g})')\n",
    "_ = ax.plot(steps, total_action_arr_hmc[:, 1], marker='', markersize=4., ls='--', label=f'Generic HMC (sample 1) (avg: {np.mean(total_action_arr_hmc[:, 1]):^5.4g})')\n",
    "_ = ax.plot(steps, total_actions_arr_l2hmc[:, 0], marker='', markersize=4., ls='-', label=f'L2HMC (sample 0) (avg: {np.mean(total_actions_arr_l2hmc[:, 0]):^5.4g})')\n",
    "_ = ax.plot(steps, total_actions_arr_l2hmc[:, 1], marker='', markersize=4., ls='-', label=f'L2HMC (sample 1) (avg: {np.mean(total_actions_arr_l2hmc[:, 1]):^5.4g})')\n",
    "#ax.axhline(u1_plaq_exact(params['beta']), xmin=0, xmax=500, color='r', label='Exact')\n",
    "_ = ax.set_ylabel('Total Action')\n",
    "_ = ax.set_xlabel('Step')\n",
    "_ = ax.legend(loc='best')\n",
    "_ = ax.set_xlim((0, 25))\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaq1_mean, avg_plaq1_err = calc_avg_vals_errors(avg_plaq_arr[100:, 0], num_blocks=100)\n",
    "avg_plaq2_mean, avg_plaq2_err = calc_avg_vals_errors(avg_plaq_arr[100:, 1], num_blocks=100)\n",
    "print(avg_plaq1_mean, avg_plaq1_err)\n",
    "print(avg_plaq2_mean, avg_plaq2_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u1_plaq_exact(params['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(model.learning_rate.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.data['avg_top_charge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaqs = np.array(model.average_plaquettes_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaqs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u1_plaq_exact(params['beta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build tf.keras.Model using tf.data.Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from u1_model_eager import GaugeModelEager, train_one_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from lattice.gauge_lattice import GaugeLattice, u1_plaq_exact\n",
    "import l2hmc_eager.gauge_dynamics_eager as gde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice = GaugeLattice(time_size=8, \n",
    "                       space_size=8, \n",
    "                       dim=2, \n",
    "                       beta=8., \n",
    "                       link_type='U1',\n",
    "                       num_samples=2,\n",
    "                       rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.calc_plaq_observables(lattice.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.total_action(lattice.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "potential_fn = lattice.get_energy_function(lattice.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dynamics = gde.GaugeDynamicsEager(lattice=lattice,\n",
    "                                  num_steps=10,\n",
    "                                  eps=0.1,\n",
    "                                  minus_loglikelihood_fn=potential_fn,\n",
    "                                  conv_net=True,\n",
    "                                  hmc=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_tensor = tf.convert_to_tensor(lattice.samples, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(samples_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset.output_shapes, dataset.output_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(dynamics.apply_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Iterate over different `eps` and `n_steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eps_arr = np.linspace(0.02, 0.2, 10)\n",
    "n_steps_arr = [5, 10, 15]\n",
    "\n",
    "for eps in eps_arr:\n",
    "    for n_steps in n_steps_arr:\n",
    "        params['eps'] = eps\n",
    "        params['n_steps'] = n_steps\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        model = GaugeModelEager(params=params,\n",
    "                                log_dir=None,\n",
    "                                restore=False,\n",
    "                                use_defun=True)\n",
    "        _ = model.calc_observables(model.samples, _print=True, _write=True)\n",
    "        model.train(1)\n",
    "        \n",
    "        model.train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaq_arr = np.array(model.average_plaquettes_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaq_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaq_arr.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u1_plaq_exact(params['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Graph mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'time_size': 8,\n",
    "    'space_size': 8,\n",
    "    'link_type': 'U1',\n",
    "    'dim': 2,\n",
    "    'beta': 3.5,\n",
    "    'num_samples': 2,\n",
    "    'n_steps': 5,\n",
    "    'eps': 0.05,\n",
    "    'loss_scale': 0.1,\n",
    "    'loss_eps': 1e-4,\n",
    "    'learning_rate_init': 1e-4,\n",
    "    'learning_rate_decay_steps': 100,\n",
    "    'learning_rate_decay_rate': 0.96,\n",
    "    'train_steps': 1000,\n",
    "    'record_loss_every': 50,\n",
    "    'data_steps': 10,\n",
    "    'save_steps': 50,\n",
    "    'print_steps': 1,\n",
    "    'logging_steps': 5,\n",
    "    'clip_value': 100,\n",
    "    'rand': False,\n",
    "    'metric': 'l2',\n",
    "    'conv_net': True,\n",
    "    'hmc': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def graph_step(dynamics, optimizer, samples, params, global_step=None):\n",
    "    clip_val = params.get('clip_value', 10)\n",
    "    loss, samples_out, accept_prob, grads = gde.loss_and_grads(\n",
    "        dynamics=dynamics, \n",
    "        x=samples, \n",
    "        params=params,\n",
    "        loss_fn=gde.compute_loss,\n",
    "        defun=False\n",
    "    )\n",
    "    gradients, _ = tf.clip_by_global_norm(grads, clip_val)\n",
    "    train_op = optimizer.apply_gradients(zip(gradients, dynamics.variables))\n",
    "    return train_op, loss, samples_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    lattice = GaugeLattice(time_size=params.get('time_size', 8),\n",
    "                           space_size=params.get('space_size', 8),\n",
    "                           dim=params.get('dim', 2),\n",
    "                           beta=params.get('beta', '2.5'),\n",
    "                           link_type=params.get('link_type', 'U1'),\n",
    "                           num_samples=params.get('num_samples', 2),\n",
    "                           rand=params.get('rand', False))\n",
    "    batch_size = lattice.samples.shape[0]\n",
    "    samples = tf.convert_to_tensor(\n",
    "        lattice.samples.reshape((batch_size, -1)),\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "    potential_fn = lattice.get_energy_function(samples)\n",
    "\n",
    "    dynamics =  gde.GaugeDynamicsEager(lattice=lattice,\n",
    "                                       n_steps=params.get('n_steps', 10),\n",
    "                                       eps=params.get('eps', 0.1),\n",
    "                                       minus_loglikelihood_fn=potential_fn,\n",
    "                                       conv_net=params.get('conv_net', True),\n",
    "                                       hmc=params.get('hmc', False),\n",
    "                                       defun=False)\n",
    "    x = tf.placeholder(tf.float32, shape=samples.shape)\n",
    "    x_, v_, x_accept_prob, x_out = dynamics.apply_transition(x)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        np_x_, np_v_, np_x_accept_prob, np_x_out =  sess.run(\n",
    "            [x_, v_, x_accept_prob, x_out],\n",
    "            feed_dict={x: lattice.samples.reshape((batch_size, -1))}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#with tf.Graph().as_default():\n",
    "lattice = GaugeLattice(time_size=params.get('time_size', 8),\n",
    "                       space_size=params.get('space_size', 8),\n",
    "                       dim=params.get('dim', 2),\n",
    "                       beta=params.get('beta', '2.5'),\n",
    "                       link_type=params.get('link_type', 'U1'),\n",
    "                       num_samples=params.get('num_samples', 2),\n",
    "                       rand=params.get('rand', False))\n",
    "batch_size = lattice.samples.shape[0]\n",
    "samples_tensor = tf.convert_to_tensor(\n",
    "    lattice.samples.reshape((batch_size, -1)),\n",
    "    dtype=tf.float32\n",
    ")\n",
    "potential_fn = lattice.get_energy_function(samples_tensor)\n",
    "\n",
    "dynamics =  gde.GaugeDynamicsEager(lattice=lattice,\n",
    "                                   n_steps=params.get('n_steps', 10),\n",
    "                                   eps=params.get('eps', 0.1),\n",
    "                                   minus_loglikelihood_fn=potential_fn,\n",
    "                                   conv_net=params.get('conv_net', True),\n",
    "                                   hmc=params.get('hmc', False),\n",
    "                                   defun=False)\n",
    "\n",
    "samples = lattice.samples.reshape((batch_size, -1))\n",
    "x = tf.placeholder(tf.float32, shape=samples_tensor.shape)\n",
    "loss, _, _ = gde.compute_loss(dynamics, x, params, defun=False)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate_init'])\n",
    "train_op, loss, x_out = graph_step(dynamics, optimizer, x, params)\n",
    "\n",
    "session_conf = tf.ConfigProto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#with tf.Session(config=session_conf) as sess:\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Warmup to reduce initialization effect when timing\n",
    "for _ in range(1):\n",
    "    _, _ = sess.run([train_op, loss], feed_dict={x: samples})\n",
    "\n",
    "# Training\n",
    "#start_time = time.time()\n",
    "for i in range(100):\n",
    "    t0 = time.time()\n",
    "    _, loss_np, samples = sess.run([train_op, loss, x_out],\n",
    "                                       feed_dict={x: samples})\n",
    "    print(f\"step: {i}  loss: {loss_np:^6.4g}  time/step: {time.time() - t0:^6.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_one_iter(dynamics, x, optimizer, loss_fn=l2hmc.compute_loss, \n",
    "                   scale=0.1, eps=1e-4, metric='l2', clip_value=10, \n",
    "                   global_step=None):\n",
    "    loss, grads, out, accept_prob = l2hmc.loss_and_grads(\n",
    "        dynamics, x, loss_fn=loss_fn, scale=scale, eps=eps, metric=metric\n",
    "    )\n",
    "    gradients, _ = tf.clip_by_global_norm(grads, clip_value)\n",
    "    optimizer.apply_gradients(\n",
    "        zip(grads, dynamics.trainable_variables), global_step=global_step\n",
    "    )\n",
    "    return loss, out, accept_prob, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def write_run_data(file_path, data, write_mode='a'):\n",
    "    with open(file_path, write_mode) as f:\n",
    "        f.write('\\n')\n",
    "        info_str = (f\"step: {data['step']:<3g} loss: {data['loss']:^6.5g} \"\n",
    "                    f\" time/step: {data['time']:^6.5g} \"\n",
    "                    f\" accept: {data['accept_prob']:^6.5g} \"\n",
    "                    f\" eps: {data['eps']:^6.5g} \"\n",
    "                    f\" avg_S: {data['avg_S']:^6.5g} \"\n",
    "                    f\" avg_topQ: {data['avg_top_charge']:^6.5g} \"\n",
    "                    f\" avg_plaq: {data['avg_plaq']:^6.5g} \\n\")\n",
    "        f.write(info_str)\n",
    "        f.write('\\n')\n",
    "        f.write('avg_plaquettes: {}\\n'.format(data['avg_plaquettes']))\n",
    "        f.write('topological_charges: {}\\n'.format(data['top_charges']))\n",
    "        f.write('total_actions: {}\\n'.format(data['total_actions']))\n",
    "        f.write((len(info_str) + 1)*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def write_run_parameters(file_path, parameters):\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write('Parameters:\\n')\n",
    "        f.write(80 * '-' + '\\n')\n",
    "        for key, val in parameters.items():\n",
    "            f.write(f'{key}: {val}\\n')\n",
    "        f.write(80*'=')\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_run_data(data):\n",
    "    print(f\"\\nstep: {data['step']:<3g} loss: {data['loss']:^6.5g} \"\n",
    "          f\" time/step: {data['time']:^6.5g} \"\n",
    "          f\" accept: {data['accept_prob']:^6.5g} \"\n",
    "          f\" eps: {data['eps']:^6.5g} \"\n",
    "          f\" avg_S: {data['avg_S']:^6.5g} \"\n",
    "          f\" avg_topQ: {data['avg_top_charge']:^6.5g} \"\n",
    "          f\" avg_plaq: {data['avg_plaq']:^6.5g} \\n\")\n",
    "    print('avg_plaquettes: {}\\n'.format(data['avg_plaquettes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_run_data(checkpointer, log_dir, files, data):\n",
    "    saved_path = checkpointer.save(file_prefix=os.path.join(log_dir,\n",
    "                                                            \"ckpt\"))\n",
    "    print(f\"Saved checkpoint to: {saved_path}\")\n",
    "    np.save(files['avg_plaquettes_file'], data['avg_plaquettes_arr'])\n",
    "    np.save(files['total_actions_file'], data['total_actions_arr'])\n",
    "    np.save(files['top_charges_file'], data['top_charges_arr'])\n",
    "    np.save(files['samples_file'], data['samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def write_summaries(summary_writer, data):\n",
    "    with summary_writer.as_default():\n",
    "        with tf.contrib.summary.always_record_summaries():\n",
    "            tf.contrib.summary.scalar(\"Training_loss\", data['loss'],\n",
    "                                      step=data['global_step'])\n",
    "            tf.contrib.summary.scalar(\"avg_plaquettes\", data['avg_plaq'],\n",
    "                                      step=data['global_step'])\n",
    "            tf.contrib.summary.scalar(\"total_actions\", data['avg_S'],\n",
    "                                      step=data['global_step'])\n",
    "            tf.contrib.summary.scalar(\"top_charges\", data['avg_top_charge'],\n",
    "                                      step=data['global_step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def exact_plaquette_average(beta):\n",
    "    return i1(beta) / i0(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct GaugeLattice with $U(1)$ gauge group\n",
    "\n",
    "$$ S[\\theta] = \\beta \\sum_{x;\\,\\, \\nu\\neq\\mu} 1 - \\cos(\\theta_{\\mu\\nu})$$\n",
    "with $\\theta_{\\mu\\nu} \\equiv \\theta_{\\mu}(x) + \\theta_{\\nu}(x +\\hat \\mu) - \\theta_{\\mu}(x + \\hat \\nu) - \\theta_{\\nu}(x)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run L2HMC for $U(1)$ gauge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "##########################  Parameters  #####################################\n",
    "# n_steps: number of leapfrog steps, eps: initial step size for dynamics\n",
    "# loss_scale: scaling factor (lambda^2 in paper) in loss objective\n",
    "# loss_eps: for numeric stability in loss function\n",
    "# beta: inverse coupling strength\n",
    "##############################################################################\n",
    "params = {\n",
    "    'time_size': 8,\n",
    "    'space_size': 8,\n",
    "    'dim': 2,\n",
    "    'beta': 3.5,\n",
    "    'num_samples': 2,\n",
    "    'n_steps': 10,\n",
    "    'eps': 0.05,\n",
    "    'loss_scale': 0.1,\n",
    "    'loss_eps': 1e-4,\n",
    "    'learning_rate': 1e-4,\n",
    "    'learning_rate_decay_steps': 100,\n",
    "    'learning_rate_decay_rate': 0.96,\n",
    "    'train_iters': 500,\n",
    "    'record_loss_every': 50,\n",
    "    'save_steps': 50,\n",
    "    'clip_value': 100,\n",
    "    'rand': False,\n",
    "    'conv_net': True,\n",
    "    'metric': 'l2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     17
    ]
   },
   "outputs": [],
   "source": [
    "u1_lattice = GaugeLattice(time_size=params['time_size'], \n",
    "                          space_size=params['space_size'], \n",
    "                          dim=params['dim'], \n",
    "                          beta=params['beta'],\n",
    "                          link_type='U1', \n",
    "                          num_samples=params['num_samples'], \n",
    "                          rand=params['rand'])\n",
    "if params['conv_net']:\n",
    "    u1_samples_tensor = tf.convert_to_tensor(u1_lattice.samples, \n",
    "                                             dtype=tf.float32)\n",
    "else:\n",
    "    flat_samples = [sample.flatten() for sample in u1_lattice.samples]\n",
    "    u1_samples_tensor = tf.convert_to_tensor(np.stack(flat_samples), \n",
    "                                             dtype=tf.float32)\n",
    "\n",
    "# Construct dynamics object\n",
    "u1_energy_fn = u1_lattice.get_energy_function(u1_samples_tensor)\n",
    "u1_dynamics = l2hmc.GaugeDynamicsEager(lattice=u1_lattice, \n",
    "                                       n_steps=params['n_steps'],\n",
    "                                       eps=params['eps'],\n",
    "                                       minus_loglikelihood_fn=u1_energy_fn, \n",
    "                                       conv_net=params['conv_net'], \n",
    "                                       hmc=False)\n",
    "total_actions = []\n",
    "average_plaquettes = []\n",
    "topological_charges = []\n",
    "samples = u1_samples_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     13,
     17
    ]
   },
   "outputs": [],
   "source": [
    "# Create new log_dir with new run number\n",
    "root_dir = '../../U1_logs/'\n",
    "if not os.path.exists(root_dir):\n",
    "    os.makedirs(root_dir)\n",
    "\n",
    "log_dirs = os.listdir(root_dir)\n",
    "try:\n",
    "    run_nums = [int(i.split('_')[-1]) for i in log_dirs if i.startswith('run')]\n",
    "    run_num = max(run_nums) + 1\n",
    "except:\n",
    "    run_num = 1\n",
    "    \n",
    "log_dir = f'../../U1_logs/run_{run_num}'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "print(f'{log_dir}')\n",
    "    \n",
    "run_files = {\n",
    "    'parameters_file': os.path.join(log_dir, 'parameters.txt'),\n",
    "    'run_info_file': os.path.join(log_dir, 'run_info.txt'),\n",
    "    'avg_plaquettes_file':  os.path.join(log_dir, 'average_plaquettes.npy'),\n",
    "    'total_actions_file': os.path.join(log_dir, 'total_actions.npy'),\n",
    "    'top_charges_file': os.path.join(log_dir, 'topological_charges.npy'),\n",
    "    'samples_file': os.path.join(log_dir, 'samples.npy'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     9
    ]
   },
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "_ = global_step.assign(1)\n",
    "\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=params['learning_rate'], \n",
    "                                           global_step=global_step, \n",
    "                                           decay_steps=params['learning_rate_decay_steps'],\n",
    "                                           decay_rate=params['learning_rate_decay_rate'], \n",
    "                                           staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "checkpointer = tf.train.Checkpoint(\n",
    "    optimizer=optimizer, dynamics=u1_dynamics, global_step=global_step\n",
    ")\n",
    "summary_writer = tf.contrib.summary.create_file_writer(log_dir)\n",
    "loss_fn = l2hmc.compute_loss\n",
    "\n",
    "print(u1_plaq_exact(params['beta']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "################### SAVE INFO ABOUT INITIAL STATE OF LATTICE ###################\n",
    "start_step = global_step.numpy()\n",
    "observables = np.array(u1_lattice.calc_plaq_observables(samples))\n",
    "_total_actions = observables[:, 0]\n",
    "_avg_plaquettes = observables[:, 1]\n",
    "_top_charges = observables[:, 2]\n",
    "\n",
    "total_actions.append(_total_actions)\n",
    "average_plaquettes.append(_avg_plaquettes)\n",
    "topological_charges.append(_top_charges)\n",
    "\n",
    "data = {\n",
    "    'step': 0,\n",
    "    'global_step': global_step.numpy(),\n",
    "    'loss': 0.,\n",
    "    'time': 0.,\n",
    "    'accept_prob': 0.,\n",
    "    'eps': u1_dynamics.eps.numpy(),\n",
    "    'avg_S': np.mean(_total_actions),\n",
    "    'avg_top_charge': np.mean(_top_charges),\n",
    "    'avg_plaq': np.mean(_avg_plaquettes),\n",
    "    'avg_plaquettes': _avg_plaquettes,\n",
    "    'top_charges': _top_charges,\n",
    "    'total_actions': _total_actions,\n",
    "    'avg_plaquettes_arr': average_plaquettes,\n",
    "    'top_charges_arr': topological_charges,\n",
    "    'total_actions_arr': total_actions,\n",
    "    'samples': samples.numpy()\n",
    "}\n",
    "\n",
    "_ = print_run_data(data)\n",
    "_ = write_run_data(run_files['run_info_file'], data, 'w')\n",
    "_ = write_run_parameters(run_files['parameters_file'], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "############################ RUN L2HMC ALGORITHM ############################\n",
    "t0 = time.time()\n",
    "for i in range(start_step, 1000):\n",
    "    t1 = time.time()\n",
    "    loss, samples, accept_prob, grads = train_one_iter(\n",
    "        u1_dynamics,\n",
    "        samples,\n",
    "        optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        scale=loss_scale,\n",
    "        metric=metric,\n",
    "        eps=loss_eps,\n",
    "        clip_value=clip_value,\n",
    "        global_step=global_step\n",
    "    )\n",
    "    observables = np.array(u1_lattice.calc_plaq_observables(samples))\n",
    "    _total_actions = observables[:, 0]\n",
    "    _avg_plaquettes = observables[:, 1]\n",
    "    _top_charges = observables[:, 2]\n",
    "    \n",
    "    total_actions.append(_total_actions)\n",
    "    average_plaquettes.append(_avg_plaquettes)\n",
    "    topological_charges.append(_top_charges)\n",
    "    \n",
    "    data = {\n",
    "        'step': i,\n",
    "        'global_step': global_step.numpy(),\n",
    "        'loss': loss.numpy(),\n",
    "        'time': time.time() - t1,\n",
    "        'accept_prob': accept_prob.numpy().mean(),\n",
    "        'eps': u1_dynamics.eps.numpy(),\n",
    "        'avg_S': np.mean(_total_actions),\n",
    "        'avg_top_charge': np.mean(_top_charges),\n",
    "        'avg_plaq': np.mean(_avg_plaquettes),\n",
    "        'avg_plaquettes': _avg_plaquettes,\n",
    "        'top_charges': _top_charges,\n",
    "        'total_actions': _total_actions,\n",
    "        'avg_plaquettes_arr': np.array(average_plaquettes),\n",
    "        'top_charges_arr': np.array(topological_charges),\n",
    "        'total_actions_arr': np.array(total_actions),\n",
    "        'samples': samples.numpy()\n",
    "    }\n",
    "    \n",
    "    _ = write_run_data(run_files['run_info_file'], data, 'a')\n",
    "    _ = print_run_data(data)\n",
    "    \n",
    "    if i % record_loss_every == 0:\n",
    "        write_summaries(summary_writer, data)\n",
    "\n",
    "    if i % save_steps == 0:\n",
    "        save_run_data(checkpointer, log_dir, run_files, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_plaqs_arr = np.array(average_plaquettes)\n",
    "_avg_plaqs_arr = np.mean(avg_plaqs_arr, axis=0)\n",
    "avg_plaq, avg_plaq_err = calc_avg_vals_errors(avg_plaqs_arr[-400:], num_blocks=10)\n",
    "print(f'avg_plaq (mean from arr): {np.mean(_avg_plaqs_arr)}')\n",
    "print(f'avg_plaq: {avg_plaq} +/- {avg_plaq_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_avg_vals_errors(_avg_plaqs_arr, num_blocks=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Gradients check\n",
    "\n",
    "Want to test that the value of the gradient ($\\partial_x U(x)$) is the same when  \n",
    "calculated using either:\n",
    "1. Tensorflow's automatic differentiation (`tf.gradients`), or\n",
    "2. The analytic expression (Eq. 17) from [reference](https://arxiv.org/pdf/hep-lat/9809160.pdf):\n",
    "$$\\partial_x U(x) = \\beta \\sum_{\\nu \\neq \\mu} \\sin \\theta_{\\mu\\nu}(x - \\hat\\nu) - \\sin \\theta_{\\mu\\nu}(x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fake data used to compare values of the gradient of the potential function\n",
    "samples_ = tf.convert_to_tensor(\n",
    "    [np.arange(128).reshape(u1_lattice.links.shape) for _ in range(4)],\n",
    "    dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# using tensorflow's automatic differentiation \n",
    "tf_grad = u1_dynamics.grad_potential(samples) \n",
    "# 276 ms ± 15.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# using the analytic expression\n",
    "# (Eq. 17 from https://arxiv.org/pdf/hep-lat/9809160.pdf)\n",
    "exact_grad = u1_lattice.grad_action(samples)\n",
    "# 503 ms ± 33.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('exact grad:')\n",
    "print(exact_grad[0].reshape(u1_lattice.links.shape)[:4, :4, 0])\n",
    "print('\\n')\n",
    "print('tf grad:')\n",
    "print(tf_grad[0].numpy().reshape(u1_lattice.links.shape)[:4, :4, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('exact grad:')\n",
    "print(exact_grad[0].reshape(u1_lattice.links.shape)[:4, :4, 1])\n",
    "print('\\n')\n",
    "print('tf grad:')\n",
    "print(tf_grad[0].numpy().reshape(u1_lattice.links.shape)[:4, :4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "################  tests  #############################\n",
    "#u1_lattice._total_action()\n",
    "#u1_lattice._average_plaquette()\n",
    "#u1_lattice.total_action(u1_samples)\n",
    "#u1_lattice.total_action()\n",
    "#u1_lattice.average_plaquette(u1_samples)\n",
    "#u1_lattice.average_plaquette()\n",
    "#---------------------------------------------\n",
    "#_momentum = tf.random_normal(tf.shape(u1_samples))\n",
    "#_potential = np.array(u1_dynamics.potential(u1_samples_tensor))\n",
    "#_kinetic = u1_dynamics.kinetic(_momentum)\n",
    "#_grad_potential = u1_dynamics.grad_potential(u1_samples_tensor)\n",
    "#print(_potential); print('\\n')\n",
    "#print(_kinetic); print('\\n')\n",
    "#print(_grad_potential)\n",
    "#print(_kinetic.numpy()); print('\\n')\n",
    "#print(_hamiltonian.numpy()); print('\\n')\n",
    "#print(_grad_potential[0][:10])\n",
    "#---------------------------------------------\n",
    "#site = u1_lattice.get_random_site()\n",
    "#u = np.random.randint(u1_lattice.dim)\n",
    "#v = np.random.randint(u1_lattice.dim)\n",
    "#plaq = u1_lattice.plaquette_operator(site, u, v)\n",
    "#---------------------------------------------\n",
    "#u1_lattice.total_action(u1_samples_tensor)\n",
    "#u1_lattice.average_plaquette(u1_samples_tensor)\n",
    "#transition_out = u1_dynamics.apply_transition(u1_samples_tensor)\n",
    "#x_post, p_post, accept_prob, x_out = transition_out\n",
    "#loss, x_out, x_accept_prob = l2hmc.compute_loss(u1_dynamics, u1_samples_tensor)\n",
    "#x_accept_prob\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Heatbath Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time_size, space_size, dim, beta, num_samples = (16, 16, 2, 4., 5)\n",
    "u1_lattice = GaugeLattice(time_size, space_size, dim, beta,\n",
    "                          link_type='U1', num_samples=num_samples)\n",
    "u1_samples = [sample.flatten() for sample in u1_lattice.samples]\n",
    "u1_samples_tensor = tf.constant(np.stack(u1_samples), dtype=tf.float32)\n",
    "\n",
    "eq_steps = 5000\n",
    "acceptances = []\n",
    "action_arr = [u1_lattice._total_action()]\n",
    "avg_plaq_arr = [u1_lattice._average_plaquette()]\n",
    "for i in range(eq_steps):\n",
    "    action = u1_lattice._total_action()\n",
    "    avg_plaq = u1_lattice._average_plaquette()\n",
    "    change = avg_plaq - avg_plaq_arr[-1]\n",
    "    avg_plaq_arr.append(avg_plaq)\n",
    "    action_arr.append(action)\n",
    "    print(f\"Step: {i:<5g}\\t action: {action:<8.4g}\\t \"\n",
    "          f\"avg plaq: {avg_plaq:<8.4g}\\t change: {change:<8.4g}\")\n",
    "    accept = 0\n",
    "    for site in u1_lattice.iter_sites():\n",
    "        for d in range(u1_lattice.dim):\n",
    "            accept += u1_lattice._update_link(site, d)\n",
    "    acceptances.append(accept)\n",
    "# 12.2s for 500 equilibration steps\n",
    "\n",
    "avg_plaq_arr = [0]\n",
    "p = k - j\n",
    "for k in range(j, 40000):\n",
    "    avg_plaq = u1_lattice._average_plaquette()\n",
    "    change = avg_plaq - avg_plaq_arr[p-1]\n",
    "    avg_plaq_arr.append(avg_plaq)\n",
    "    print(f\"Step: {k:<5g}: avg plaq: {avg_plaq:>12.4g} change: {change:12.4g}\")\n",
    "    for site in u1_lattice.iter_sites():\n",
    "        for d in range(u1_lattice.dim):\n",
    "            _ = u1_lattice._update_link(site, d)\n",
    "\n",
    "num_acceptances = 0\n",
    "measure_steps = 10000\n",
    "avg_plq = np.zeros(measure_steps)\n",
    "for step in range(measure_steps):\n",
    "    for site in u1_lattice.iter_sites():\n",
    "        for d in range(u1_lattice.dim):\n",
    "            num_acceptances += u1_lattice._update_link(site, d)\n",
    "    avg_plq[step] = u1_lattice._average_plaquette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### GMM Model (test L2HMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sigmas, distribution = gen_ring(1., var=0.02, nb_mixtures=4)\n",
    "\n",
    "gmm_potential = distribution.get_energy_function()\n",
    "gmm_dynamics = _l2hmc.Dynamics(x_dim=2, minus_loglikelihood_fn=gmm_potential,\n",
    "                               n_steps=25, eps=0.1)\n",
    "\n",
    "samples = distribution.get_samples(200)\n",
    "\n",
    "_position = tf.convert_to_tensor(samples, dtype=tf.float32)\n",
    "_momentum = tf.random_normal(tf.shape(_position))\n",
    "_hamiltonian = gmm_dynamics.hamiltonian(_position, _momentum)\n",
    "\n",
    "grad_pot = gmm_dynamics.grad_potential(_position, _momentum)\n",
    "\n",
    "grad_pot.shape\n",
    "\n",
    "gmm_dynamics.masks[0]\n",
    "\n",
    "scale, translation, transformed = gmm_dynamics.position_fn([_position, _momentum, gmm_dynamics._get_time(0)])\n",
    "\n",
    "scale.shape\n",
    "\n",
    "_position.shape\n",
    "\n",
    "gmm_dynamics.masks[0].shape\n",
    "\n",
    "gmm_dynamics.masks[0] * _position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Construct GaugeLattice with SU(3) gauge group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time_size = 2\n",
    "space_size = 4\n",
    "dim = 4\n",
    "beta = 1.\n",
    "link_type = 'SU3' \n",
    "batch_size = 3\n",
    "gauge_lattice = GaugeLattice(time_size, space_size, dim, beta, link_type)\n",
    "# create `num_samples` random samples of GaugeLattice.links\n",
    "links_samples = gauge_lattice.get_links_samples(batch_size, link_type=link_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gauge_energy_fn = gauge_lattice.get_energy_function()\n",
    "gauge_dynamics = l2hmc.GaugeDynamics(gauge_lattice, \n",
    "                                     minus_loglikelihood_fn=gauge_energy_fn, \n",
    "                                     batch_size=3, n_steps=5, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gauge_lattice.links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "potential_arr = gauge_dynamics.potential(links_samples, batch_size)\n",
    "\n",
    "[i.numpy() for i in potential_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_momentum = tf.random_normal(tf.shape(links_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gauge_dynamics.kinetic(_momentum).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_x = links_samples\n",
    "#_momentum = tf.random_normal(tf.shape(_x))\n",
    "_hamiltonian = gauge_dynamics.hamiltonian(_x, _momentum)\n",
    "_hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Construct IsingLattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ising_batch_size = 10\n",
    "ising_lattice = IsingLattice(3, 4)\n",
    "ising_samples = [ising_lattice._randomize() for _ in range(ising_batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ising_energy_fn = ising_lattice.get_energy_function()\n",
    "ising_dynamics = l2hmc.LatticeDynamics(ising_lattice, \n",
    "                                       minus_loglikelihood_fn=ising_energy_fn,\n",
    "                                       batch_size=ising_batch_size, \n",
    "                                       n_steps=10, eps=0.1)\n",
    "#dynamics = l2hmc.LDynamics(latt.sites.shape, minus_loglikelihood_fn=energy_fn, n_steps=10, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ising_dynamics.potential(samples, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_iposition = ising_samples\n",
    "_imomentum = tf.random_normal(tf.shape(_iposition))\n",
    "_ihamiltonian = dynamics.hamiltonian(_iposition, _imomentum)\n",
    "_ihamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_isample = _iposition[0].reshape(ising_lattice.num_sites)\n",
    "#dynamics.grad_potential(np.array(_position).reshape(-1, lattice.num_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grad_pot = dynamics.grad_potential(ising_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ising_jacobian = jacobian(dynamics.potential, ising_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grad_fn = tfe.gradients_function(lattice._calc_energy, params=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_jacobian = jacobian(dynamics.potential, _position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.calc_energy(_position, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dynamics.position_fn(momentum, latt.sites.flatten()[:], dynamics)\n",
    "#dynamics._forward_lf(latt.sites.flatten()[:], momentum, 0)\n",
    "dynamics._forward_lf(np.array(_position).reshape(-1, lattice.num_sites),\n",
    "                     np.array(_momentum).reshape(-1, lattice.num_sites), 1)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
