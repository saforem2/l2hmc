{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic HMC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:20:55.398801Z",
     "start_time": "2018-12-18T02:20:42.174892Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from l2hmc_eager import dynamics_eager as _l2hmc\n",
    "from l2hmc_eager import gauge_dynamics_eager as l2hmc\n",
    "from l2hmc_eager.neural_nets import *\n",
    "from utils.distributions import GMM, gen_ring\n",
    "from utils.jacobian import _map, jacobian\n",
    "from utils.data_utils import (\n",
    "    calc_avg_vals_errors, block_resampling, jackknife_err\n",
    ")\n",
    "\n",
    "from HMC.hmc import HMC\n",
    "\n",
    "from lattice.gauge_lattice import GaugeLattice, pbc, mat_adj, u1_plaq_exact\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:28:59.696064Z",
     "start_time": "2018-12-18T02:28:59.625478Z"
    }
   },
   "outputs": [],
   "source": [
    "from u1_model_eager import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:21:03.489414Z",
     "start_time": "2018-12-18T02:21:03.430016Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:21:05.112701Z",
     "start_time": "2018-12-18T02:21:05.018934Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_iter(dynamics, x, optimizer, loss_fn=l2hmc.compute_loss, \n",
    "                   scale=0.1, eps=1e-4, l2_dist=True, global_step=None):\n",
    "    loss, grads, out, accept_prob = l2hmc.loss_and_grads(\n",
    "        dynamics, x, loss_fn=loss_fn, scale=scale, eps=eps, l2_dist=l2_dist\n",
    "    )\n",
    "    gradients, _ = tf.clip_by_global_norm(grads, 10.)\n",
    "    optimizer.apply_gradients(\n",
    "        zip(grads, dynamics.trainable_variables), global_step=global_step\n",
    "    )\n",
    "    return loss, out, accept_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:21:06.126929Z",
     "start_time": "2018-12-18T02:21:06.062526Z"
    }
   },
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    result /= result[result.argmax()]\n",
    "    return result[result.size//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:21:07.922213Z",
     "start_time": "2018-12-18T02:21:07.840149Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_ac_spectrum(samples_history, target_mean, target_covar):\n",
    "    \"\"\"Compute autocorrelation spectrum.\n",
    "    Follows equation 15 from the L2HMC paper.\n",
    "    Args:\n",
    "        samples_history: Numpy array of shape [T, B, D], where T is the total\n",
    "            number of time steps, B is the batch size, and D is the dimensionality\n",
    "            of sample space.\n",
    "        target_mean: 1D Numpy array of the mean of target(true) distribution.\n",
    "        target_covar: 2D Numpy array representing a symmetric matrix for \n",
    "            variance.\n",
    "    Returns:\n",
    "        Autocorrelation spectrum, Numpy array of shape [T-1].\n",
    "    \"\"\"\n",
    "    # Using numpy here since eager is a bit slow due to the loop\n",
    "    time_steps = samples_history.shape[0]\n",
    "    #trace = np.trace(target_covar)\n",
    "    trace = 1.\n",
    "    rhos = []\n",
    "    for t in range(time_steps - 1):\n",
    "        rho_t = 0.\n",
    "        for tau in range(time_steps - t):\n",
    "            v_tau = samples_history[tau, :] - target_mean\n",
    "            v_tau_plus_t = samples_history[tau + t, :] - target_mean\n",
    "            # Take dot product over observation dims and take mean over batch dims\n",
    "            rho_t = v_tau.T.dot(v_tau_plus_t)\n",
    "            #rho_t += np.mean(np.sum(v_tau * v_tau_plus_t, axis=1))\n",
    "        rho_t /= trace * (time_steps - t)\n",
    "        rhos.append(rho_t)\n",
    "    return np.array(rhos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D $U(1)$ Lattice Gauge Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using L2HMC framework with hmc flag. `hmc=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:35:42.633620Z",
     "start_time": "2018-12-18T02:35:42.541892Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'time_size': 8,\n",
    "    'space_size': 8,\n",
    "    'link_type': 'U1',\n",
    "    'dim': 2,\n",
    "    'beta': 8.,\n",
    "    'num_samples': 2,\n",
    "    'num_steps': 5,\n",
    "    'eps': 0.05,\n",
    "    'loss_scale': 0.1,\n",
    "    'loss_eps': 1e-4,\n",
    "    'learning_rate_init': 1e-4,\n",
    "    'learning_rate_decay_steps': 100,\n",
    "    'learning_rate_decay_rate': 0.96,\n",
    "    'train_steps': 1000,\n",
    "    'record_loss_every': 50,\n",
    "    'data_steps': 10,\n",
    "    'save_steps': 50,\n",
    "    'print_steps': 1,\n",
    "    'logging_steps': 5,\n",
    "    'clip_value': 100,\n",
    "    'rand': False,\n",
    "    'metric': 'l2',\n",
    "    #'conv_net': False,\n",
    "    #'hmc': True,\n",
    "}\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:35:50.541568Z",
     "start_time": "2018-12-18T02:35:50.416155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory for new run: /Users/saforem2/ANL/l2hmc/gauge_logs_eager/run_128/\n",
      "Creating lattice...\n",
      "done.\n",
      "Creating dynamics...\n",
      "done.\n",
      "total initialization time: 0.029989242553710938\n",
      "\n",
      "################################################################################\n",
      "Model parameters:\n",
      "log_dir: /Users/saforem2/ANL/l2hmc/gauge_logs_eager/run_128/\n",
      "\n",
      "info_dir: /Users/saforem2/ANL/l2hmc/gauge_logs_eager/run_128/run_info/\n",
      "\n",
      "figs_dir: /Users/saforem2/ANL/l2hmc/gauge_logs_eager/run_128/figures/\n",
      "\n",
      "_defun: True\n",
      "\n",
      "conv_net: False\n",
      "\n",
      "hmc: True\n",
      "\n",
      "time_size: 8\n",
      "\n",
      "space_size: 8\n",
      "\n",
      "link_type: U1\n",
      "\n",
      "dim: 2\n",
      "\n",
      "beta: 8.0\n",
      "\n",
      "num_samples: 2\n",
      "\n",
      "num_steps: 5\n",
      "\n",
      "eps: 0.05\n",
      "\n",
      "loss_scale: 0.1\n",
      "\n",
      "loss_eps: 0.0001\n",
      "\n",
      "learning_rate_init: 0.0001\n",
      "\n",
      "learning_rate_decay_steps: 100\n",
      "\n",
      "learning_rate_decay_rate: 0.96\n",
      "\n",
      "train_steps: 1000\n",
      "\n",
      "record_loss_every: 50\n",
      "\n",
      "data_steps: 10\n",
      "\n",
      "save_steps: 50\n",
      "\n",
      "print_steps: 1\n",
      "\n",
      "logging_steps: 5\n",
      "\n",
      "clip_value: 100\n",
      "\n",
      "rand: False\n",
      "\n",
      "metric: l2\n",
      "\n",
      "batch_size: 2\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_hmc = GaugeModelEager(params=params,\n",
    "                            conv_net=False,\n",
    "                            hmc=True,\n",
    "                            log_dir=None,\n",
    "                            restore=False,\n",
    "                            defun=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:35:52.552697Z",
     "start_time": "2018-12-18T02:35:52.332914Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================\n",
      "    STEP        LOSS   TIME/STEP  ACCEPT %    EPS      ACTION    TOP Q      PLAQ   \n",
      "------------------------------------------------------------------------------------\n",
      "    0/1000       0         0         0        0.05       0         0         1     \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "observables_hmc = model_hmc.calc_observables(model_hmc.samples, \n",
    "                                             _print=True, \n",
    "                                             _write=True)\n",
    "total_actions, avg_plaquettes, top_charges = observables_hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:29:31.625988Z",
     "start_time": "2018-12-18T02:29:05.292775Z"
    }
   },
   "outputs": [],
   "source": [
    "start_step = model_hmc.global_step.numpy()\n",
    "samples = model_hmc.samples\n",
    "\n",
    "loss, samples, accept_prob, grads = train_one_iter(\n",
    "    dynamics=model_hmc.dynamics,\n",
    "    samples=samples,\n",
    "    optimizer=model_hmc.optimizer,\n",
    "    loss_fn=model_hmc.loss_fn,\n",
    "    global_step=model_hmc.global_step,\n",
    "    params=model_hmc.params,\n",
    "    hmc=model_hmc.hmc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T04:21:33.710281Z",
     "start_time": "2018-12-18T02:35:59.224227Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-72e8e3c2dfae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_hmc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~/ANL/l2hmc/l2hmc/u1_model_eager.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, num_train_steps, keep_samples)\u001b[0m\n\u001b[0;32m    481\u001b[0m                 \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m                 \u001b[0mhmc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhmc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m             )\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/ANL/l2hmc/l2hmc/u1_model_eager.py\u001b[0m in \u001b[0;36mtrain_one_iter\u001b[1;34m(dynamics, samples, optimizer, loss_fn, params, global_step, hmc)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mloss_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mhmc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhmc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     )\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/ANL/l2hmc/l2hmc/l2hmc_eager/gauge_dynamics_eager.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[1;34m(dynamics, x, params, loss_fn, hmc)\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;31m#  if not hmc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdynamics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdynamics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    965\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_inputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backprop_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_backprop_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    628\u001b[0m     \"\"\"\n\u001b[0;32m    629\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backward_graph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_backprop_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_backprop_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[0mbackwards_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradients_wrt_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m     self._backward_graph_function = Function(\n\u001b[1;32m--> 616\u001b[1;33m         backwards_graph, attrs=self._attrs)\n\u001b[0m\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_backprop_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func_graph, attrs)\u001b[0m\n\u001b[0;32m    482\u001b[0m     self._inference_function = _EagerDefinedFunction(\n\u001b[0;32m    483\u001b[0m         \u001b[0m_inference_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m         self._func_graph.inputs, self._func_graph.outputs, self._attrs)\n\u001b[0m\u001b[0;32m    485\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backward_graph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, graph, inputs, outputs, attrs)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \"\"\"\n\u001b[0;32m    321\u001b[0m     operations = [\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[0mop\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_operations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     ]\n",
      "\u001b[1;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    321\u001b[0m     operations = [\n\u001b[0;32m    322\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_operations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m     ]\n\u001b[0;32m    325\u001b[0m     fn = pywrap_tensorflow.TF_GraphToFunction_wrapper(\n",
      "\u001b[1;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    321\u001b[0m     operations = [\n\u001b[0;32m    322\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_operations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m     ]\n\u001b[0;32m    325\u001b[0m     fn = pywrap_tensorflow.TF_GraphToFunction_wrapper(\n",
      "\u001b[1;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;34m\"\"\"The `Operation` that produces this tensor as an output.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_hmc.train(500, keep_samples=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using HMC.hmc method (separate from L2HMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:19:26.445583Z",
     "start_time": "2018-12-18T02:19:26.340678Z"
    }
   },
   "outputs": [],
   "source": [
    "lattice = GaugeLattice(time_size=params['time_size'],\n",
    "                       space_size=params['space_size'],\n",
    "                       dim=params['dim'],\n",
    "                       beta=params['beta'],\n",
    "                       link_type=params['link_type'],\n",
    "                       num_samples=params['num_samples'],\n",
    "                       rand=params['rand'])\n",
    "#samples = np.array([sample.flatten() for sample in lattice.samples])\n",
    "lattice_energy_fn = lattice.get_energy_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:19:27.361635Z",
     "start_time": "2018-12-18T02:19:27.284764Z"
    }
   },
   "outputs": [],
   "source": [
    "#step_size = params['eps']\n",
    "step_size = 0.05\n",
    "#n_leapfrog_steps = params['n_steps']\n",
    "n_leapfrog_steps = 5\n",
    "#position_init = samples\n",
    "position_init = lattice.links.flatten()\n",
    "lattice_hmc = HMC(position_init=position_init,\n",
    "                  step_size=step_size,\n",
    "                  n_leapfrog_steps=n_leapfrog_steps,\n",
    "                  potential_fn=lattice_energy_fn,\n",
    "                  beta=lattice.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:19:28.288306Z",
     "start_time": "2018-12-18T02:19:28.224690Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact value of the average plaquette (at 8.0): 0.9352354935294382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 500 steps in ~ 6m 41s\n",
    "links0 = lattice.links.flatten()\n",
    "momentum0 = np.random.randn(*links0.shape)\n",
    "links_arr = [links0]\n",
    "vel_arr = []\n",
    "probs_arr = []\n",
    "total_actions = []\n",
    "average_plaquettes = []\n",
    "topological_charges = []\n",
    "samples_arr = []\n",
    "links1 = links0\n",
    "num_steps = 500\n",
    "print(\"Exact value of the average plaquette \"\n",
    "      f\"(at {params['beta']}): {u1_plaq_exact(params['beta'])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T02:20:20.928982Z",
     "start_time": "2018-12-18T02:19:32.587765Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "step: 0     accept rate: 0.46315    time/step: 0.9393  avg_S:  35.401   avg_topQ: 0.099018  avg_plaq: 0.93086 \n",
      " \n",
      "\n",
      "step: 1     accept rate:    1       time/step: 0.9632  avg_S:  32.466   avg_topQ: 0.031778  avg_plaq: 0.93659 \n",
      " \n",
      "\n",
      "step: 2     accept rate:    1       time/step: 0.9292  avg_S:  24.82    avg_topQ: 0.035451  avg_plaq: 0.95152 \n",
      " \n",
      "\n",
      "step: 3     accept rate: 0.76233    time/step: 1.056   avg_S:  35.84    avg_topQ: -0.050784  avg_plaq:   0.93  \n",
      " \n",
      "\n",
      "step: 4     accept rate: 0.82029    time/step: 0.961   avg_S:  49.175   avg_topQ: 0.085133  avg_plaq: 0.90396 \n",
      " \n",
      "\n",
      "step: 5     accept rate:    1       time/step: 1.017   avg_S:  35.858   avg_topQ: 0.026927  avg_plaq: 0.92997 \n",
      " \n",
      "\n",
      "step: 6     accept rate:    1       time/step: 1.042   avg_S:  33.347   avg_topQ: 0.061325  avg_plaq: 0.93487 \n",
      " \n",
      "\n",
      "step: 7     accept rate:    1       time/step: 1.023   avg_S:  22.991   avg_topQ: 0.046442  avg_plaq:  0.9551 \n",
      " \n",
      "\n",
      "step: 8     accept rate: 0.83292    time/step: 0.9618  avg_S:  29.822   avg_topQ: -0.026191  avg_plaq: 0.94175 \n",
      " \n",
      "\n",
      "step: 9     accept rate: 0.91595    time/step: 1.098   avg_S:  30.936   avg_topQ: -0.026461  avg_plaq: 0.93958 \n",
      " \n",
      "\n",
      "step: 10    accept rate: 0.86433    time/step: 1.028   avg_S:  37.943   avg_topQ: 0.054991  avg_plaq: 0.92589 \n",
      " \n",
      "\n",
      "step: 11    accept rate:    1       time/step: 1.049   avg_S:  39.869   avg_topQ: -0.14871  avg_plaq: 0.92213 \n",
      " \n",
      "\n",
      "step: 12    accept rate:    1       time/step: 0.9404  avg_S:  30.171   avg_topQ: -0.032954  avg_plaq: 0.94107 \n",
      " \n",
      "\n",
      "step: 13    accept rate:    1       time/step: 0.9446  avg_S:  25.324   avg_topQ: -0.027556  avg_plaq: 0.95054 \n",
      " \n",
      "\n",
      "step: 14    accept rate: 0.88133    time/step: 1.059   avg_S:  31.074   avg_topQ: 0.070388  avg_plaq: 0.93931 \n",
      " \n",
      "\n",
      "step: 15    accept rate: 0.91141    time/step: 0.9173  avg_S:  34.703   avg_topQ: 0.0048305  avg_plaq: 0.93222 \n",
      " \n",
      "\n",
      "step: 16    accept rate:    1       time/step: 0.9284  avg_S:  34.458   avg_topQ: -0.067674  avg_plaq:  0.9327 \n",
      " \n",
      "\n",
      "step: 17    accept rate:    1       time/step: 0.9088  avg_S:  35.517   avg_topQ: 0.023865  avg_plaq: 0.93063 \n",
      " \n",
      "\n",
      "step: 18    accept rate:    1       time/step: 0.8505  avg_S:  27.526   avg_topQ: -0.15045  avg_plaq: 0.94624 \n",
      " \n",
      "\n",
      "step: 19    accept rate: 0.81895    time/step: 0.9402  avg_S:  27.526   avg_topQ: -0.15045  avg_plaq: 0.94624 \n",
      " \n",
      "\n",
      "step: 20    accept rate:    1       time/step: 0.8743  avg_S:  24.486   avg_topQ: -0.035471  avg_plaq: 0.95218 \n",
      " \n",
      "\n",
      "step: 21    accept rate: 0.91219    time/step: 0.9556  avg_S:  28.713   avg_topQ: 0.051372  avg_plaq: 0.94392 \n",
      " \n",
      "\n",
      "step: 22    accept rate:    1       time/step: 0.8749  avg_S:  31.369   avg_topQ: -0.011905  avg_plaq: 0.93873 \n",
      " \n",
      "\n",
      "step: 23    accept rate:    1       time/step: 0.8784  avg_S:  23.061   avg_topQ: 0.053381  avg_plaq: 0.95496 \n",
      " \n",
      "\n",
      "step: 24    accept rate: 0.84614    time/step: 0.9087  avg_S:  30.267   avg_topQ: -0.010637  avg_plaq: 0.94088 \n",
      " \n",
      "\n",
      "step: 25    accept rate:    1       time/step: 1.002   avg_S:  24.714   avg_topQ: 0.11016   avg_plaq: 0.95173 \n",
      " \n",
      "\n",
      "step: 26    accept rate: 0.80592    time/step: 0.9009  avg_S:  35.162   avg_topQ: 0.039107  avg_plaq: 0.93132 \n",
      " \n",
      "\n",
      "step: 27    accept rate: 0.97865    time/step: 1.064   avg_S:  32.993   avg_topQ: -0.062468  avg_plaq: 0.93556 \n",
      " \n",
      "\n",
      "step: 28    accept rate: 0.89908    time/step: 1.028   avg_S:  36.135   avg_topQ: -0.060985  avg_plaq: 0.92942 \n",
      " \n",
      "\n",
      "step: 29    accept rate:    1       time/step: 1.077   avg_S:  27.637   avg_topQ: -0.027406  avg_plaq: 0.94602 \n",
      " \n",
      "\n",
      "step: 30    accept rate:    1       time/step: 0.9995  avg_S:  25.768   avg_topQ: -0.015287  avg_plaq: 0.94967 \n",
      " \n",
      "\n",
      "step: 31    accept rate: 0.73183    time/step: 0.9323  avg_S:  25.768   avg_topQ: -0.015287  avg_plaq: 0.94967 \n",
      " \n",
      "\n",
      "step: 32    accept rate: 0.91778    time/step: 1.024   avg_S:  24.069   avg_topQ: 0.094378  avg_plaq: 0.95299 \n",
      " \n",
      "\n",
      "step: 33    accept rate: 0.83016    time/step: 0.9001  avg_S:  31.993   avg_topQ: -0.036817  avg_plaq: 0.93751 \n",
      " \n",
      "\n",
      "step: 34    accept rate: 0.89494    time/step: 0.9189  avg_S:  38.639   avg_topQ: -0.018823  avg_plaq: 0.92453 \n",
      " \n",
      "\n",
      "step: 35    accept rate: 0.91093    time/step: 0.9334  avg_S:  43.249   avg_topQ: -0.12686  avg_plaq: 0.91553 \n",
      " \n",
      "\n",
      "step: 36    accept rate:    1       time/step: 1.033   avg_S:  32.365   avg_topQ: -0.090704  avg_plaq: 0.93679 \n",
      " \n",
      "\n",
      "step: 37    accept rate: 0.88054    time/step: 0.9546  avg_S:  35.118   avg_topQ: -0.087453  avg_plaq: 0.93141 \n",
      " \n",
      "\n",
      "step: 38    accept rate:    1       time/step: 0.8726  avg_S:  30.646   avg_topQ: 0.018634  avg_plaq: 0.94015 \n",
      " \n",
      "\n",
      "step: 39    accept rate: 0.73221    time/step: 0.8368  avg_S:  43.323   avg_topQ: 0.013487  avg_plaq: 0.91538 \n",
      " \n",
      "\n",
      "step: 40    accept rate:    1       time/step: 0.8776  avg_S:  43.961   avg_topQ: 0.079586  avg_plaq: 0.91414 \n",
      " \n",
      "\n",
      "step: 41    accept rate:    1       time/step: 0.9333  avg_S:  42.831   avg_topQ: -0.013029  avg_plaq: 0.91635 \n",
      " \n",
      "\n",
      "step: 42    accept rate:    1       time/step: 0.8949  avg_S:  38.958   avg_topQ: 0.011158  avg_plaq: 0.92391 \n",
      " \n",
      "\n",
      "step: 43    accept rate:    1       time/step: 1.289   avg_S:  34.403   avg_topQ: 0.028508  avg_plaq: 0.93281 \n",
      " \n",
      "\n",
      "step: 44    accept rate: 0.96822    time/step: 0.8713  avg_S:  31.699   avg_topQ: -0.019413  avg_plaq: 0.93809 \n",
      " \n",
      "\n",
      "step: 45    accept rate:    1       time/step: 0.9469  avg_S:  33.643   avg_topQ: -6.1481e-05  avg_plaq: 0.93429 \n",
      " \n",
      "\n",
      "step: 46    accept rate:    1       time/step: 0.8424  avg_S:  20.69    avg_topQ: 0.02481   avg_plaq: 0.95959 \n",
      " \n",
      "\n",
      "step: 47    accept rate: 0.94481    time/step: 0.9639  avg_S:  23.843   avg_topQ: 0.063735  avg_plaq: 0.95343 \n",
      " \n",
      "\n",
      "step: 48    accept rate: 0.94368    time/step:  1.02   avg_S:  28.565   avg_topQ: -0.021404  avg_plaq: 0.94421 \n",
      " \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-79707c3ee07f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msamples_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mlinks1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvel1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlattice_hmc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_transition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mobservables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlattice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calc_plaq_observables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/ANL/l2hmc/l2hmc/HMC/hmc.py\u001b[0m in \u001b[0;36mapply_transition\u001b[1;34m(self, position)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Apply leapfrog steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_leapfrog_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mleapfrog_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_leapfrog_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_post\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum_post\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mposition_post\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum_post\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleapfrog_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/ANL/l2hmc/l2hmc/HMC/hmc.py\u001b[0m in \u001b[0;36m_leapfrog_fn\u001b[1;34m(self, position, momentum, i)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mmomentum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_momentum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mposition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mmomentum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_momentum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/ANL/l2hmc/l2hmc/HMC/hmc.py\u001b[0m in \u001b[0;36m_update_momentum\u001b[1;34m(self, position, momentum, t)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;34m\"\"\"Update momentum in the leapfrog step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_potential_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_grad_potential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad_potential_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/ANL/l2hmc/l2hmc/HMC/hmc.py\u001b[0m in \u001b[0;36m_grad_potential\u001b[1;34m(self, position, check_numerics)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;34m\"\"\"Get gradient of potential function at current position.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotential\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpotential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~/Library/Python/3.6/lib/python/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    368\u001b[0m     \u001b[1;34m\"\"\"Computes the gradient of the decorated function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_and_grad_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_steps):\n",
    "    t1 = time.time()\n",
    "    if isinstance(links1, tf.Tensor):\n",
    "        samples_arr.append(links1.numpy())\n",
    "    else: \n",
    "        samples_arr.append(links1)\n",
    "    links1, vel1, probs1 = lattice_hmc.apply_transition(links1)\n",
    "    \n",
    "    observables = np.array(lattice._calc_plaq_observables(links1))\n",
    "    _total_actions = observables[0]\n",
    "    _avg_plaquettes = observables[1]\n",
    "    _top_charges = observables[2]\n",
    "    \n",
    "    total_actions.append(_total_actions)\n",
    "    average_plaquettes.append(_avg_plaquettes)\n",
    "    topological_charges.append(_top_charges)\n",
    "    print(f'\\nstep: {i:<5g} accept rate: {np.mean(probs1):^8.5g}  '\n",
    "      f' time/step: {time.time() - t1:^6.4g} '\n",
    "      f' avg_S: {np.mean(_total_actions):^8.5g} '\n",
    "      f' avg_topQ: {np.mean(_top_charges):^8.5g} '\n",
    "      f' avg_plaq: {np.mean(_avg_plaquettes):^8.5g}\\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:26:08.779835Z",
     "start_time": "2018-12-15T00:26:08.520106Z"
    }
   },
   "outputs": [],
   "source": [
    "_samples_arr = []\n",
    "for i in range(len(samples_arr)):\n",
    "    if isinstance(samples_arr[i], tf.Tensor):\n",
    "        print(f'{i} (is tensor)')\n",
    "        _samples_arr.append(samples_arr[i].numpy())\n",
    "    else:\n",
    "        print(f'{i} (is not tensor)')\n",
    "        _samples_arr.append(samples_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:26:35.919047Z",
     "start_time": "2018-12-15T00:26:35.794860Z"
    }
   },
   "outputs": [],
   "source": [
    "_samples_arr = np.array(_samples_arr)\n",
    "_samples_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T03:35:37.128158Z",
     "start_time": "2018-12-15T03:35:37.029211Z"
    }
   },
   "outputs": [],
   "source": [
    "target_mean = np.mean(_samples_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T03:38:36.841281Z",
     "start_time": "2018-12-15T03:38:36.355659Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples_autocorr = compute_ac_spectrum(_samples_arr, target_mean=target_mean,\n",
    "                                       target_covar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T20:15:11.692332Z",
     "start_time": "2018-12-14T20:15:11.476162Z"
    }
   },
   "outputs": [],
   "source": [
    "#apply_transition = tfe.defun(lattice_hmc.apply_transition)\n",
    "\n",
    "#_samples = tf.random_normal(shape=links1.shape)\n",
    "#_samples = np.random.randn(*links1.shape)\n",
    "#samples_arr = []\n",
    "#actions_arr = []\n",
    "#plaquettes_arr = []\n",
    "#top_charges_arr = []\n",
    "#for i in range(100):\n",
    "    #samples_arr.append(_samples)\n",
    "    #_samples, _, _ = apply_transition(_samples)\n",
    "    #\n",
    "    #observables = np.array(lattice._calc_plaq_observables(_samples))\n",
    "    #_total_actions = observables[0]\n",
    "    #_avg_plaquettes = observables[1]\n",
    "    #_top_charges = observables[2]\n",
    "    #\n",
    "    #actions_arr.append(_total_actions)\n",
    "    #plaquettes_arr.append(_avg_plaquettes)\n",
    "    #top_charges_arr.append(_top_charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:19:00.159518Z",
     "start_time": "2018-12-15T00:19:00.017882Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:20:07.059787Z",
     "start_time": "2018-12-15T00:20:06.925485Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_arr[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:20:33.234196Z",
     "start_time": "2018-12-15T00:20:33.094932Z"
    }
   },
   "outputs": [],
   "source": [
    "_samples_arr = [samples_arr[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:21:41.648771Z",
     "start_time": "2018-12-15T00:21:41.519222Z"
    }
   },
   "outputs": [],
   "source": [
    "type(samples_arr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:22:11.000254Z",
     "start_time": "2018-12-15T00:22:10.907713Z"
    }
   },
   "outputs": [],
   "source": [
    "isinstance(samples_arr[1], tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:23:22.639776Z",
     "start_time": "2018-12-15T00:23:22.527599Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_arr[2].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:22:22.726591Z",
     "start_time": "2018-12-15T00:22:22.582886Z"
    }
   },
   "outputs": [],
   "source": [
    "_samples_arr.append([i.numpy() for i in samples_arr if isinstance(i, tf.Tensor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:22:34.272211Z",
     "start_time": "2018-12-15T00:22:34.144552Z"
    }
   },
   "outputs": [],
   "source": [
    "_samples_arr = np.array(_samples_arr)\n",
    "_samples_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:18:46.084857Z",
     "start_time": "2018-12-15T00:18:45.914599Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_arr = np.array([sample.numpy() for sample in samples_arr])\n",
    "samples_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:18:12.095715Z",
     "start_time": "2018-12-15T00:18:11.947884Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_arr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T00:17:44.557269Z",
     "start_time": "2018-12-15T00:17:25.403644Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_autocorr = autocorr(samples_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T23:55:27.345664Z",
     "start_time": "2018-12-14T23:55:27.088617Z"
    }
   },
   "outputs": [],
   "source": [
    "top_charge_autocorr4 = autocorr(np.array(topological_charges))\n",
    "steps = np.arange(len(top_charge_autocorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T19:55:32.794139Z",
     "start_time": "2018-12-14T19:55:32.682133Z"
    }
   },
   "outputs": [],
   "source": [
    "top_charge_autocorr3 = autocorr(np.array(topological_charges))\n",
    "steps = np.arange(len(top_charge_autocorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T19:21:41.571826Z",
     "start_time": "2018-12-14T19:21:41.326726Z"
    }
   },
   "outputs": [],
   "source": [
    "top_charge_autocorr2 = autocorr(np.array(topological_charges))\n",
    "steps = np.arange(len(top_charge_autocorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T18:36:44.568956Z",
     "start_time": "2018-12-14T18:36:44.345313Z"
    }
   },
   "outputs": [],
   "source": [
    "top_charge_autocorr1 = autocorr(np.array(topological_charges))\n",
    "steps = np.arange(len(top_charge_autocorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T18:06:34.378281Z",
     "start_time": "2018-12-14T18:06:34.007399Z"
    }
   },
   "outputs": [],
   "source": [
    "top_charge_autocorr = autocorr(np.array(topological_charges))\n",
    "steps = np.arange(len(top_charge_autocorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_autocorr = autocorr(np.array())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-14T18:07:17.869835Z",
     "start_time": "2018-12-14T18:07:17.705594Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T03:40:32.261324Z",
     "start_time": "2018-12-15T03:40:31.765972Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "steps = np.arange(len(top_charge_autocorr))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps, top_charge_autocorr, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {params['eps']}, 5 steps)\")\n",
    "ax.plot(steps, top_charge_autocorr1, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {0.1}, 5 steps)\")\n",
    "ax.plot(steps, top_charge_autocorr2, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {0.025}, 5 steps)\")\n",
    "ax.plot(steps, top_charge_autocorr, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {0.05}, 10 steps)\")\n",
    "ax.plot(steps, top_charge_autocorr4, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {0.025}, 10 steps)\")\n",
    "ax.set_xlabel('Gradient computations')\n",
    "ax.set_ylabel('Autocorrelation of Topological Charge')\n",
    "#ax.set_xlim((-2, 50))\n",
    "ax.legend(loc='best')\n",
    "fig.savefig(\n",
    "    '../../figures/HMC_autocorrelation_fn/top_charge_autocorr_no_l2hmc.pdf', \n",
    "    dpi=400, bbox_inches='tight'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-15T03:40:02.193802Z",
     "start_time": "2018-12-15T03:40:02.019102Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "steps = np.arange(len(samples_autocorr))\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(steps, samples_autocorr, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {params['eps']}, 5 steps)\")\n",
    "ax.set_xlabel('Gradient computations')\n",
    "ax.set_ylabel('Autocorrelation from Samples')\n",
    "#ax.set_xlim((-2, 50))\n",
    "ax.legend(loc='best')\n",
    "#fig.savefig(\n",
    "#    '../../figures/HMC_autocorrelation_fn/top_charge_autocorr_no_l2hmc.pdf', \n",
    "#    dpi=400, bbox_inches='tight'\n",
    "#)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-24T02:32:05.861348Z",
     "start_time": "2018-11-24T02:32:05.751251Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(average_plaquettes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T13:06:50.663124Z",
     "start_time": "2018-11-19T13:06:50.595424Z"
    }
   },
   "outputs": [],
   "source": [
    "print(u1_plaq_exact(beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using L2HMC with auxiliary functions $Q, S, T \\equiv 0$ (i.e. generic HMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T05:46:15.674100Z",
     "start_time": "2018-11-19T05:46:15.451225Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################  Parameters  #####################################\n",
    "# n_steps: number of leapfrog steps, eps: initial step size for dynamics\n",
    "# loss_scale: scaling factor (lambda^2 in paper) in loss objective\n",
    "# loss_eps: for numeric stability in loss function\n",
    "# beta: inverse coupling strength\n",
    "##############################################################################\n",
    "time_size, space_size, dim, beta, num_samples = (4, 4, 2, 3., 4)\n",
    "n_steps, eps, loss_scale, loss_eps = (10, 0.1, .1, 1e-4)\n",
    "rand=True\n",
    "l2_dist = True\n",
    "conv_net = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T05:46:17.319361Z",
     "start_time": "2018-11-19T05:46:17.243205Z"
    },
    "code_folding": [
     0,
     2,
     5,
     12
    ]
   },
   "outputs": [],
   "source": [
    "u1_lattice = GaugeLattice(time_size, space_size, dim, beta,\n",
    "                          link_type='U1', num_samples=num_samples, rand=rand)\n",
    "if conv_net:\n",
    "    u1_samples_tensor = tf.convert_to_tensor(u1_lattice.samples, \n",
    "                                             dtype=tf.float32)\n",
    "else:\n",
    "    flat_samples = [sample.flatten() for sample in u1_lattice.samples]\n",
    "    u1_samples_tensor = tf.convert_to_tensor(np.stack(flat_samples), \n",
    "                                             dtype=tf.float32)\n",
    "\n",
    "# Construct dynamics object\n",
    "u1_energy_fn = u1_lattice.get_energy_function(u1_samples_tensor)\n",
    "u1_dynamics = l2hmc.GaugeDynamics(u1_lattice, n_steps=n_steps, eps=eps,\n",
    "                                  minus_loglikelihood_fn=u1_energy_fn, \n",
    "                                  conv_net=conv_net, test_HMC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T05:46:18.928851Z",
     "start_time": "2018-11-19T05:46:18.862498Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "_ = global_step.assign(1)\n",
    "train_iters = 500\n",
    "record_loss_every = 50\n",
    "save_steps = 50 \n",
    "\n",
    "learning_rate = tf.train.exponential_decay(1e-2, global_step, 50,\n",
    "                                           0.96, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "checkpointer = tf.train.Checkpoint(\n",
    "    optimizer=optimizer, dynamics=u1_dynamics, global_step=global_step\n",
    ")\n",
    "#summary_writer = tf.contrib.summary.create_file_writer(log_dir)\n",
    "loss_fn = l2hmc.compute_loss\n",
    "\n",
    "print(u1_plaq_exact(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T05:46:20.734300Z",
     "start_time": "2018-11-19T05:46:20.624609Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#################    Run L2HMC algorithm    ##################################\n",
    "total_actions = []\n",
    "average_plaquettes = []\n",
    "topological_charges = []\n",
    "samples = u1_samples_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T10:42:29.851345Z",
     "start_time": "2018-11-19T05:46:23.985470Z"
    },
    "code_folding": [
     4,
     22
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "start_step = global_step.numpy()\n",
    "for i in range(start_step, 1000):\n",
    "    t1 = time.time()\n",
    "    loss, samples, accept_prob = train_one_iter(\n",
    "        u1_dynamics,\n",
    "        samples,\n",
    "        optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        scale=loss_scale,\n",
    "        eps=loss_eps,\n",
    "        global_step=global_step\n",
    "    )\n",
    "    observables = np.array(u1_lattice.calc_plaq_observables(samples))\n",
    "    _total_actions = observables[:, 0]\n",
    "    _avg_plaquettes = observables[:, 1]\n",
    "    _top_charges = observables[:, 2]\n",
    "    \n",
    "    total_actions.append(_total_actions)\n",
    "    average_plaquettes.append(_avg_plaquettes)\n",
    "    topological_charges.append(_top_charges)\n",
    "    \n",
    "    print(f'\\nstep: {i:<5g} loss: {loss.numpy():^8.5g} '\n",
    "          f' time/step: {time.time() - t1:^6.4g} '\n",
    "          f' accept: {accept_prob.numpy().mean():^8.5g} '\n",
    "          f' eps: {u1_dynamics.eps.numpy():^6.4g} '\n",
    "          f' avg_S: {np.mean(_total_actions):^8.5g} '\n",
    "          f' avg_topQ: {np.mean(_top_charges):^8.5g} '\n",
    "          f' avg_plaq: {np.mean(_avg_plaquettes):^8.5g}\\n ')\n",
    "    print('avg_plaquettes: {}\\n'.format([_avg_plaquettes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T13:20:12.126389Z",
     "start_time": "2018-11-19T13:20:12.059084Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = u1_samples_tensor\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T13:26:19.597261Z",
     "start_time": "2018-11-19T13:26:19.531566Z"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.reshape(samples, shape=[samples.shape[0], -1])\n",
    "y = tf.random_normal(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T13:26:33.824256Z",
     "start_time": "2018-11-19T13:26:33.741720Z"
    }
   },
   "outputs": [],
   "source": [
    "xy = tf.matmul(x, y, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T13:28:23.906972Z",
     "start_time": "2018-11-19T13:28:23.836930Z"
    }
   },
   "outputs": [],
   "source": [
    "xy_loss = tf.reduce_sum(xy / (tf.norm(x) * tf.norm(y)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T13:29:27.816539Z",
     "start_time": "2018-11-19T13:29:27.709360Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean((loss_scale / xy_loss - xy_loss / loss_scale), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T13:29:31.176036Z",
     "start_time": "2018-11-19T13:29:31.109158Z"
    }
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T16:55:15.182893Z",
     "start_time": "2018-11-19T16:55:14.823508Z"
    }
   },
   "outputs": [],
   "source": [
    "help(tf.clip_by_global_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T13:21:41.097737Z",
     "start_time": "2018-11-19T13:21:40.978535Z"
    }
   },
   "outputs": [],
   "source": [
    "ss = tf.matmul(samples, samples)\n",
    "print(ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T12:40:03.172443Z",
     "start_time": "2018-11-19T12:40:03.041128Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_plaqs_arr = np.array(average_plaquettes)\n",
    "_avg_plaqs_arr = np.mean(avg_plaqs_arr, axis=0)\n",
    "avg_plaq, avg_plaq_err = calc_avg_vals_errors(avg_plaqs_arr[450:500], num_blocks=50)\n",
    "print(f'avg_plaq (mean from arr): {np.mean(_avg_plaqs_arr)}')\n",
    "print(f'avg_plaq: {avg_plaq} +/- {avg_plaq_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T03:26:57.255969Z",
     "start_time": "2018-11-19T03:26:57.178825Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(average_plaquettes[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T17:08:29.488212Z",
     "start_time": "2018-11-19T17:08:29.375522Z"
    }
   },
   "outputs": [],
   "source": [
    "def project_angle(x):\n",
    "    \"\"\"Function to project an angle from [-4pi, 4pi] to [-pi, pi].\"\"\"\n",
    "    return x - 2 * np.pi * tf.math.floor((x + np.pi) / (2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T17:10:49.058902Z",
     "start_time": "2018-11-19T17:10:48.971455Z"
    }
   },
   "outputs": [],
   "source": [
    "project_angle(-2 * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T17:09:12.544687Z",
     "start_time": "2018-11-19T17:09:12.463838Z"
    }
   },
   "outputs": [],
   "source": [
    "t = np.arange(-10, 10, 0.05)\n",
    "y = project_angle(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-19T17:09:13.867563Z",
     "start_time": "2018-11-19T17:09:13.459503Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, y, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strongly Correlated Gaussian target distribution (for testing HMC implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define log density function of target distribution (potential energy function) $S(x)$\n",
    "\n",
    "$$ S(\\mathbf{x}) = \\frac{-\\frac{1}{2} (\\mathbf{x} - \\mathbf{\\mu})^{T} \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu})}{\\sqrt{|\\Sigma|}} $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:05:25.661962Z",
     "start_time": "2018-10-24T05:05:25.592019Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mu = np.zeros(2)\n",
    "cov = np.array([[1., 0.95], [0.95, 1.]], dtype=np.float32)\n",
    "cov_inv = np.linalg.inv(np.copy(cov))\n",
    "def quadratic_gaussian(x):\n",
    "    x_mu = x - mu\n",
    "    return 0.5 * tf.reduce_sum(tf.transpose(x_mu) * cov_inv * x_mu)\n",
    "\n",
    "def quadratic_gaussian_grad(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:20:41.801881Z",
     "start_time": "2018-10-24T05:20:41.487505Z"
    }
   },
   "outputs": [],
   "source": [
    "mean = [0, 0]\n",
    "cov = [[1., 0.95], [0.95, 1.]]\n",
    "samples_x, samples_y = np.random.multivariate_normal(mean, cov, 1000).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate HMC object for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:20:55.116071Z",
     "start_time": "2018-10-24T05:20:55.032927Z"
    }
   },
   "outputs": [],
   "source": [
    "step_size = 0.1\n",
    "n_leapfrog_steps = 15\n",
    "hmc = HMC(position_init=np.random.randn(2), \n",
    "          step_size=step_size,\n",
    "          n_leapfrog_steps=n_leapfrog_steps,\n",
    "          potential_fn=quadratic_gaussian,\n",
    "          grad_potential_fn=grad_quad_gaussian)\n",
    "          #grad_potential_fn=grad_quad_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:03:30.730373Z",
     "start_time": "2018-10-24T05:03:30.143537Z"
    }
   },
   "outputs": [],
   "source": [
    "pos0 = [[-1., 1.]]\n",
    "pos = [pos0]\n",
    "vel = []\n",
    "probs = []\n",
    "pos1 = pos0\n",
    "\n",
    "for i in range(500):\n",
    "    #pos0 = pos[i-1]\n",
    "    pos1, vel1, probs1 = hmc.apply_transition(pos1)\n",
    "    pos.append(pos1)\n",
    "    vel.append(vel1)\n",
    "    probs.append(probs1)\n",
    "pos = np.array(pos).reshape(len(pos), -1)\n",
    "vel = np.array(vel)\n",
    "probs = np.array(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:03:52.287961Z",
     "start_time": "2018-10-24T05:03:51.751937Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(samples_x, samples_y, marker='o', ls='', alpha=0.45)\n",
    "_ = ax.plot(pos[:,0], pos[:,1], marker='o', ls='', alpha=0.6)\n",
    "_ = ax.set_title('500 transitions, numerical gradient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the leapfrog integrator to tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:03:35.465585Z",
     "start_time": "2018-10-24T05:03:35.380420Z"
    }
   },
   "outputs": [],
   "source": [
    "x0 = np.array([-1., 1.])\n",
    "p0 = np.random.randn(*np.array(x0).shape)\n",
    "x, p = x0, p0\n",
    "x_arr = []\n",
    "p_arr = []\n",
    "for i in range(n_leapfrog_steps):\n",
    "    lf_out = hmc._leapfrog_fn(x, p, i)\n",
    "    x, p = lf_out\n",
    "    x_arr.append(x)\n",
    "    p_arr.append(p)\n",
    "x_arr = np.array(x_arr)\n",
    "p_arr = np.array(p_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:03:44.723110Z",
     "start_time": "2018-10-24T05:03:44.174202Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(samples_x, samples_y, marker='o', ls='', alpha=0.45)\n",
    "_ = ax.plot(x_arr[:,0], x_arr[:,1], marker='.', ls='-', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T05:03:52.287961Z",
     "start_time": "2018-10-24T05:03:51.751937Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(samples_x, samples_y, marker='o', ls='', alpha=0.45)\n",
    "_ = ax.plot(pos[:,0], pos[:,1], marker='o', ls='', alpha=0.6)\n",
    "_ = ax.set_title('500 transitions, numerical gradient')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
