{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic HMC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from l2hmc_eager import dynamics_eager as _l2hmc\n",
    "from l2hmc_eager import gauge_dynamics_eager as l2hmc\n",
    "from l2hmc_eager.neural_nets import *\n",
    "from utils.distributions import GMM, gen_ring\n",
    "from utils.jacobian import _map, jacobian\n",
    "from utils.data_utils import (\n",
    "    calc_avg_vals_errors, block_resampling, jackknife_err\n",
    ")\n",
    "\n",
    "from HMC.hmc import HMC\n",
    "\n",
    "from lattice.gauge_lattice import GaugeLattice, pbc, mat_adj, u1_plaq_exact\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from u1_model_eager import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gauge_model import GaugeModel\n",
    "\n",
    "import utils.gauge_model_helpers as helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_ac_spectrum(samples_history, target_mean, target_covar):\n",
    "    \"\"\"Compute autocorrelation spectrum.\n",
    "    Follows equation 15 from the L2HMC paper.\n",
    "    Args:\n",
    "        samples_history: Numpy array of shape [T, B, D], where T is the total\n",
    "            number of time steps, B is the batch size, and D is the dimensionality\n",
    "            of sample space.\n",
    "        target_mean: 1D Numpy array of the mean of target(true) distribution.\n",
    "        target_covar: 2D Numpy array representing a symmetric matrix for \n",
    "            variance.\n",
    "    Returns:\n",
    "        Autocorrelation spectrum, Numpy array of shape [T-1].\n",
    "    \"\"\"\n",
    "    # Using numpy here since eager is a bit slow due to the loop\n",
    "    time_steps = samples_history.shape[0]\n",
    "    #trace = np.trace(target_covar)\n",
    "    trace = 1.\n",
    "    rhos = []\n",
    "    for t in range(time_steps - 1):\n",
    "        rho_t = 0.\n",
    "        for tau in range(time_steps - t):\n",
    "            v_tau = samples_history[tau, :] - target_mean\n",
    "            v_tau_plus_t = samples_history[tau + t, :] - target_mean\n",
    "            # Take dot product over observation dims and take mean over batch dims\n",
    "            rho_t = v_tau.T.dot(v_tau_plus_t)\n",
    "            #rho_t += np.mean(np.sum(v_tau * v_tau_plus_t, axis=1))\n",
    "        rho_t /= trace * (time_steps - t)\n",
    "        rhos.append(rho_t)\n",
    "    return np.array(rhos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D $U(1)$ Lattice Gauge Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using L2HMC framework with hmc flag. `hmc=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'time_size': 8,\n",
    "    'space_size': 8,\n",
    "    'link_type': 'U1',\n",
    "    'dim': 2,\n",
    "    'beta': 8.,\n",
    "    'num_samples': 5,\n",
    "    'num_steps': 10, \n",
    "    'eps': 0.2,\n",
    "    'loss_scale': 0.1,\n",
    "    'loss_eps': 1e-4,\n",
    "    'learning_rate_init': 1e-4,\n",
    "    'learning_rate_decay_steps': 100,\n",
    "    'learning_rate_decay_rate': 0.96,\n",
    "    'train_steps': 5000,\n",
    "    #'record_loss_every': 50,\n",
    "    #'data_steps': 1,\n",
    "    'save_steps': 500,\n",
    "    #'print_steps': 1,\n",
    "    'logging_steps': 25,\n",
    "    'clip_value': 100,\n",
    "    'rand': False,\n",
    "    'metric': 'l2',\n",
    "    #'conv_net': False,\n",
    "    #'hmc': True,\n",
    "}\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config=tf.ConfigProto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hmc = GaugeModel(params=params,\n",
    "                       config=config,\n",
    "                       sess=None,\n",
    "                       conv_net=False,\n",
    "                       hmc=True,\n",
    "                       log_dir=None,\n",
    "                       restore=False,\n",
    "                       eps_trainable=False,\n",
    "                       aux=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hmc.train(1000, kill_sess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_history = model_hmc.run(250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_hmc = GaugeModelEager(params=params,\n",
    "                            #conv_net=False,\n",
    "                            #hmc=True,\n",
    "                            #log_dir=None,\n",
    "                            #restore=False,\n",
    "                            #defun=False,\n",
    "                            #eps_trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables_hmc = model_hmc.calc_observables(model_hmc.dynamics.samples, \n",
    "                                             update=True)\n",
    "total_actions, avg_plaquettes, top_charges = observables_hmc\n",
    "helpers.print_run_data(model_hmc.data, header=True)\n",
    "helpers.write_run_data(model_hmc.files['run_info_file'],  model_hmc.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, samples_out = model_hmc.dynamics.apply_transition(model_hmc.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hmc.train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_arr = [0]\n",
    "steps_arr.extend(model_hmc.steps_arr)\n",
    "\n",
    "_ = helpers.plot_run_data(model_hmc.data, model_hmc.params, steps_arr, \n",
    "                          model_hmc.figs_dir, skip_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_hmc = tf.random_normal(shape=model_hmc.samples.shape)\n",
    "samples_history_hmc = []\n",
    "actions_history_hmc = []\n",
    "avg_plaquettes_history_hmc = []\n",
    "top_charges_history_hmc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    #samples_history_hmc.append(samples_hmc.numpy())\n",
    "    t0 = time.time()\n",
    "    #_, _, _, samples_hmc = apply_transition_hmc(samples_hmc)\n",
    "    _, _, _, samples_hmc = model_hmc.dynamics.apply_transition(samples_hmc)\n",
    "    observables_hmc = np.array(\n",
    "        model_hmc.lattice.calc_plaq_observables(samples_hmc)\n",
    "    ).T\n",
    "    actions_history_hmc.append(observables_hmc[0])\n",
    "    avg_plaquettes_history_hmc.append(observables_hmc[1])\n",
    "    top_charges_history_hmc.append(observables_hmc[2])\n",
    "    step_time = (time.time() - t0) / (model_hmc.num_steps * model_hmc.batch_size)\n",
    "    print(f'step: {i}  time/step: {step_time:^6.4g} '\n",
    "          f'top_charge: {np.mean(observables_hmc[2]):^6.4g} '\n",
    "          f'avg_plaq: {np.mean(observables_hmc[1]):^6.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_history_hmc = np.array(actions_history_hmc)\n",
    "avg_plaquettes_history_hmc = np.array(avg_plaquettes_history_hmc)\n",
    "top_charges_history_hmc = np.array(top_charges_history_hmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_charges_autocorr0_hmc = autocorr(top_charges_history_hmc[:, 0])\n",
    "top_charges_autocorr1_hmc = autocorr(top_charges_history_hmc[:, 1])\n",
    "\n",
    "top_charges_autocorr_hmc = (top_charges_autocorr0_hmc \n",
    "                            + top_charges_autocorr1_hmc) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_hmc = np.arange(len(top_charges_autocorr_hmc))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#ax.plot(steps_hmc, top_charges_autocorr_hmc, \n",
    "#        marker='', ls='-', label='topological_charge (HMC)')\n",
    "#ax.plot(steps_hmc, avg_plaquettes_autocorr_hmc,\n",
    "#        marker='', ls='--', label='avg plaquettes (L2HMC, hmcNet)')\n",
    "ax.plot(steps_hmc, top_charges_autocorr0_hmc,\n",
    "        marker='', ls='-', label='topological charges (GenericHMC, sample1)')\n",
    "ax.plot(steps_hmc, top_charges_autocorr1_hmc,\n",
    "        marker='', ls='--', label='topological charges (GenericHMC, sample2)')\n",
    "ax.plot(steps_hmc, top_charges_autocorr_hmc,\n",
    "        marker='', ls=':', label='topological charges (GenericHMC, mean)')\n",
    "#ax.plot(steps1, top_charges_autocorr, marker='', ls='-', label='topological_charge (L2HMC)')\n",
    "ax.set_title(r\"$\\epsilon = 0.1$, 10 steps\", fontsize=16)\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "fig.savefig(os.path.join(model_hmc.figs_dir, \n",
    "                         'top_charge_autocorrelation_fn_hmc.pdf'), \n",
    "            dpi=400, bbox_inches='tight')\n",
    "#ax.set_xlim((ax.get_xlim()[0], 1000))\n",
    "#ax.set_xlim((-5, 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using HMC.hmc method (separate from L2HMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = helpers.create_log_dir('gauge_logs_graph/HMC')\n",
    "log_dir, info_dir, figs_dir = dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'time_size': 16,\n",
    "    'space_size': 16,\n",
    "    'link_type': 'U1',\n",
    "    'dim': 2,\n",
    "    'beta': 8.,\n",
    "    'num_samples': 5,\n",
    "    'num_steps': 5, \n",
    "    'eps': 0.1,\n",
    "    'loss_scale': 0.1,\n",
    "    'loss_eps': 1e-4,\n",
    "    'learning_rate_init': 1e-4,\n",
    "    'learning_rate_decay_steps': 100,\n",
    "    'learning_rate_decay_rate': 0.96,\n",
    "    'train_steps': 1000,\n",
    "    'record_loss_every': 50,\n",
    "    'data_steps': 1,\n",
    "    'save_steps': 50,\n",
    "    'print_steps': 1,\n",
    "    'logging_steps': 5,\n",
    "    'clip_value': 100,\n",
    "    'rand': False,\n",
    "    'metric': 'l2',\n",
    "    #'conv_net': False,\n",
    "    #'hmc': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice = GaugeLattice(time_size=params['time_size'],\n",
    "                       space_size=params['space_size'],\n",
    "                       dim=params['dim'],\n",
    "                       beta=params['beta'],\n",
    "                       link_type=params['link_type'],\n",
    "                       num_samples=params['num_samples'],\n",
    "                       rand=params['rand'])\n",
    "samples = np.array([sample.flatten() for sample in lattice.samples])\n",
    "lattice_energy_fn = lattice.get_energy_function(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#position_init = lattice.links.flatten()\n",
    "lattice_hmc = HMC(position_init=samples,\n",
    "                  step_size=params['eps'],\n",
    "                  n_leapfrog_steps=params['num_steps'],\n",
    "                  potential_fn=lattice_energy_fn,\n",
    "                  grad_potential_fn=None,\n",
    "                  beta=lattice.beta)\n",
    "print(\"Exact value of the average plaquette \"\n",
    "      f\"(at {params['beta']}): {u1_plaq_exact(params['beta'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run HMC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "momentum = np.random.randn(*samples.shape)\n",
    "\n",
    "samples_history_dir = os.path.join(log_dir, 'samples_history')\n",
    "if not os.path.isdir(samples_history_dir):\n",
    "    os.makedirs(samples_history_dir)\n",
    "\n",
    "eval_steps_arr = [50, 100, 200, 400, 500, 600, 800, 1000, 5000]\n",
    "for eval_steps in eval_steps_arr:\n",
    "    samples_arr = []\n",
    "    probs_arr = []\n",
    "    for i in range(eval_steps):\n",
    "        t1 = time.time()\n",
    "        if isinstance(samples, tf.Tensor):\n",
    "            samples_arr.append(samples.numpy())\n",
    "        else: \n",
    "            samples_arr.append(samples)\n",
    "        samples, vel, probs = lattice_hmc.apply_transition(samples)\n",
    "        probs_arr.append(probs)\n",
    "        \n",
    "        tt = (time.time() - t1)\n",
    "              #/ (params['num_steps'] \n",
    "              #   * lattice.num_samples \n",
    "              #   * lattice.num_links))\n",
    "        print(f\"\\nstep: {i:<5g} accept rate: {np.mean(probs):^8.5g}  \"\n",
    "              f\" time/step: {tt:^6.4g} \")\n",
    "        samples_history_file = os.path.join(\n",
    "            samples_history_dir,\n",
    "            f'samples_history_{eval_steps}.pkl'\n",
    "        )\n",
    "        accept_prob_history_file = os.path.join(\n",
    "            samples_history_dir,\n",
    "            f'accept_prob_history_{eval_steps}.pkl'\n",
    "        )\n",
    "        with open(samples_history_file, 'wb') as f:\n",
    "            pickle.dump(samples_arr, f)\n",
    "        with open(accept_prob_history_file, 'wb') as f:\n",
    "            pickle.dump(probs_arr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_arr = np.array(samples_arr)\n",
    "samples_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_arr[0][0][:10]\n",
    "samples_arr[1][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "samples_history_file = os.path.join(info_dir, 'samples_history.pkl')\n",
    "parameters_file = os.path.join(info_dir, 'parameters.pkl')\n",
    "with open(samples_history_file, 'wb') as f:\n",
    "    pickle.dump(np.array(samples_arr), f)\n",
    "with open(parameters_file, 'wb') as f:\n",
    "    pickle.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables = np.array([\n",
    "    lattice.calc_plaq_observables(samples=samples_arr[i]) for i in range(100)\n",
    "])\n",
    "#total_actions, avg_plaquettes, top_charges = observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = observables[:, 0, :]\n",
    "plaquettes = observables[:, 1, :]\n",
    "charges = observables[:, 2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9']\n",
    "MARKERS = ['o', 's', 'x', 'v', 'h', '^', 'p', '<', 'd', '>', 'o']\n",
    "LINESTYLES = ['-', '--', ':', '-.', '-', '--', ':', '-.', '-', '--']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for idx in range(actions.shape[1]):\n",
    "    _ = ax.plot(actions[:, idx], label=f'Sample {idx}', color=COLORS[idx])\n",
    "    \n",
    "_ = ax.legend(loc='best')\n",
    "_ = ax.set_xlabel('Step')\n",
    "_ = ax.set_ylabel('Total action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for idx in range(plaquettes.shape[1]):\n",
    "    _ = ax.plot(plaquettes[:, idx], label=f'Sample {idx}', color=COLORS[idx], ls='--')\n",
    "\n",
    "_ = ax.plot(plaquettes.mean(axis=1), label=\"Average\", color='k', alpha=0.8,\n",
    "            lw=3.)\n",
    "    \n",
    "_ = ax.axhline(y=u1_plaq_exact(lattice.beta), \n",
    "               color='r', ls='-', lw=2.5, label='exact')\n",
    "    \n",
    "_ = ax.legend(loc='best')\n",
    "_ = ax.set_xlabel('Step')\n",
    "_ = ax.set_ylabel('Average Plaquette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for idx in range(charges.shape[1]):\n",
    "    _ = ax.plot(charges[:, idx], label=f'Sample {idx}', color=COLORS[idx])\n",
    "    \n",
    "_ = ax.legend(loc='best')\n",
    "_ = ax.set_xlabel('Step')\n",
    "_ = ax.set_ylabel('Topological charge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute autocorrelations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_actions = np.array(total_actions)\n",
    "avg_plaquettes = np.array(avg_plaquettes)\n",
    "top_charges = np.array(top_charges)\n",
    "samples_arr = np.array(samples_arr)\n",
    "print(total_actions.shape, avg_plaquettes.shape, top_charges.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_charges_autocorr = autocorr(top_charges)\n",
    "\n",
    "links_autocorr_arr = [\n",
    "    autocorr(sample) for sample in samples_arr.T\n",
    "]\n",
    "\n",
    "links_autocorr_arr = np.array(links_autocorr_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Save samples, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_history_file = os.path.join(info_dir, 'sample_history.pkl')\n",
    "with open(samples_history_file, 'wb') as f:\n",
    "    _ = pickle.dump(samples_arr, f)\n",
    "    \n",
    "params_file = os.path.join(info_dir, 'parameters.pkl')\n",
    "with open(params_file, 'wb') as f:\n",
    "    _ = pickle.dump(samples_arr, f)\n",
    "    \n",
    "params_txt_file = os.path.join(info_dir, 'parameters.txt')\n",
    "with open(params_txt_file, 'w') as f:\n",
    "    for key, val in params.items():\n",
    "        _ = f.write(f'{key}: {val}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot autocorrelation of top. charge and individual links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_hmc = np.arange(len(top_charges_autocorr))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps_hmc, top_charges_autocorr,\n",
    "        marker='', ls='-')#, label='')\n",
    "title_str = (rf\"$\\epsilon =$ {params['eps']}, {params['num_steps']} steps\")\n",
    "ax.set_title(title_str, fontsize=16)\n",
    "ax.set_ylabel('Autocorrelation (top. charge)', fontsize=14)\n",
    "ax.set_xlabel('step', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "out_file = os.path.join(\n",
    "    figs_dir,  'top_charge_autocorrelation_fn_hmc.pdf'\n",
    ")\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.arange(len(links_autocorr_arr.T))\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(10):\n",
    "    _ = ax.plot(steps, links_autocorr_arr[i, :], label=f'link {i}', ls='-',\n",
    "                alpha=0.7)\n",
    "    #_ = ax.plot(acl_steps, samples_acl_spectrum/samples_acl_spectrum[0], \n",
    "    #            label=f'{key}')\n",
    "_ = ax.plot(steps, links_autocorr_arr.mean(axis=0), label='average',\n",
    "            color='k', lw=2.5)\n",
    "_ = ax.set_xlabel('step', fontsize=14)\n",
    "_ = ax.set_ylabel('Autocorrelation (individual links)', fontsize=14)\n",
    "#_ = ax.legend(loc='best')\n",
    "plt.savefig(os.path.join(figs_dir, 'links_autocorrelation_vs_step.pdf'),\n",
    "            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.arange(len(links_autocorr_arr.T))\n",
    "fig, ax = plot_multiple_lines(steps, links_autocorr_arr[:10, :], \n",
    "                              x_label='steps', \n",
    "                              y_label='Autocorrelation (links)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_mean = np.mean(samples_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples_autocorr = compute_ac_spectrum(samples_arr, target_mean=target_mean,\n",
    "                                       target_covar=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps_hmc = np.arange(len(samples_autocorr))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps_hmc, samples_autocorr,\n",
    "        marker='', ls='-', label='samples (hmc.HMC)')\n",
    "ax.set_title(r\"$\\epsilon = 0.05$, 10 steps\", fontsize=16)\n",
    "ax.set_ylabel('Autocorrelation', fontsize=14)\n",
    "ax.set_xlabel('Gradient Evaluations', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=12)\n",
    "#fig.savefig(os.path.join(model_hmc.figs_dir, \n",
    "#                         'top_charge_autocorrelation_fn_hmc.pdf'), \n",
    "#            dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "apply_transition = tfe.defun(lattice_hmc.apply_transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_samples = tf.random_normal(shape=links1.shape)\n",
    "#_samples = np.random.randn(*links1.shape)\n",
    "samples_arr = []\n",
    "actions_arr = []\n",
    "plaquettes_arr = []\n",
    "top_charges_arr = []\n",
    "for i in range(500):\n",
    "    samples_arr.append(_samples)\n",
    "    _samples, _, _ = apply_transition(_samples)\n",
    "    \n",
    "    observables = np.array(lattice._calc_plaq_observables(_samples))\n",
    "    _total_actions = observables[0]\n",
    "    _avg_plaquettes = observables[1]\n",
    "    _top_charges = observables[2]\n",
    "    \n",
    "    actions_arr.append(_total_actions)\n",
    "    plaquettes_arr.append(_avg_plaquettes)\n",
    "    top_charges_arr.append(_top_charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#apply_transition = tfe.defun(lattice_hmc.apply_transition)\n",
    "\n",
    "#_samples = tf.random_normal(shape=links1.shape)\n",
    "#_samples = np.random.randn(*links1.shape)\n",
    "#samples_arr = []\n",
    "#actions_arr = []\n",
    "#plaquettes_arr = []\n",
    "#top_charges_arr = []\n",
    "#for i in range(100):\n",
    "    #samples_arr.append(_samples)\n",
    "    #_samples, _, _ = apply_transition(_samples)\n",
    "    #\n",
    "    #observables = np.array(lattice._calc_plaq_observables(_samples))\n",
    "    #_total_actions = observables[0]\n",
    "    #_avg_plaquettes = observables[1]\n",
    "    #_top_charges = observables[2]\n",
    "    #\n",
    "    #actions_arr.append(_total_actions)\n",
    "    #plaquettes_arr.append(_avg_plaquettes)\n",
    "    #top_charges_arr.append(_top_charges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Create plots (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps = np.arange(len(top_charge_autocorr))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(steps, top_charge_autocorr, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {params['eps']}, 5 steps)\")\n",
    "ax.plot(steps, top_charge_autocorr1, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {0.1}, 5 steps)\")\n",
    "ax.plot(steps, top_charge_autocorr2, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {0.025}, 5 steps)\")\n",
    "ax.plot(steps, top_charge_autocorr, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {0.05}, 10 steps)\")\n",
    "ax.plot(steps, top_charge_autocorr4, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {0.025}, 10 steps)\")\n",
    "ax.set_xlabel('Gradient computations')\n",
    "ax.set_ylabel('Autocorrelation of Topological Charge')\n",
    "#ax.set_xlim((-2, 50))\n",
    "ax.legend(loc='best')\n",
    "fig.savefig(\n",
    "    '../../figures/HMC_autocorrelation_fn/top_charge_autocorr_no_l2hmc.pdf', \n",
    "    dpi=400, bbox_inches='tight'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "steps = np.arange(len(samples_autocorr))\n",
    "fig, ax = plt.subplots()\n",
    "ax.semilogy(steps, samples_autocorr, ls='-', marker='', \n",
    "        label=f\"HMC (eps: {params['eps']}, 5 steps)\")\n",
    "ax.set_xlabel('Gradient computations')\n",
    "ax.set_ylabel('Autocorrelation from Samples')\n",
    "#ax.set_xlim((-2, 50))\n",
    "ax.legend(loc='best')\n",
    "#fig.savefig(\n",
    "#    '../../figures/HMC_autocorrelation_fn/top_charge_autocorr_no_l2hmc.pdf', \n",
    "#    dpi=400, bbox_inches='tight'\n",
    "#)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(average_plaquettes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(u1_plaq_exact(beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Using L2HMC with auxiliary functions $Q, S, T \\equiv 0$ (i.e. generic HMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##########################  Parameters  #####################################\n",
    "# n_steps: number of leapfrog steps, eps: initial step size for dynamics\n",
    "# loss_scale: scaling factor (lambda^2 in paper) in loss objective\n",
    "# loss_eps: for numeric stability in loss function\n",
    "# beta: inverse coupling strength\n",
    "##############################################################################\n",
    "time_size, space_size, dim, beta, num_samples = (4, 4, 2, 3., 4)\n",
    "n_steps, eps, loss_scale, loss_eps = (10, 0.1, .1, 1e-4)\n",
    "rand=True\n",
    "l2_dist = True\n",
    "conv_net = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     2,
     5,
     12
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u1_lattice = GaugeLattice(time_size, space_size, dim, beta,\n",
    "                          link_type='U1', num_samples=num_samples, rand=rand)\n",
    "if conv_net:\n",
    "    u1_samples_tensor = tf.convert_to_tensor(u1_lattice.samples, \n",
    "                                             dtype=tf.float32)\n",
    "else:\n",
    "    flat_samples = [sample.flatten() for sample in u1_lattice.samples]\n",
    "    u1_samples_tensor = tf.convert_to_tensor(np.stack(flat_samples), \n",
    "                                             dtype=tf.float32)\n",
    "\n",
    "# Construct dynamics object\n",
    "u1_energy_fn = u1_lattice.get_energy_function(u1_samples_tensor)\n",
    "u1_dynamics = l2hmc.GaugeDynamics(u1_lattice, n_steps=n_steps, eps=eps,\n",
    "                                  minus_loglikelihood_fn=u1_energy_fn, \n",
    "                                  conv_net=conv_net, test_HMC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     9
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "_ = global_step.assign(1)\n",
    "train_iters = 500\n",
    "record_loss_every = 50\n",
    "save_steps = 50 \n",
    "\n",
    "learning_rate = tf.train.exponential_decay(1e-2, global_step, 50,\n",
    "                                           0.96, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "checkpointer = tf.train.Checkpoint(\n",
    "    optimizer=optimizer, dynamics=u1_dynamics, global_step=global_step\n",
    ")\n",
    "#summary_writer = tf.contrib.summary.create_file_writer(log_dir)\n",
    "loss_fn = l2hmc.compute_loss\n",
    "\n",
    "print(u1_plaq_exact(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#################    Run L2HMC algorithm    ##################################\n",
    "total_actions = []\n",
    "average_plaquettes = []\n",
    "topological_charges = []\n",
    "samples = u1_samples_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     22
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "start_step = global_step.numpy()\n",
    "for i in range(start_step, 1000):\n",
    "    t1 = time.time()\n",
    "    loss, samples, accept_prob = train_one_iter(\n",
    "        u1_dynamics,\n",
    "        samples,\n",
    "        optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        scale=loss_scale,\n",
    "        eps=loss_eps,\n",
    "        global_step=global_step\n",
    "    )\n",
    "    observables = np.array(u1_lattice.calc_plaq_observables(samples))\n",
    "    _total_actions = observables[:, 0]\n",
    "    _avg_plaquettes = observables[:, 1]\n",
    "    _top_charges = observables[:, 2]\n",
    "    \n",
    "    total_actions.append(_total_actions)\n",
    "    average_plaquettes.append(_avg_plaquettes)\n",
    "    topological_charges.append(_top_charges)\n",
    "    \n",
    "    print(f'\\nstep: {i:<5g} loss: {loss.numpy():^8.5g} '\n",
    "          f' time/step: {time.time() - t1:^6.4g} '\n",
    "          f' accept: {accept_prob.numpy().mean():^8.5g} '\n",
    "          f' eps: {u1_dynamics.eps.numpy():^6.4g} '\n",
    "          f' avg_S: {np.mean(_total_actions):^8.5g} '\n",
    "          f' avg_topQ: {np.mean(_top_charges):^8.5g} '\n",
    "          f' avg_plaq: {np.mean(_avg_plaquettes):^8.5g}\\n ')\n",
    "    print('avg_plaquettes: {}\\n'.format([_avg_plaquettes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples = u1_samples_tensor\n",
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = tf.reshape(samples, shape=[samples.shape[0], -1])\n",
    "y = tf.random_normal(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xy = tf.matmul(x, y, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xy_loss = tf.reduce_sum(xy / (tf.norm(x) * tf.norm(y)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean((loss_scale / xy_loss - xy_loss / loss_scale), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "help(tf.clip_by_global_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ss = tf.matmul(samples, samples)\n",
    "print(ss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaqs_arr = np.array(average_plaquettes)\n",
    "_avg_plaqs_arr = np.mean(avg_plaqs_arr, axis=0)\n",
    "avg_plaq, avg_plaq_err = calc_avg_vals_errors(avg_plaqs_arr[450:500], num_blocks=50)\n",
    "print(f'avg_plaq (mean from arr): {np.mean(_avg_plaqs_arr)}')\n",
    "print(f'avg_plaq: {avg_plaq} +/- {avg_plaq_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(average_plaquettes[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def project_angle(x):\n",
    "    \"\"\"Function to project an angle from [-4pi, 4pi] to [-pi, pi].\"\"\"\n",
    "    return x - 2 * np.pi * tf.math.floor((x + np.pi) / (2 * np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "project_angle(-2 * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t = np.arange(-10, 10, 0.05)\n",
    "y = project_angle(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, y, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Strongly Correlated Gaussian target distribution (for testing HMC implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Define log density function of target distribution (potential energy function) $S(x)$\n",
    "\n",
    "$$ S(\\mathbf{x}) = \\frac{-\\frac{1}{2} (\\mathbf{x} - \\mathbf{\\mu})^{T} \\mathbf{\\Sigma}^{-1}(\\mathbf{x} - \\mathbf{\\mu})}{\\sqrt{|\\Sigma|}} $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mu = np.zeros(2)\n",
    "cov = np.array([[1., 0.95], [0.95, 1.]], dtype=np.float32)\n",
    "cov_inv = np.linalg.inv(np.copy(cov))\n",
    "def quadratic_gaussian(x):\n",
    "    x_mu = x - mu\n",
    "    return 0.5 * tf.reduce_sum(tf.transpose(x_mu) * cov_inv * x_mu)\n",
    "\n",
    "def quadratic_gaussian_grad(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Exact target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mean = [0, 0]\n",
    "cov = [[1., 0.95], [0.95, 1.]]\n",
    "samples_x, samples_y = np.random.multivariate_normal(mean, cov, 1000).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Instantiate HMC object for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "step_size = 0.1\n",
    "n_leapfrog_steps = 15\n",
    "hmc = HMC(position_init=np.random.randn(2), \n",
    "          step_size=step_size,\n",
    "          n_leapfrog_steps=n_leapfrog_steps,\n",
    "          potential_fn=quadratic_gaussian,\n",
    "          grad_potential_fn=grad_quad_gaussian)\n",
    "          #grad_potential_fn=grad_quad_gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos0 = [[-1., 1.]]\n",
    "pos = [pos0]\n",
    "vel = []\n",
    "probs = []\n",
    "pos1 = pos0\n",
    "\n",
    "for i in range(500):\n",
    "    #pos0 = pos[i-1]\n",
    "    pos1, vel1, probs1 = hmc.apply_transition(pos1)\n",
    "    pos.append(pos1)\n",
    "    vel.append(vel1)\n",
    "    probs.append(probs1)\n",
    "pos = np.array(pos).reshape(len(pos), -1)\n",
    "vel = np.array(vel)\n",
    "probs = np.array(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(samples_x, samples_y, marker='o', ls='', alpha=0.45)\n",
    "_ = ax.plot(pos[:,0], pos[:,1], marker='o', ls='', alpha=0.6)\n",
    "_ = ax.set_title('500 transitions, numerical gradient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Look at the leapfrog integrator to tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x0 = np.array([-1., 1.])\n",
    "p0 = np.random.randn(*np.array(x0).shape)\n",
    "x, p = x0, p0\n",
    "x_arr = []\n",
    "p_arr = []\n",
    "for i in range(n_leapfrog_steps):\n",
    "    lf_out = hmc._leapfrog_fn(x, p, i)\n",
    "    x, p = lf_out\n",
    "    x_arr.append(x)\n",
    "    p_arr.append(p)\n",
    "x_arr = np.array(x_arr)\n",
    "p_arr = np.array(p_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(samples_x, samples_y, marker='o', ls='', alpha=0.45)\n",
    "_ = ax.plot(x_arr[:,0], x_arr[:,1], marker='.', ls='-', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = ax.plot(samples_x, samples_y, marker='o', ls='', alpha=0.45)\n",
    "_ = ax.plot(pos[:,0], pos[:,1], marker='o', ls='', alpha=0.6)\n",
    "_ = ax.set_title('500 transitions, numerical gradient')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
