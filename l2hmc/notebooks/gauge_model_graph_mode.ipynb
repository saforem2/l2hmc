{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $U(1)$ Gauge Model using L2HMC in graph mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------\n",
    "### TODO:\n",
    "* [ ] Look at performance on Cooley (longer training runs).\n",
    "* [ ] Fit observables to Eq. \\ref{eq:therm_time} to determine the thermalization time $\\tau$.\n",
    "\n",
    "\\begin{equation} \n",
    "f(t) \\equiv A \\exp^{-t / \\tau}+ \\,\\, B\n",
    "\\label{eq:therm_time}\n",
    "\\end{equation}\n",
    "* [ ] Look at defining a distance metric as the difference in topological charge between two samples and see what effect adding this as an additional term to the loss function has on the models' ability to tunnel between topological sectors.\n",
    "\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import i0, i1\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import utils.gauge_model_helpers as helpers\n",
    "from utils.data_utils import (\n",
    "    calc_avg_vals_errors, block_resampling, jackknife_err\n",
    ")\n",
    "from gauge_model import GaugeModel\n",
    "\n",
    "tfe = tf.contrib.eager\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "params = {\n",
    "    # --------------------- Lattice parameters ----------------------------\n",
    "    'time_size': 8,\n",
    "    'space_size': 8,\n",
    "    'link_type': 'U1',\n",
    "    'dim': 2,\n",
    "    'num_samples': 56,\n",
    "    'rand': False,\n",
    "    'data_format': 'channels_last',\n",
    "    # --------------------- Leapfrog parameters ---------------------------\n",
    "    'num_steps': 4,\n",
    "    'eps': 0.25,\n",
    "    'loss_scale': 1.,\n",
    "    # --------------------- Learning rate parameters ----------------------\n",
    "    'lr_init': 1e-3,\n",
    "    'lr_decay_steps': 1000,\n",
    "    'lr_decay_rate': 0.96,\n",
    "    # --------------------- Annealing rate parameters ---------------------\n",
    "    'annealing': True,\n",
    "    'beta_init': 2.,\n",
    "    'beta_final': 4.,\n",
    "    # --------------------- Training parameters ---------------------------\n",
    "    'train_steps': 10000,\n",
    "    'save_steps': 1000,\n",
    "    'logging_steps': 50,\n",
    "    'print_steps': 1,\n",
    "    'training_samples_steps': 1000,\n",
    "    'training_samples_length': 500,\n",
    "    # --------------------- Model parameters ------------------------------\n",
    "    'network_arch': 'generic',\n",
    "    'hmc': False,\n",
    "    'eps_trainable': True,\n",
    "    'metric': 'cos_diff',\n",
    "    'std_weight': 1.,\n",
    "    'aux_weight': 1.,\n",
    "    'charge_weight': 1.,\n",
    "    'summaries': True,\n",
    "    'clip_grads': False,\n",
    "    'clip_value': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KMP_BLOCKTIME\"] = str(0)\n",
    "os.environ[\"KMP_SETTINGS\"] = str(1)\n",
    "os.environ[\"KMP_AFFINITY\"] = \"granularity=fine,verbose,compact,1,0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(2)\n",
    "config = tf.ConfigProto()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15.7 s to create for 8x8, num_samples=100, num_steps=1\n",
    "# 15.2 s to create for 8x8, num_samples=10, num_steps=3\n",
    "log_dir = os.path.join('/', 'tmp')\n",
    "model = GaugeModel(params=params, \n",
    "                   config=config,\n",
    "                   sess=None,\n",
    "                   log_dir=log_dir,\n",
    "                   restore=False)\n",
    "\n",
    "#save_params_to_pkl_file(params, model.info_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot_ng as pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_pydot():\n",
    "  try:\n",
    "    # Attempt to create an image of a blank graph\n",
    "    # to check the pydot/graphviz installation.\n",
    "    pydot.Dot.create(pydot.Dot())\n",
    "  except Exception:\n",
    "    # pydot raises a generic Exception here,\n",
    "    # so no specific class can be caught.\n",
    "    raise ImportError('Failed to import pydot. You must install pydot'\n",
    "                      ' and graphviz for `pydotprint` to work.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_dot(model, show_shapes=False, show_layer_names=True, rankdir='TB'):\n",
    "  \"\"\"Convert a Keras model to dot format.\n",
    "\n",
    "  Arguments:\n",
    "      model: A Keras model instance.\n",
    "      show_shapes: whether to display shape information.\n",
    "      show_layer_names: whether to display layer names.\n",
    "      rankdir: `rankdir` argument passed to PyDot,\n",
    "          a string specifying the format of the plot:\n",
    "          'TB' creates a vertical plot;\n",
    "          'LR' creates a horizontal plot.\n",
    "\n",
    "  Returns:\n",
    "      A `pydot.Dot` instance representing the Keras model.\n",
    "  \"\"\"\n",
    "  from tensorflow.python.keras.layers.wrappers import Wrapper\n",
    "  from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "  _check_pydot()\n",
    "  dot = pydot.Dot()\n",
    "  dot.set('rankdir', rankdir)\n",
    "  dot.set('concentrate', True)\n",
    "  dot.set_node_defaults(shape='record')\n",
    "\n",
    "  if isinstance(model, Sequential):\n",
    "    if not model.built:\n",
    "      model.build()\n",
    "  layers = model.layers\n",
    "\n",
    "  # Create graph nodes.\n",
    "  for layer in layers:\n",
    "    layer_id = str(id(layer))\n",
    "\n",
    "    # Append a wrapped layer's label to node's label, if it exists.\n",
    "    layer_name = layer.name\n",
    "    class_name = layer.__class__.__name__\n",
    "    if isinstance(layer, Wrapper):\n",
    "      layer_name = '{}({})'.format(layer_name, layer.layer.name)\n",
    "      child_class_name = layer.layer.__class__.__name__\n",
    "      class_name = '{}({})'.format(class_name, child_class_name)\n",
    "\n",
    "    # Create node's label.\n",
    "    if show_layer_names:\n",
    "      label = '{}: {}'.format(layer_name, class_name)\n",
    "    else:\n",
    "      label = class_name\n",
    "\n",
    "    # Rebuild the label as a table including input/output shapes.\n",
    "    if show_shapes:\n",
    "      try:\n",
    "        outputlabels = str(layer.output_shape)\n",
    "      except AttributeError:\n",
    "        outputlabels = 'multiple'\n",
    "      if hasattr(layer, 'input_shape'):\n",
    "        inputlabels = str(layer.input_shape)\n",
    "      elif hasattr(layer, 'input_shapes'):\n",
    "        inputlabels = ', '.join([str(ishape) for ishape in layer.input_shapes])\n",
    "      else:\n",
    "        inputlabels = 'multiple'\n",
    "      label = '%s\\n|{input:|output:}|{{%s}|{%s}}' % (label, inputlabels,\n",
    "                                                     outputlabels)\n",
    "    node = pydot.Node(layer_id, label=label)\n",
    "    dot.add_node(node)\n",
    "\n",
    "  # Connect nodes with edges.\n",
    "  for layer in layers:\n",
    "    layer_id = str(id(layer))\n",
    "    for i, node in enumerate(layer._inbound_nodes):\n",
    "      node_key = layer.name + '_ib-' + str(i)\n",
    "      if node_key in model._network_nodes:  # pylint: disable=protected-access\n",
    "        for inbound_layer in node.inbound_layers:\n",
    "          inbound_layer_id = str(id(inbound_layer))\n",
    "          layer_id = str(id(layer))\n",
    "          dot.add_edge(pydot.Edge(inbound_layer_id, layer_id))\n",
    "  return dot\n",
    "\n",
    "\n",
    "def plot_model(model,\n",
    "               to_file='model.png',\n",
    "               show_shapes=False,\n",
    "               show_layer_names=True,\n",
    "               rankdir='TB'):\n",
    "  \"\"\"Converts a Keras model to dot format and save to a file.\n",
    "\n",
    "  Arguments:\n",
    "      model: A Keras model instance\n",
    "      to_file: File name of the plot image.\n",
    "      show_shapes: whether to display shape information.\n",
    "      show_layer_names: whether to display layer names.\n",
    "      rankdir: `rankdir` argument passed to PyDot,\n",
    "          a string specifying the format of the plot:\n",
    "          'TB' creates a vertical plot;\n",
    "          'LR' creates a horizontal plot.\n",
    "  \"\"\"\n",
    "  dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)\n",
    "  _, extension = os.path.splitext(to_file)\n",
    "  if not extension:\n",
    "    extension = 'png'\n",
    "  else:\n",
    "    extension = extension[1:]\n",
    "  dot.write(to_file, format=extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model.dynamics, to_file='dynamics_model.png',\n",
    "           show_shapes=True, show_layer_names=True, rankdir='LR')\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model.dynamics.position_fn, to_file='dynamics_position_fn.png',\n",
    "           show_shapes=True, show_layer_names=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model.dynamics.momentum_fn, to_file='dynamics_momentum_fn.png',\n",
    "           show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(model.train_data_dict['charges'].values()), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._current_state['samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_charge(x, fft=False):\n",
    "    plaq_sums = (x[:, :, :, 0]\n",
    "                 - x[:, :, :, 1]\n",
    "                 - np.roll(x[:, :, :, 0], shift=-1, axis=2)\n",
    "                 + np.roll(x[:, :, :, 1], shift=-1, axis=1))\n",
    "\n",
    "    if fft:\n",
    "        ps_proj = project_angle_approx(plaq_sums)\n",
    "    else:\n",
    "        ps_proj = project_angle(plaq_sums)\n",
    "\n",
    "    top_charges = np.floor(0.1 + (np.sum(ps_proj, axis=(1, 2)) / (2 * np.pi)))\n",
    "    #top_charges = tf.floor(\n",
    "    #            0.1 + (tf.reduce_sum(project_angle(self._calc_plaq_sums(x)),\n",
    "    #                                 axis=(1, 2), name='top_charges')\n",
    "    #                   / (2 * np.pi))\n",
    "    #        )\n",
    "    \n",
    "    return top_charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = top_charge(np.random.randn(*samples.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model._current_state['samples'].reshape(-1, 8, 8, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array(top_charge(samples, fft=False), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array(top_charge(np.mod(samples, 2*np.pi), fft=False), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lattice.num_plaquettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lattice.calc_plaq_observables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dynamics.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dynamics.built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dynamics.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dynamics.position_fn.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dynamics.position_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_np = np.reshape(\n",
    "    np.array(model.lattice.samples, dtype=np.float32),\n",
    "    (model.num_samples, model.x_dim)\n",
    ")\n",
    "\n",
    "beta_np = model.beta_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = {model.x: samples_np,\n",
    "      model.beta: beta_np}\n",
    "\n",
    "outputs = model.sess.run([\n",
    "    model.train_op,         # apply gradients\n",
    "    model.loss_op,          # calculate loss\n",
    "    model.x_out,            # get new samples\n",
    "    model.px,               # calculate accept. prob\n",
    "    model.dynamics.eps,     # evaluate current step size\n",
    "    model.actions_op,       # calculate avg. actions\n",
    "    model.plaqs_op,         # calculate avg. plaquettes\n",
    "    model.charges_op,       # calculate top. charges\n",
    "    model.lr,               # evaluate learning rate\n",
    "    model.charge_diff_op,   # change in top charge / num_samples \n",
    "], feed_dict=fd)\n",
    "#\n",
    "loss_np = outputs[1]\n",
    "samples_np = outputs[2]\n",
    "px_np = outputs[3]\n",
    "eps_np = outputs[4]\n",
    "actions_np = outputs[5]\n",
    "plaqs_np = outputs[6]\n",
    "charges_np = outputs[7]\n",
    "lr_np = outputs[8]\n",
    "charge_diff = outputs[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charges_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.file_io as io\n",
    "io.save_params_to_pkl_file(params, model.info_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 0.3xx s / step for 8x8, num_samples=100, num_steps=1\n",
    "# ~ 1.3x s / step for 8x8, num_samples=100, num_steps=5\n",
    "# ~ 0.97x s / step for 8x8, num_samples=128, num_steps=3\n",
    "# ~ 0.75x s / step for 8x8, num_samples=20, num_steps=5\n",
    "# ~ 1.5x s / step for 8x8, num_samples=20, num_steps=10\n",
    "model.train(model.train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [3., 4.]\n",
    "for beta in betas:\n",
    "    model.run(50000, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_events_keys = np.array(list(model.tunn_events_dict.keys()))\n",
    "tun_events_vals = np.array(list(model.tunn_events_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tun_events_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(tun_events_vals, marker='.', fillstyle='none', ls='')\n",
    "ax.set_xlabel('Training step', fontsize=14)\n",
    "ax.set_ylabel('Number of events', fontsize=14)\n",
    "title_str = (f'Number of tunneling events vs. '\n",
    "             f'training step for {model.num_samples} samples')\n",
    "ax.set_title(title_str, fontsize=16)\n",
    "out_file = os.path.join(model.figs_dir, 'tunneling_events_vs_training_step.png')\n",
    "print(f\"Saving figure to: {out_file}.\")\n",
    "plt.savefig(out_file, dpi=400, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_events_keys[:10, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = tun_events_keys[:, 0]\n",
    "betas = tun_events_keys[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = plt.subplot(211)\n",
    "ax2 = plt.subplot(212)\n",
    "\n",
    "ax1.plot(steps, tun_events_vals / model.num_samples, \n",
    "         marker='.', fillstyle='none', ls='')\n",
    "ax1.set_xlabel('Training step', fontsize=14)\n",
    "ax2.set_xlabel('Beta', fontsize=16)\n",
    "ax1.set_ylabel('# of tunneling events', fontsize=14)\n",
    "#ax1.set_title(title_str, fontsize=16)\n",
    "\n",
    "ax1.get_shared_x_axes().join(ax1, ax2)\n",
    "ax1.set_xticklabels([])\n",
    "ax2.autoscale() ## call autoscale if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, stats = model.run(1000, beta=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, stats = model.run(100, beta=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tunn_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observables = []\n",
    "stats = []\n",
    "betas = [3., 4.]\n",
    "steps = [5e3, 1e4, 5e4]\n",
    "for step in steps:\n",
    "    for beta in betas:\n",
    "        obs, stats = model.run(step, beta=beta)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_strings = ('steps_50000_beta_4.0', 'steps_50000_beta_3.0')\n",
    "obs_dirs = (os.path.join(model.eval_dir, 'observables', dir_strings[0]),\n",
    "            os.path.join(model.eval_dir, 'observables', dir_strings[1]))\n",
    "samples_history_files = (\n",
    "    os.path.join('samples', 'samples_history_' + dir_strings[0] + '.npy'),\n",
    "    os.path.join('samples', 'samples_history_' + dir_strings[1] + '.npy')\n",
    ")\n",
    "actions_files = (\n",
    "    os.path.join(obs_dirs[0], 'actions_' + dir_strings[0] + '.pkl'),\n",
    "    os.path.join(obs_dirs[1], 'actions_' + dir_strings[1] + '.pkl')\n",
    ")\n",
    "plaqs_files = (\n",
    "    os.path.join(obs_dirs[0], 'plaqs_' + dir_strings[0] + '.pkl'),\n",
    "    os.path.join(obs_dirs[1], 'plaqs_' + dir_strings[1] + '.pkl')\n",
    ")\n",
    "charges_files = (\n",
    "    os.path.join(obs_dirs[0], 'charges_' + dir_strings[0] + '.pkl'),\n",
    "    os.path.join(obs_dirs[1], 'charges_' + dir_strings[1] + '.pkl'))\n",
    "tunn_events_files = (\n",
    "    os.path.join(obs_dirs[0], 'tunn_events_' + dir_strings[0] + '.pkl'),\n",
    "    os.path.join(obs_dirs[1], 'tunn_events_' + dir_strings[1] + '.pkl')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "samples = []\n",
    "for f in samples_files:\n",
    "    samples.append(np.load(f))\n",
    "actions = []\n",
    "for f in actions_files:\n",
    "    with open(f, 'rb') as ff:\n",
    "        actions.append(pickle.load(ff))\n",
    "plaqs = []\n",
    "for f in plaqs_files:\n",
    "    with open(f, 'rb') as ff:\n",
    "        plaqs.append(pickle.load(ff))\n",
    "charges = []\n",
    "for f in charges_files:\n",
    "    with open(f, 'rb') as ff:\n",
    "        charges.append(pickle.load(ff))\n",
    "tunn_events = []\n",
    "for f in tunn_events_files:\n",
    "    with open(f, 'rb') as ff:\n",
    "        tunn_events.append(pickle.load(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for f in samples_history_files:\n",
    "    samples.append(np.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "tunn_events = []\n",
    "for f in tunn_events_files:\n",
    "    with open(f, 'rb') as ff:\n",
    "        tunn_events.append(pickle.load(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for f in samples_files:\n",
    "    with open(f, 'rb') as ff:\n",
    "        samples.append(pickle.load(ff))\n",
    "tunn_events = []\n",
    "for f in tunn_events_files:\n",
    "    with open(f, 'rb') as ff:\n",
    "        tunn_events.append(pickle.load(ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(100, beta=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(500, beta=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(1000, beta=4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(50000, beta=4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(50000, beta=4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(50000, beta=model.beta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(model.files['samples_pkl_file'], 'rb') as f:\n",
    "    samples_init = pickle.load(f)\n",
    "beta_init = model.update_beta(model.data['step'])\n",
    "beta_init\n",
    "model.data['learning_rate']\n",
    "model.data['step']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(50000, beta=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(50000, beta=4.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(50000, beta=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(50000, beta=model.beta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train(model.train_steps, samples_init=samples_init, beta_init=beta_init, \n",
    "#            pre_train=False, trace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(20000, beta=model.beta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(50000, beta=model.beta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 37m 39s for 8x8 with num_steps=1 using slow _total_action method\n",
    "model.run(50000, beta=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(20000, beta=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#betas = [2., 4.]\n",
    "betas = [model.beta_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_steps = [500, 1000, 5000, 10000]#, 20000]#, 50000]#, 6000#, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 8x8 lattice, run 20000 eval steps in ~14m 20s\n",
    "# for 8x8 lattice, run 30000 eval steps in ~21m 31s\n",
    "# for 8x8 lattice, run 50000 eval steps in ~40m 12s\n",
    "for beta in betas:\n",
    "    for steps in run_steps:\n",
    "        model.run(steps, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sess.run(model.dynamics.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sess.run(tf.log(model.dynamics.eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(20000, beta=model.beta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(30000, beta=model.beta_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dynamics.momentum_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in run_steps:\n",
    "    model.run(step, beta=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(10000, beta=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(40000, beta=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run(1000, beta=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for steps in run_steps:\n",
    "    _ = model.run(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.run(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.run(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.run(8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = model.sess.run(model.global_step)\n",
    "model._save_model(samples=None, step=step)\n",
    "\n",
    "#helpers.write_run_data(model.files['run_info_file'], model.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_np = np.array(model.lattice.samples, dtype=np.float32)\n",
    "fd = {model.x: samples_np, model.beta: 8.}\n",
    "model.sess.run(model.dynamics.position_fn.conv_x1, feed_dict=fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_np = np.array(model.lattice.samples, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_x1_kernel, conv_x1_bias = model.dynamics.position_fn.conv_x1.weights\n",
    "conv_x1_kernel_np = model.sess.run(conv_x1_kernel)\n",
    "conv_x1_kernel_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_x2_kernel, conv_x2_bias = model.dynamics.position_fn.conv_x2.weights\n",
    "conv_x2_kernel_np = model.sess.run(conv_x2_kernel)\n",
    "conv_x2_kernel_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv_x1_out = model.dynamics.position_fn.conv_x1(model.x)\n",
    "conv_x1_out_np = model.sess.run(model.dynamics.position_fn.conv_x1, feed_dict={model.x: samples_np,\n",
    "                                                                                      model.beta: 8.})\n",
    "conv_x1_out_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_x1_out = model.sess.run(model.dynamics.position_fn.conv_x1.output, feed_dict={model.x: samples_np, model.beta: 8.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = conv_x2_kernel_np.shape[2]\n",
    "channels = range(conv_x2_kernel_np.shape[2])\n",
    "w_max = np.max(conv_x2_kernel_np)\n",
    "w_min = np.min(conv_x2_kernel_np)\n",
    "\n",
    "for channel in channels:\n",
    "    # create figure and axes\n",
    "    fig, axes = plt.subplots(4, 4)\n",
    "    for idx, ax in enumerate(axes.flat):\n",
    "        img = conv_x2_kernel_np[:, :, channel, idx]\n",
    "        _ = ax.imshow(img, vmin=w_min, vmax=w_max, \n",
    "                      interpolation='nearest', cmap='seismic')\n",
    "        _ = ax.set_xticks([])\n",
    "        _ = ax.set_yticks([])\n",
    "        _ = ax.set_title(f'{channel}, {idx}')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# iterate channels\n",
    "for channel in channels:\n",
    "    # iterate filters inside every channel\n",
    "    for l, ax in enumerate(axes.flat):\n",
    "        # get a single filter\n",
    "        img = weights[:, :, channel, l]\n",
    "        # put it on the grid\n",
    "        ax.imshow(img, vmin=w_min, vmax=w_max, interpolation='nearest', cmap='seismic')\n",
    "        # remove any labels from the axes\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    # save figure\n",
    "    plt.savefig(os.path.join(plot_dir, '{}-{}.png'.format(name, channel)), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = conv_x1_kernel_np[:, :, 0]\n",
    "w_min = np.min(w0)\n",
    "w_max = np.max(w0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_ = ax.imshow(conv_x1_kernel_np[:, :, 0], vmin=w_min, vmax=w_max, \n",
    "          interpolation='nearest', cmap='seismic')\n",
    "# remove any labels from the axes\n",
    "_ = ax.set_xticks([])\n",
    "_ = ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dynamics.position_fn.dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(model.files['parameters_pkl_file'], 'wb') as f:\n",
    "    pickle.dump(model.params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sess.graph.collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sess.graph.get_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dynamics.position_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over samples history and calculate observables for each sample.\n",
    "# `lattice.calc_plaq_observables(samples)` calculates observables for each of\n",
    "# the samples in the mini-batch.\n",
    "actions_history = []\n",
    "avg_plaquettes_history = []\n",
    "top_charges_history = []\n",
    "for idx, samples in enumerate(samples_history):\n",
    "    t0 = time.time()\n",
    "    observables = np.array(model.lattice.calc_plaq_observables(samples))\n",
    "    actions, plaqs, charges = observables\n",
    "    \n",
    "    actions_history.append(actions)\n",
    "    avg_plaquettes_history.append(plaqs)\n",
    "    top_charges_history.append(charges)\n",
    "    \n",
    "    print(f'step: {idx}  '\n",
    "          f'time / step: {time.time() - t0:^6.4g}  '\n",
    "          f'avg action: {np.mean(actions):^6.4g}  '\n",
    "          f'avg plaquette: {np.mean(plaqs):^6.4g} '\n",
    "          f'top charge: {np.mean(charges):^6.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = helpers.plot_run_data(model.data, \n",
    "                          model.params, \n",
    "                          model.steps_arr, \n",
    "                          model.figs_dir, \n",
    "                          skip_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#model = GaugeModel(params=params,\n",
    "#                   config=None,\n",
    "#                   sess=None,\n",
    "#                   conv_net=False,\n",
    "#                   hmc=False,\n",
    "#                   log_dir='../../gauge_logs_graph/run_25',\n",
    "#                   restore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.randn(*model.samples.shape)\n",
    "samples_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    t0 = time.time()\n",
    "    samples = model.sess.run(model.x_out, feed_dict={model.x: samples})\n",
    "    samples_history.append(samples)\n",
    "    print(f'step: {i:^6.4g} time/step: {time.time() - t0:^6.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_history_conv = np.array(samples_history_conv)\n",
    "print(samples_history_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "samples_history_file = os.path.join(model.info_dir, 'samples_history.pkl')\n",
    "with open(samples_history_file, 'wb') as f:\n",
    "    pickle.dump(samples_history_conv, f)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
