{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $U(1)$ Gauge Model using L2HMC in graph mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------\n",
    "### TODO:\n",
    "* [ ] Look at performance on Cooley (longer training runs).\n",
    "* [ ] Fit observables to Eq. \\ref{eq:therm_time} to determine the thermalization time $\\tau$.\n",
    "\n",
    "\\begin{equation} \n",
    "f(t) \\equiv A \\exp^{-t / \\tau}+ \\,\\, B\n",
    "\\label{eq:therm_time}\n",
    "\\end{equation}\n",
    "* [ ] Look at defining a distance metric as the difference in topological charge between two samples and see what effect adding this as an additional term to the loss function has on the models' ability to tunnel between topological sectors.\n",
    "\n",
    "--------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T07:29:33.108657Z",
     "start_time": "2019-02-01T07:29:20.019265Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import i0, i1\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import utils.gauge_model_helpers as helpers\n",
    "from utils.data_utils import (\n",
    "    calc_avg_vals_errors, block_resampling, jackknife_err\n",
    ")\n",
    "from gauge_model import (\n",
    "    GaugeModel, check_else_make_dir, save_params_to_pkl_file\n",
    ")\n",
    "\n",
    "tfe = tf.contrib.eager\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "#from gauge_model import GaugeModel\n",
    "#%reload_ext gauge_model.GaugeModel\n",
    "#from gauge_model import GaugeModel\n",
    "#\n",
    "#from dynamics.gauge_dynamics import GaugeDynamics\n",
    "#%reload_ext dynamics.gauge_dynamics\n",
    "#from dynamics.gauge_dynamics import GaugeDynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T07:29:39.750245Z",
     "start_time": "2019-02-01T07:29:39.680651Z"
    }
   },
   "outputs": [],
   "source": [
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    result /= result[result.argmax()]\n",
    "    return result[result.size//2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T07:29:46.780052Z",
     "start_time": "2019-02-01T07:29:46.663428Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "#--------------------- Lattice parameters ----------------------------\n",
    "    'time_size': 8,\n",
    "    'space_size': 8,\n",
    "    'link_type': 'U1',\n",
    "    'dim': 2,\n",
    "    'num_samples': 4,\n",
    "    'rand': False,\n",
    "#--------------------- Leapfrog parameters ---------------------------\n",
    "    'num_steps': 5,\n",
    "    'eps': 0.2,\n",
    "    'loss_scale': 1.,\n",
    "    'loss_eps': 1e-4,\n",
    "#--------------------- Learning rate parameters ----------------------\n",
    "    'learning_rate_init': 1e-3,\n",
    "    'learning_rate_decay_steps': 500,\n",
    "    'learning_rate_decay_rate': 0.96,\n",
    "#--------------------- Annealing rate parameters ---------------------\n",
    "    'annealing': True,\n",
    "    'annealing_steps': 500,\n",
    "    'annealing_factor': 0.99995,\n",
    "    #'beta': 3.,\n",
    "    'beta_init': 8.,\n",
    "    'beta_final': 8.,\n",
    "#--------------------- Training parameters ---------------------------\n",
    "    'train_steps': 5000,\n",
    "    'save_steps': 1000,\n",
    "    'logging_steps': 50,\n",
    "    'training_samples_steps': 500,\n",
    "    'training_samples_length': 100,\n",
    "#--------------------- Model parameters ------------------------------\n",
    "    'conv_net': True,\n",
    "    'hmc': False,\n",
    "    'eps_trainable': True,\n",
    "    'metric': 'l2',\n",
    "    'aux': True,\n",
    "    'clip_grads': False,\n",
    "    'clip_value': 10.,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T07:29:52.945181Z",
     "start_time": "2019-02-01T07:29:52.889267Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"KMP_BLOCKTIME\"] = str(0)\n",
    "os.environ[\"KMP_SETTINGS\"] = str(1)\n",
    "os.environ[\"KMP_AFFINITY\"] = \"granularity=fine,verbose,compact,1,0\"\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = str(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T07:29:52.999303Z",
     "start_time": "2019-02-01T07:29:52.947343Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T07:43:55.485107Z",
     "start_time": "2019-02-01T07:29:53.001385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory for new run: /Users/saforem2/ANL/l2hmc/gauge_logs_graph/run_42/\n",
      "Creating directory: /Users/saforem2/ANL/l2hmc/gauge_logs_graph/run_42/samples_history.\n",
      "Creating directory: /Users/saforem2/ANL/l2hmc/gauge_logs_graph/run_42/samples_history/training.\n",
      "Creating directory: /Users/saforem2/ANL/l2hmc/gauge_logs_graph/run_42/train_samples.\n",
      "time_size: 8\n",
      "space_size: 8\n",
      "link_type: U1\n",
      "dim: 2\n",
      "num_samples: 4\n",
      "rand: False\n",
      "num_steps: 5\n",
      "eps: 0.2\n",
      "loss_scale: 1.0\n",
      "loss_eps: 0.0001\n",
      "learning_rate_init: 0.001\n",
      "learning_rate_decay_steps: 500\n",
      "learning_rate_decay_rate: 0.96\n",
      "annealing: True\n",
      "annealing_steps: 500\n",
      "annealing_factor: 0.99995\n",
      "beta_init: 8.0\n",
      "beta_final: 8.0\n",
      "train_steps: 5000\n",
      "save_steps: 1000\n",
      "logging_steps: 50\n",
      "training_samples_steps: 500\n",
      "training_samples_length: 100\n",
      "conv_net: True\n",
      "hmc: False\n",
      "eps_trainable: True\n",
      "metric: l2\n",
      "aux: True\n",
      "clip_grads: False\n",
      "clip_value: 10.0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Building graph... (started at: Fri Feb  1 01:29:53 2019)\n",
      "  Creating loss...\n",
      "\n",
      "    took: 386.2770221233368 seconds.\n",
      "  Creating optimizer...\n",
      "\n",
      "\n",
      "    took: 454.54613280296326 seconds.\n",
      "  Creating summaries...\n",
      "\n",
      "\n",
      "    took: 1.5026400089263916 seconds.\n",
      "Time to build graph: 842.3258039951324.\n",
      "\n",
      "Saving params to: /Users/saforem2/ANL/l2hmc/gauge_logs_graph/run_42/run_info/parameters.pkl.\n"
     ]
    }
   ],
   "source": [
    "model = GaugeModel(params=params, \n",
    "                   config=config,\n",
    "                   sess=None,\n",
    "                   log_dir=None,\n",
    "                   restore=False)\n",
    "\n",
    "save_params_to_pkl_file(params, model.info_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-01T07:31:40.777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "     STEP           LOSS       NORM. TIME     ACCEPT %        EPS           BETA           LR      \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.train(model.train_steps, kill_sess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-01T07:31:41.829Z"
    }
   },
   "outputs": [],
   "source": [
    "run_steps = [100, 200, 500, 1000, 5000]#, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-01T07:31:42.766Z"
    }
   },
   "outputs": [],
   "source": [
    "for steps in run_steps:\n",
    "    _ = model.run(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T04:56:23.827714Z",
     "start_time": "2019-01-19T04:56:23.789926Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(model.files['parameters_pkl_file'], 'wb') as f:\n",
    "    pickle.dump(model.params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T07:12:16.636348Z",
     "start_time": "2018-12-28T07:12:16.178153Z"
    }
   },
   "outputs": [],
   "source": [
    "model.sess.graph.collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sess.graph.get_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-27T23:52:43.644163Z",
     "start_time": "2018-12-27T23:52:43.521373Z"
    }
   },
   "outputs": [],
   "source": [
    "model.dynamics.position_fn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over samples history and calculate observables for each sample.\n",
    "# `lattice.calc_plaq_observables(samples)` calculates observables for each of\n",
    "# the samples in the mini-batch.\n",
    "actions_history = []\n",
    "avg_plaquettes_history = []\n",
    "top_charges_history = []\n",
    "for idx, samples in enumerate(samples_history):\n",
    "    t0 = time.time()\n",
    "    observables = np.array(model.lattice.calc_plaq_observables(samples))\n",
    "    actions, plaqs, charges = observables\n",
    "    \n",
    "    actions_history.append(actions)\n",
    "    avg_plaquettes_history.append(plaqs)\n",
    "    top_charges_history.append(charges)\n",
    "    \n",
    "    print(f'step: {idx}  '\n",
    "          f'time / step: {time.time() - t0:^6.4g}  '\n",
    "          f'avg action: {np.mean(actions):^6.4g}  '\n",
    "          f'avg plaquette: {np.mean(plaqs):^6.4g} '\n",
    "          f'top charge: {np.mean(charges):^6.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-23T07:27:14.617518Z",
     "start_time": "2018-12-23T07:27:10.814102Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = helpers.plot_run_data(model.data, \n",
    "                          model.params, \n",
    "                          model.steps_arr, \n",
    "                          model.figs_dir, \n",
    "                          skip_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-23T08:15:46.037934Z",
     "start_time": "2018-12-23T08:15:45.833638Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#tf.reset_default_graph()\n",
    "#model = GaugeModel(params=params,\n",
    "#                   config=None,\n",
    "#                   sess=None,\n",
    "#                   conv_net=False,\n",
    "#                   hmc=False,\n",
    "#                   log_dir='../../gauge_logs_graph/run_25',\n",
    "#                   restore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T04:37:52.672123Z",
     "start_time": "2018-12-24T04:37:52.594856Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = np.random.randn(*model.samples.shape)\n",
    "samples_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T01:12:15.116857Z",
     "start_time": "2018-12-24T01:05:47.837592Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    t0 = time.time()\n",
    "    samples = model.sess.run(model.x_out, feed_dict={model.x: samples})\n",
    "    samples_history.append(samples)\n",
    "    print(f'step: {i:^6.4g} time/step: {time.time() - t0:^6.4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T01:27:43.364615Z",
     "start_time": "2018-12-24T01:27:43.288550Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_history_conv = np.array(samples_history_conv)\n",
    "print(samples_history_conv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T01:27:54.695644Z",
     "start_time": "2018-12-24T01:27:54.608370Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "samples_history_file = os.path.join(model.info_dir, 'samples_history.pkl')\n",
    "with open(samples_history_file, 'wb') as f:\n",
    "    pickle.dump(samples_history_conv, f)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "5",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
