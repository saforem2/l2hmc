{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2HMC using eager execution in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import i0, i1\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from l2hmc_eager import dynamics_eager as _l2hmc\n",
    "from l2hmc_eager import gauge_dynamics_eager as l2hmc\n",
    "from l2hmc_eager.neural_nets import *\n",
    "from utils.distributions import GMM, gen_ring\n",
    "from utils.jacobian import _map, jacobian\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lattice.ising_lattice import IsingLattice\n",
    "from lattice.gauge_lattice import GaugeLattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     5
    ]
   },
   "outputs": [],
   "source": [
    "def train_one_iter(dynamics, beta, x, optimizer, \n",
    "                   loss_fn=l2hmc.compute_loss, global_step=None):\n",
    "    loss, grads, out, accept_prob = l2hmc.loss_and_grads(\n",
    "        dynamics, x, loss_fn=loss_fn\n",
    "    )\n",
    "    optimizer.apply_gradients(\n",
    "        zip(grads, dynamics.trainable_variables), global_step=global_step\n",
    "    )\n",
    "    return loss, out, accept_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_plaquette_average(beta):\n",
    "    return i1(beta) / i0(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct GaugeLattice with $U(1)$ gauge group\n",
    "\n",
    "$$ U_{\\mu\\nu} = \\frac{\\beta}{3}\\sum_{\\nu \\neq \\mu} \\mathrm{Re}\\left\\{\\mathrm{Tr}\\left[U_{\\mu}(x)U_{\\nu}(x+\\hat\\mu)U_{\\mu}^{\\dagger}(x+\\hat\\nu)U_{\\nu}^{\\dagger}(x)\\right]\\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Heatbath Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time_size, space_size, dim, beta, num_samples = (16, 16, 2, 4., 5)\n",
    "u1_lattice = GaugeLattice(time_size, space_size, dim, beta,\n",
    "                          link_type='U1', num_samples=num_samples)\n",
    "u1_samples = [sample.flatten() for sample in u1_lattice.samples]\n",
    "u1_samples_tensor = tf.constant(np.stack(u1_samples), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eq_steps = 5000\n",
    "acceptances = []\n",
    "action_arr = [u1_lattice._total_action()]\n",
    "avg_plaq_arr = [u1_lattice._average_plaquette()]\n",
    "for i in range(eq_steps):\n",
    "    action = u1_lattice._total_action()\n",
    "    avg_plaq = u1_lattice._average_plaquette()\n",
    "    change = avg_plaq - avg_plaq_arr[-1]\n",
    "    avg_plaq_arr.append(avg_plaq)\n",
    "    action_arr.append(action)\n",
    "    print(f\"Step: {i:<5g}\\t action: {action:<8.4g}\\t \"\n",
    "          f\"avg plaq: {avg_plaq:<8.4g}\\t change: {change:<8.4g}\")\n",
    "    accept = 0\n",
    "    for site in u1_lattice.iter_sites():\n",
    "        for d in range(u1_lattice.dim):\n",
    "            accept += u1_lattice._update_link(site, d)\n",
    "    acceptances.append(accept)\n",
    "# 12.2s for 500 equilibration steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(avg_plaq_arr[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(avg_plaq_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exact_plaquette_average(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_plaq_arr = [0]\n",
    "p = k - j\n",
    "for k in range(j, 40000):\n",
    "    avg_plaq = u1_lattice._average_plaquette()\n",
    "    change = avg_plaq - avg_plaq_arr[p-1]\n",
    "    avg_plaq_arr.append(avg_plaq)\n",
    "    print(f\"Step: {k:<5g}: avg plaq: {avg_plaq:>12.4g} change: {change:12.4g}\")\n",
    "    for site in u1_lattice.iter_sites():\n",
    "        for d in range(u1_lattice.dim):\n",
    "            _ = u1_lattice._update_link(site, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_acceptances = 0\n",
    "measure_steps = 10000\n",
    "avg_plq = np.zeros(measure_steps)\n",
    "for step in range(measure_steps):\n",
    "    for site in u1_lattice.iter_sites():\n",
    "        for d in range(u1_lattice.dim):\n",
    "            num_acceptances += u1_lattice._update_link(site, d)\n",
    "    avg_plq[step] = u1_lattice._average_plaquette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u1_lattice._total_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u1_lattice._average_plaquette()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run L2HMC for $U(1)$ gauge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_size, space_size, dim, beta, num_samples = (8, 8, 2, 2., 10)\n",
    "u1_lattice = GaugeLattice(time_size, space_size, dim, beta,\n",
    "                          link_type='U1', num_samples=num_samples, rand=False)\n",
    "#u1_samples = u1_lattice.get_links_samples(batch_size, link_type='U1')\n",
    "#u1_samples_flat = [i.flatten() for i in u1_samples]\n",
    "u1_samples = [sample.flatten() for sample in u1_lattice.samples]\n",
    "u1_samples_tensor = tf.constant(np.stack(u1_samples), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dynamics object\n",
    "u1_energy_fn = u1_lattice.get_energy_function(u1_samples_tensor)\n",
    "u1_dynamics = l2hmc.GaugeDynamics(u1_lattice, \n",
    "                                  minus_loglikelihood_fn=u1_energy_fn, \n",
    "                                  n_steps=10, eps=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "################  tests  #############################\n",
    "#u1_lattice._total_action()\n",
    "#u1_lattice._average_plaquette()\n",
    "#u1_lattice.total_action(u1_samples)\n",
    "#u1_lattice.total_action()\n",
    "#u1_lattice.average_plaquette(u1_samples)\n",
    "#u1_lattice.average_plaquette()\n",
    "#---------------------------------------------\n",
    "#_momentum = tf.random_normal(tf.shape(u1_samples))\n",
    "#_potential = np.array(u1_dynamics.potential(u1_samples_tensor))\n",
    "#_kinetic = u1_dynamics.kinetic(_momentum)\n",
    "#_grad_potential = u1_dynamics.grad_potential(u1_samples_tensor)\n",
    "#print(_potential); print('\\n')\n",
    "#print(_kinetic); print('\\n')\n",
    "#print(_grad_potential)\n",
    "#print(_kinetic.numpy()); print('\\n')\n",
    "#print(_hamiltonian.numpy()); print('\\n')\n",
    "#print(_grad_potential[0][:10])\n",
    "#---------------------------------------------\n",
    "#site = u1_lattice.get_random_site()\n",
    "#u = np.random.randint(u1_lattice.dim)\n",
    "#v = np.random.randint(u1_lattice.dim)\n",
    "#plaq = u1_lattice.plaquette_operator(site, u, v)\n",
    "#---------------------------------------------\n",
    "#u1_lattice.total_action(u1_samples_tensor)\n",
    "#u1_lattice.average_plaquette(u1_samples_tensor)\n",
    "#transition_out = u1_dynamics.apply_transition(u1_samples_tensor)\n",
    "#x_post, p_post, accept_prob, x_out = transition_out\n",
    "#loss, x_out, x_accept_prob = l2hmc.compute_loss(u1_dynamics, u1_samples_tensor)\n",
    "#x_accept_prob\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new log_dir with new run number\n",
    "log_dirs = os.listdir('../../U1_logs/')\n",
    "run_nums = [int(i.split('_')[-1]) for i in log_dirs if i.startswith('run')]\n",
    "run_num = max(run_nums) + 1\n",
    "log_dir = f'../../U1_logs/run_{run_num}'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "_ = global_step.assign(1)\n",
    "train_iters = 500\n",
    "record_loss_every = 10\n",
    "save_steps = 50 \n",
    "\n",
    "learning_rate = tf.train.exponential_decay(1e-3, global_step, 1000, \n",
    "                                           0.96, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "checkpointer = tf.train.Checkpoint(\n",
    "    optimizer=optimizer, dynamics=u1_dynamics, global_step=global_step\n",
    ")\n",
    "summary_writer = tf.contrib.summary.create_file_writer(log_dir)\n",
    "loss_fn = l2hmc.compute_loss\n",
    "samples = u1_samples_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     18,
     35
    ]
   },
   "outputs": [],
   "source": [
    "total_actions = []\n",
    "average_plaquettes = []\n",
    "t0 = time.time()\n",
    "for i in range(1, 500):\n",
    "    t1 = time.time()\n",
    "    loss, samples, accept_prob = train_one_iter(\n",
    "        u1_dynamics,\n",
    "        u1_lattice.beta,\n",
    "        samples,\n",
    "        optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        global_step=global_step\n",
    "    )\n",
    "    _total_actions = u1_lattice.total_action(samples)\n",
    "    _avg_plaquettes = u1_lattice.average_plaquette(samples)\n",
    "    total_actions.extend(_total_actions)\n",
    "    average_plaquettes.extend(_avg_plaquettes)\n",
    "\n",
    "    print(\"Iteration {}, loss {:.4f}, x_accept {:.4f},\"\n",
    "          \" eps {:.4f}, avg_S {:.4f}, avg_plaquette: {:.4f}\".format(\n",
    "              i, loss.numpy(), accept_prob.numpy().mean(),\n",
    "              u1_dynamics.eps.numpy(), np.mean(_total_actions), \n",
    "              np.mean(_avg_plaquettes))\n",
    "         )\n",
    "    print(f'\\n _avg_plaquettes: {[i.numpy() for i in _avg_plaquettes]}\\n')\n",
    "    print(f'time per training step: {time.time() - t1}\\n')\n",
    "\n",
    "    if i % record_loss_every == 0:\n",
    "        with summary_writer.as_default():\n",
    "            with tf.contrib.summary.always_record_summaries():\n",
    "                tf.contrib.summary.scalar(\"Training loss\", loss,\n",
    "                                          step=global_step)\n",
    "\n",
    "    if i % save_steps == 0:\n",
    "        saved_path = checkpointer.save(file_prefix=os.path.join(log_dir,\n",
    "                                                                \"ckpt\"))\n",
    "        print(f\"Saved checkpoint to: {saved_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_plaquette_average(u1_lattice.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1_lattice.total_action(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaqs = []\n",
    "S = []\n",
    "S_approx = []\n",
    "for site in _latt.iter_sites():\n",
    "    for mu in range(_latt.dim):\n",
    "        for nu in range(_latt.dim):\n",
    "            if nu > mu:\n",
    "                plaq =  _latt.plaquette_operator(_latt.links, site, mu, nu)\n",
    "                _S = 1 - np.cos(plaq)\n",
    "                S_approx.append(0.5 * plaq ** 2)\n",
    "                plaqs.append(plaq)\n",
    "                S.append(_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = checkpointer.save(file_prefix=os.path.join(train_dir, \n",
    "                                                        \"ckpt\"))\n",
    "print(f\"Saved checkpoint to: {saved_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "help(sys.stdout.flush)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Construct GaugeLattice with SU(3) gauge group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time_size = 2\n",
    "space_size = 4\n",
    "dim = 4\n",
    "beta = 1.\n",
    "link_type = 'SU3' \n",
    "batch_size = 3\n",
    "gauge_lattice = GaugeLattice(time_size, space_size, dim, beta, link_type)\n",
    "# create `num_samples` random samples of GaugeLattice.links\n",
    "links_samples = gauge_lattice.get_links_samples(batch_size, link_type=link_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gauge_energy_fn = gauge_lattice.get_energy_function()\n",
    "gauge_dynamics = l2hmc.GaugeDynamics(gauge_lattice, \n",
    "                                     minus_loglikelihood_fn=gauge_energy_fn, \n",
    "                                     batch_size=3, n_steps=5, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gauge_lattice.links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "potential_arr = gauge_dynamics.potential(links_samples, batch_size)\n",
    "\n",
    "[i.numpy() for i in potential_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_momentum = tf.random_normal(tf.shape(links_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gauge_dynamics.kinetic(_momentum).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_x = links_samples\n",
    "#_momentum = tf.random_normal(tf.shape(_x))\n",
    "_hamiltonian = gauge_dynamics.hamiltonian(_x, _momentum)\n",
    "_hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Construct IsingLattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ising_batch_size = 10\n",
    "ising_lattice = IsingLattice(3, 4)\n",
    "ising_samples = [ising_lattice._randomize() for _ in range(ising_batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ising_energy_fn = ising_lattice.get_energy_function()\n",
    "ising_dynamics = l2hmc.LatticeDynamics(ising_lattice, \n",
    "                                       minus_loglikelihood_fn=ising_energy_fn,\n",
    "                                       batch_size=ising_batch_size, \n",
    "                                       n_steps=10, eps=0.1)\n",
    "#dynamics = l2hmc.LDynamics(latt.sites.shape, minus_loglikelihood_fn=energy_fn, n_steps=10, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ising_dynamics.potential(samples, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_iposition = ising_samples\n",
    "_imomentum = tf.random_normal(tf.shape(_iposition))\n",
    "_ihamiltonian = dynamics.hamiltonian(_iposition, _imomentum)\n",
    "_ihamiltonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_isample = _iposition[0].reshape(ising_lattice.num_sites)\n",
    "#dynamics.grad_potential(np.array(_position).reshape(-1, lattice.num_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grad_pot = dynamics.grad_potential(ising_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grad_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ising_jacobian = jacobian(dynamics.potential, ising_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grad_fn = tfe.gradients_function(lattice._calc_energy, params=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_jacobian = jacobian(dynamics.potential, _position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lattice.calc_energy(_position, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dynamics.position_fn(momentum, latt.sites.flatten()[:], dynamics)\n",
    "#dynamics._forward_lf(latt.sites.flatten()[:], momentum, 0)\n",
    "dynamics._forward_lf(np.array(_position).reshape(-1, lattice.num_sites),\n",
    "                     np.array(_momentum).reshape(-1, lattice.num_sites), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### GMM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sigmas, distribution = gen_ring(1., var=0.02, nb_mixtures=4)\n",
    "\n",
    "gmm_potential = distribution.get_energy_function()\n",
    "gmm_dynamics = _l2hmc.Dynamics(x_dim=2, minus_loglikelihood_fn=gmm_potential,\n",
    "                               n_steps=25, eps=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "samples = distribution.get_samples(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_position = samples\n",
    "_momentum = tf.random_normal(tf.shape(_position))\n",
    "_hamiltonian = gmm_dynamics.hamiltonian(_position, _momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grad_pot = gmm_dynamics.grad_potential(_position, _momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grad_pot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
